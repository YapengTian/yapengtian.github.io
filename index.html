<!DOCTYPE html>
<html lang="en">
<head>

  <!-- Basic Page Needs
  –––––––––––––––––––––––––––––––––––––––––––––––––– -->
  <meta charset="utf-8">
  <title>Yapeng Tian | Home</title>
  <meta name="description" content="Yapeng Tian">
  <meta name="author" content="Yapeng Tian">


  <!-- <meta property="og:title" content="Martin Saveski" />
  <meta property="og:type" content="website" />
  <meta property="og:url" content="http://yapengtian.org/" />
  <meta property="og:site_name" content="Yapeng Tian" />
  <link rel="canonical" href="https://yapengtian.org/" /> -->

  <!-- Mobile Specific Metas
  –––––––––––––––––––––––––––––––––––––––––––––––––– -->
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">

  <!-- FONT
  –––––––––––––––––––––––––––––––––––––––––––––––––– -->
  <link href='https://fonts.googleapis.com/css?family=Raleway:400,300,600' rel='stylesheet' type='text/css'>

  <!-- CSS
  –––––––––––––––––––––––––––––––––––––––––––––––––– -->
  <link rel="stylesheet" href=/libs/external/skeleton/normalize.css>
  <link rel="stylesheet" href=/libs/external/skeleton/skeleton.css>
  <link rel="stylesheet" href=/libs/custom/my_css.css>

  <!-- JQuery
  –––––––––––––––––––––––––––––––––––––––––––––––––– -->
  <script src=/libs/external/jquery-3.1.1.min.js></script>

  <!-- Font-Awesome
  –––––––––––––––––––––––––––––––––––––––––––––––––– -->
  <link rel="stylesheet" href=/libs/external/font-awesome-4.7.0/css/font-awesome.min.css>

  <!-- Academicons
  –––––––––––––––––––––––––––––––––––––––––––––––––– -->
  <link rel="stylesheet" href=/libs/external/academicons-1.8.6/css/academicons.min.css>

  <!-- Skeleton tabs
  –––––––––––––––––––––––––––––––––––––––––––––––––– -->
  <link rel="stylesheet" href=/libs/external/skeleton_tabs/skeleton-tabs.css>
  <script src=/libs/external/skeleton_tabs/skeleton-tabs.js></script>

  <!-- Timeline
  –––––––––––––––––––––––––––––––––––––––––––––––––– -->
  <link rel="stylesheet" href=/libs/external/timeline.css>

  <!-- Scripts
  –––––––––––––––––––––––––––––––––––––––––––––––––– -->
  <!--<link rel="stylesheet" href=/libs/external/github-prettify-theme.css>-->
  <script src=/libs/custom/my_js.js></script>

  <!-- Favicon
  –––––––––––––––––––––––––––––––––––––––––––––––––– -->
  <!-- <link rel="icon" type="image/png" href=/libs/icon.png>
  <link rel="shortcut icon" type="image/png" href=/libs/icon.png> -->

  <link rel="icon" href="https://upload.wikimedia.org/wikipedia/commons/7/7c/UT_Dallas_2_Color_Emblem_-_SVG_Brand_Identity_File.svg">
  <link rel="shortcut icon" href="https://upload.wikimedia.org/wikipedia/commons/7/7c/UT_Dallas_2_Color_Emblem_-_SVG_Brand_Identity_File.svg">

</head>
<body>

  <!-- Primary Page Layout
  –––––––––––––––––––––––––––––––––––––––––––––––––– -->
  <div class="container">

    <section class="header">
      <div class="row">
        <div class="three columns">
          <a href="/"><img class="rounded" height="200px" width="200px" src='/assets/profile-pics/YapengTian.jpg'></a>
        </div>
        <div class="nine columns main-description">
            <h1>Yapeng Tian</h1>
            <p>Assistant Professor, University of Texas at Dallas</p>
            <p>yapeng.tian@utdallas.edu</p>
            <p>ECSS 4.211</p>
            <p>
              <span onclick="window.open('https://twitter.com/YapengTian')" style="cursor: pointer">
                <i class="fa fa-twitter" aria-hidden="true"></i>
              </span>

              <span onclick="window.open('https://www.linkedin.com/in/yapeng-tian-780795141/')" style="cursor: pointer">
                <i class="fa fa-linkedin-square" aria-hidden="true"></i>
              </span>

              <span onclick="window.open('https://github.com/YapengTian')" style="cursor: pointer">
                <i class="fa fa-github" aria-hidden="true"></i>
              </span>

              <span onclick="window.open('https://scholar.google.com/citations?user=lxCqdpoAAAAJ&hl=en')" style="cursor: pointer">
                <i class="ai ai-google-scholar ai-lg" aria-hidden="true"></i>
              </span>

              <span onclick="window.open('https://dblp.dagstuhl.de/pid/176/4020.html')" style="cursor: pointer">
                <i class="ai ai-dblp ai-lg" aria-hidden="true"></i>
              </span>
            </p>
        </div>
      </div>
    </section>

    <div class="navbar-spacer"></div>
    <nav class="navbar">
      <div class="container">
        <ul class="navbar-list">
          <li class="navbar-item"><a class="navbar-link" href=/index.html#bio>Home</a></li>
          <li class="navbar-item"><a class="navbar-link" href=/index.html#group>Students</a></li>
          <li class="navbar-item"><a class="navbar-link" href=/index.html#publications>Publications</a></li>
          <!-- <li class="navbar-item"><a class="navbar-link" href=/index.html#projects>Projects</a></li> -->
          <li class="navbar-item"><a class="navbar-link" href=/index.html#teaching>Teaching</a></li>
          <li class="navbar-item"><a class="navbar-link" href=/index.html#activity>Service</a></li>
          <li class="navbar-item"><a class="navbar-link" href=/index.html#award>Awards</a></li>
          <li class="navbar-item"><a class="navbar-link" href=/index.html#resume>CV</a></li>
        </ul>
      </div>
    </nav>

    <!-- ========== BIO ========== -->
<span class="anchor" id="bio"></span>
<div class="docs-section">
<div class="docs-section">
  <h4>Bio</h4>
  <p style="text-align:justify; text-justify:inter-ideograph">
    I am an assistant professor in the Computer Science Department of UT Dallas and lead the <b>Computer Vision and Multimodal Computing (CVMC) Lab</b>.
 I am interested in solving core <b>computer vision</b> and <b>computer audition</b> problems and applying the developed learning approaches to broad AI applications.

  My recent work has focused on studying audio-visual scene understanding 
  [<a href="https://openaccess.thecvf.com/content_ECCV_2018/papers/Yapeng_Tian_Audio-Visual_Event_Localization_ECCV_2018_paper.pdf" target="_blank">ECCV'18</a>,
  <a href="https://openaccess.thecvf.com/content_CVPRW_2019/papers/Sight%20and%20Sound/Yapeng_Tian_Audio-Visual_Interpretable_and_Controllable_Video_Captioning_CVPRW_2019_paper.pdf" target="_blank">CVPRW'19</a>,
  <a href="https://arxiv.org/pdf/2007.10558.pdf" target="_blank">ECCV'20</a>,
  <a href="https://arxiv.org/pdf/2104.02026.pdf" target="_blank">CVPR'21a</a>,
  <a href="https://arxiv.org/pdf/2104.02000.pdf" target="_blank">CVPR'21b</a>,
  <a href="https://arxiv.org/pdf/2203.14072.pdf" target="_blank">CVPR'22a</a>]
  and mitigating video motions
  [<a href="https://openaccess.thecvf.com/content_CVPR_2020/papers/Tian_TDAN_Temporally-Deformable_Alignment_Network_for_Video_Super-Resolution_CVPR_2020_paper.pdf" target="_blank">CVPR'20a</a>, 
  <a href="https://arxiv.org/pdf/2002.11616.pdf" target="_blank">CVPR'20b</a>].
  <!-- and improving image quality
  [<a href="https://arxiv.org/pdf/1802.08797.pdf" target="_blank">CVPR'18</a>
  <a href="https://arxiv.org/pdf/2203.13963.pdf" target="_blank">CVPR'22b</a>].  -->
  <!-- My research often falls at the intersections of Social Networks, Machine Learning, and Causal Inference. -->
  </p>

  <p>
    Before coming to UTD, I finished my PhD at University of Rochester, advised by <a href="https://www.cs.rochester.edu/u/cxu22/" target="_blank">Chenliang Xu</a>, my master degree at Tsinghua University working with <a href="http://www.fiesta.tsinghua.edu.cn/pi/2/10" target="_blank">Wenming Yang</a>, and B.E degree at Xidian University.
    I was a visiting student at SIAT advised by <a href="https://scholar.google.com/citations?user=gFtI-8QAAAAJ&hl=en" target="_blank">Yu Qiao</a>. I did internships at Adobe Research with <a href="https://dingzeyu.li/" target="_blank">Dingzeyu Li</a> and Meta with <a href="https://alexanderrichard.github.io/" target="_blank">Alexander Richard</a>.
  </p>



 

  <!-- <p align="justify">
    <a style="color:red;margin-bottom:0;">
      <b>Prospective students:</b><br>
    </a>
    My group has multiple opening Ph.D. positions in Spring and Fall 2023. Please email me your CV if you are interested. For application, please apply to our CS <a href="https://www.utdallas.edu/fact-sheets/ecs/phd-computer-science/" target="_blank">Ph.D. program</a> and mention my name in your research statement.
    <b>
    Current UTD students interested in doing research with me are welcome to email me or stop by my office during my office hours. 
    </b>
  </p>  -->

  <!--
  I am a Postdoc at the department of Management Science and Engineering at Stanford University, working with <a href="https://web.stanford.edu/~jugander/" target="_blank">Johan Ugander</a>. 
  My research develops tools for analyzing large-scale social data, aiming to provide a better understanding of social structure and behaviors online while also impacting the design of digital social systems.
  My work often falls at the intersections of Social Networks, Machine Learning, and Causal Inference.
  </p>

  <p>
  I completed my Ph.D. from MIT in 2020 under the supervision of Deb Roy. 
  Before coming to MIT, I spent one year in Paris and one year in Barcelona doing a M.Sc. in Data mining and Knowledge Management. 
  I got my B.Sc. from Staffordshire University with First Class honors in Computer Science. 
  Throughout my graduate studies, I spent several summers doing internships in industry, including Yahoo! Labs, Amazon, LinkedIn, and Facebook.
  </p>
  -->
</div>
</div>

<span class="anchor" id="news"></span>
<div class="docs-section">
<div class="docs-section">
  <h4>News</h4>
  <div  style="overflow-y: scroll; height:364px;">
<table border="1" style="border-width: 0px;" width="1050">
<tbody>
<tr>
<td style="border-style: none; border-width: medium;">

<ul class="STYLE238">
  <li> 02/2023: Please check out our new <a href="https://liangsusan-git.github.io/project/avnerf/">AV-NeRF</a> paper. In this work, we pose and tackle a Real-World Audio-Visual Scene Synthesis problem.</li>
  <li> 02/2023: One journal paper accepted at IEEE Signal Processing Letters.</li>
  <li> 02/2023: One journal paper accepted at IEEE Transactions on Neural Networks and Learning Systems.</li>
  <li> 01/2023: Two papers accepted at ICLR 2023.</li>
  <li> 11/2022: Selected for the 2023 AAAI New Faculty Highlights Program. </li>
  <li> 10/2022: Invited talk at <a href="https://av4d.org/">AV4D Workshop</a> @ ECCV 2022.</li>
  <li> 09/2022: One paper accepted at NeurIPS 2022. Congratulations to Shentong!</li>
  <li> 09/2022: Two papers accepted at <a href="https://av4d.org/">ECCV@AV4D 2022 </a>.</li>
  <li> 08/2022: Please check out our new article "<a href="https://arxiv.org/pdf/2208.09579.pdf">Learning in Audio-visual Context: A Review, Analysis, and New Perspective</a>."</li>
  <li> 08/2022: I start as an assistant professor in CS at UTD. </li>
  <li> 07/2022: I will serve as a Senior Program Committee (SPC) Member for AAAI 2023. </li>
  <li> 07/2022: One paper accepted at ECCV 2022. </li>
  <li> 06/2022: One paper accepted at MICCAI 2022. </li>
  <li> 06/2022: Successfully defended my dissertation! Thanks to everyone who supported me and helped me along the way.   </li>
  <li> 04/2022: I will attend  CVPR'22 Doctoral Consortium.  </li>
  <li> 03/2022: Two works: audio-visual question answering and MRI SR are accepted by CVPR 2022. </li>
  <li> 12/2021: Two papers are accepted by AAAI 2022.</li>
<li> 10/2021: One paper on sounding object localization is accepted by BMVC 2021! </li>
<li> 07/2021: One paper on video matting is accepted by ICCV 2021! </li>
<li> 03/2021: Our two works: co-learn sounding object visual grounding and sound separation and audio-visual robustness are accepted by CVPR 2021!</li>
<li>02/2021: We will co-organize a CVPR 2021 Tutorial on Audio-visual Scene Understanding!</li>

<li>01/2021: Co-organized the WACV 2021 Tutorial on Audio-visual Scene Understanding. More details can be found in our <a href="https://echo0409.github.io/Audio-Visual-Scene-Understanding/">website</a>.</a></li>

<li>10/2020: I was in the top 10% of high-scoring reviewers for NeurIPS 2020! </li>

<li>07/2020: Our audio-visual video parsing work got accepted by ECCV 2020 as a Spotlight</a>.  </li>

<li>05/2020: Our three papers will be presented in the <a href="http://sightsound.org/">CVPR 2020 Sight and Sound workshop</a>.</li>

<li>02/2020: Two papers on video restoration got accepted by CVPR 2020! Congratulations to all co-authors! </li>

<li>01/2020: RDN is accepted by IEEE TPAMI! Congratulations to Yulun!</li>

<li>12/2019: Please check our deep audio prior paper. </li>

<li>08/2019: One paper is accepted by IEEE TIP. Congratulations to Xuechen!</li>

<li>07/2019: One paper is accepted by ICCV 2019. Congratulations to Wei! </li>

<li>05/2019: Our two works: audio-visual event localization and audio-visual video captioning will be presented in the CVPR 2019 Sight and Sound workshop.</li>

<li>02/2019: I will serve as an ICCV 2019 reviewer. </li>

<li>12/2018: Two papers are posted on ArXiv. Please watch the corresponding demos.  </li>

<li>07/2018: One paper is accepted by ECCV 2018! AVE dataset and codes have been released. </li>

<li> 02/2018: One paper is accepted by CVPR 2018. Congratulations to Yulun! </li>

<li>07/2017: I recieve '<strong>Outstanding Graduate of Tsinghua university</strong>' and '<strong>Outstanding Master Thesis Award</strong>'. </li>

<li>03/2017: I will join Prof. <a href="http://www.cs.rochester.edu/u/cxu22/">Chenliang Xu</a>'s lab to pursue a PhD degree at University of Rochester! </li>


</font>
</ul>
</td>
</tr>
</tbody>
</table>
</div>
</div>
</div>

<!-- ========== BIO ========== -->
<span class="anchor" id="group"></span>
<div class="docs-section">
<div class="docs-section">
  <h4>Students</h4>
    <p style="text-align:left"><b>Students at UTD:</b><br>
      Siva Sai Nagender Vasireddy (PhD student; Fall 2022)<br>
      Shijian Deng (PhD student; Spring 2023)<br>
      Harsh Singh (PhD student; Spring 2023)<br><br>
      <!-- <a href="https://weiguopian.github.io/">Weiguo Pian</a> (PhD student;  co-advised with Prof. Yunhui Guo; Fall 2023)<br> -->
      Yulang Wu (Graduate student; Spring 2023)<br>
      Prathyushaa Vajravelu Karthikeyan (Graduate student; Spring 2023)<br>
      Sasha Kaplan (Undergraduate student; Spring 2023)<br>
      Zeke Barnett (High school student; Spring 2023)<br>
  
    </p>

    <p style="text-align:left"><b>External Students:</b><br>
      <a href="https://scholar.google.com/citations?user=6aYncPAAAAAJ&hl=en">Shentong Mo</a> (PhD student at Carnegie Mellon University)<br>
      <a href="https://ayameyao.github.io/">Guangyao Li</a> (PhD student at Renmin University of China)<br>
      Yuxin Ye (Graduate student at Tsinghua University)<br>
      Yichen Chi (Graduate student at Tsinghua University)<br>
      Junhao Gu (PhD student at Tsinghua University)<br>
      Jiamiao Zhang (Graduate student at Tsinghua University)<br>
    </p>

    <p style="text-align:left"><b>Alumni:</b><br>
    Shijian Deng (Graduate student at University of Rochester; next: PhD student at UTD)<br>
    Hai Wang (Graduate student at Tsinghua University; next: PhD student at UCL)<br>
    <a href="https://lester0866.github.io/">Sizhe Li</a> (Undergraduate student at University of Rochester; next: Visiting student at MIT)<br>
    Yiyang Su (Undergraduate student at University of Rochester; next: PhD student at Michigan State University)<br>
    Rohan Sharma (Graduate student at University of Rochester; next: PhD student at SUNY Buffalo) <br>
    Chenxiao Guan (Undergraduate student at University of Rochester; next: Graduate student at CMU)<br>

    </p>

</div>
</div>

<!-- ========== PUBLICATIONS ========== -->
<span class="anchor"  id="publications"></span>
<div class="docs-section">
<div class="docs-section">
  <h4>Publications</h4>

  <p>Most recent publications on <a href="https://scholar.google.com/citations?user=lxCqdpoAAAAJ&hl=en" target="_blank">Google Scholar</a>.<br/>
  <sup>‡</sup> indicates equal contribution.
  </p>

  <ul class="tab-nav">
    <li><div class="button active" data-ref="#papers-all" font-size: 10px style="width:40px;padding:0 0;">All</div></li>
    <li><div  class="button" data-ref="#papers-selected" font-size: 10px style="width:90px;padding:0 0;">Selected</div></li>
    <li><div class="button" data-ref="#papers-audiovisual" font-size: 10px  style="width:120px;padding:0 0;">Vision+Sound</div></li>
    <li><div class="button" data-ref="#papers-videorestoration" font-size: 10px  style="width:160px;padding:0 0;">Video Restoration</div></li>
    <li><div class="button" data-ref="#papers-imagerestoration" font-size: 10px  style="width:160px;padding:0 0;">Image Restoration</div></li>
  </ul>

  <!-- <div class="tab-content">
    <div class="tab-pane " id="papers-all">
      
      
        <div class="paper">
          <div class="row">
            <div class="four columns" style="margin-right:-35px;" >
              <div class="figure">
                <img style="position:relative;top:-8px" src="/assets/publications/2023_avnerf/teaser.png" width="220" height="110">
              </div>
            </div>
            <div class="eight columns" style="width:69%;">
          <p class="title"><b>AV-NeRF: Learning Neural Fields for Real-World Audio-Visual Scene Synthesis</b></p>
          <p>Susan Liang, Chao Huang, <b>Yapeng Tian</b>, Anurag Kumar, Chenliang Xu</p>
          <p><i>Preprint'23. </i></p>
           
           <div class="paper-buttons">
            
              <a class="button" href="https://arxiv.org/pdf/2302.02088.pdf" target="_blank">Paper</a>
            

            

            

            

            

            

            
              <a class="button" href="https://liangsusan-git.github.io/project/avnerf/" target="_blank">Project</a>
            
           </div>
            </div>
          </div>


        </div>
      
        <div class="paper">
          <div class="row">
            <div class="four columns" style="margin-right:-35px;" >
              <div class="figure">
                <img style="position:relative;top:-8px" src="/assets/publications/2022_avsurvey/teaser.png" width="220" height="110">
              </div>
            </div>
            <div class="eight columns" style="width:69%;">
          <p class="title"><b>Learning in Audio-visual Context: A Review, Analysis, and New Perspective</b></p>
          <p>Yake Wei, Di Hu, <b>Yapeng Tian</b>, Xuelong Li</p>
          <p><i>Preprint'22. </i></p>
           
           <div class="paper-buttons">
            
              <a class="button" href="https://arxiv.org/pdf/2208.09579.pdf" target="_blank">Paper</a>
            

            

            

            

            

            

            
              <a class="button" href="https://gewu-lab.github.io/audio-visual-learning/" target="_blank">Project</a>
            
           </div>
            </div>
          </div>


        </div>
      
        <div class="paper">
          <div class="row">
            <div class="four columns" style="margin-right:-35px;" >
              <div class="figure">
                <img style="position:relative;top:-8px" src="/assets/publications/2023_iclrkd/teaser.png" width="220" height="110">
              </div>
            </div>
            <div class="eight columns" style="width:69%;">
          <p class="title"><b>Knowledge Distillation based Degradation Estimation for Blind Super-Resolution</b></p>
          <p>Bin Xia, Yulun Zhang, Yitong Wang, <b>Yapeng Tian</b>, Wenming Yang, Radu Timofte, Luc Van Gool</p>
          <p><i>ICLR'23: International Conference on Learning Representations.</i></p>
           
           <div class="paper-buttons">
            
              <a class="button" href="https://arxiv.org/abs/2211.16928" target="_blank">Paper</a>
            

            

            

            

            

            

            
           </div>
            </div>
          </div>


        </div>
      
        <div class="paper">
          <div class="row">
            <div class="four columns" style="margin-right:-35px;" >
              <div class="figure">
                <img style="position:relative;top:-8px" src="/assets/publications/2023_iclrbbcu/teaser.png" width="220" height="110">
              </div>
            </div>
            <div class="eight columns" style="width:69%;">
          <p class="title"><b>Basic Binary Convolution Unit for Binarized Image Restoration Network</b></p>
          <p>Bin Xia, Yulun Zhang, Yitong Wang, <b>Yapeng Tian</b>, Wenming Yang, Radu Timofte, Luc Van Gool</p>
          <p><i>ICLR'23: International Conference on Learning Representations.</i></p>
           
           <div class="paper-buttons">
            
              <a class="button" href="https://arxiv.org/pdf/2210.00405.pdf" target="_blank">Paper</a>
            

            

            

            

            

            

            
           </div>
            </div>
          </div>


        </div>
      
        <div class="paper">
          <div class="row">
            <div class="four columns" style="margin-right:-35px;" >
              <div class="figure">
                <img style="position:relative;top:-8px" src="/assets/publications/2023_aaainfh/teaser.png" width="220" height="110">
              </div>
            </div>
            <div class="eight columns" style="width:69%;">
          <p class="title"><b>Towards Unified, Explainable, and Robust Multisensory Perception</b></p>
          <p>Yapeng Tian</p>
          <p><i>AAAI'23: AAAI Conference on Artificial Intelligence. (NFH program)</i></p>
           
           <div class="paper-buttons">
            
              <a class="button" href="/assets/publications/2023_aaainfh/paper.pdf" target="_blank">Paper</a>
            

            

            

            

            

            

            
           </div>
            </div>
          </div>


        </div>
      
        <div class="paper">
          <div class="row">
            <div class="four columns" style="margin-right:-35px;" >
              <div class="figure">
                <img style="position:relative;top:-8px" src="/assets/publications/2022_mgn/teaser.png" width="220" height="110">
              </div>
            </div>
            <div class="eight columns" style="width:69%;">
          <p class="title"><b>Multi-modal Grouping Network for Weakly-Supervised Audio-Visual Video Parsing</b></p>
          <p>Shentong Mo, <b>Yapeng Tian</b></p>
          <p><i>NeurIPS'22: The Annual Conference on Neural Information Processing Systems. </i></p>
           
           <div class="paper-buttons">
            
              <a class="button" href="https://openreview.net/pdf?id=zfo2LqFEVY" target="_blank">Paper</a>
            

            

            

            

            
              <a class="button" href="https://github.com/stoneMo/MGN" target="_blank">Code</a>
            

            

            
           </div>
            </div>
          </div>


        </div>
      
        <div class="paper">
          <div class="row">
            <div class="four columns" style="margin-right:-35px;" >
              <div class="figure">
                <img style="position:relative;top:-8px" src="/assets/publications/2022_std/teaser.png" width="220" height="110">
              </div>
            </div>
            <div class="eight columns" style="width:69%;">
          <p class="title"><b>Learning Spatio-Temporal Downsampling for Effective Video Upscaling</b></p>
          <p>Xiaoyu Xiang, <b>Yapeng Tian</b>, Vijay Rengarajan, Lucas Young, Bo Zhu, Rakesh Ranjan</p>
          <p><i>ECCV'22: European Conference on Computer Vision. </i></p>
           
           <div class="paper-buttons">
            
              <a class="button" href="https://www.ecva.net/papers/eccv_2022/papers_ECCV/papers/136780159.pdf" target="_blank">Paper</a>
            

            

            

            

            

            

            
           </div>
            </div>
          </div>


        </div>
      
        <div class="paper">
          <div class="row">
            <div class="four columns" style="margin-right:-35px;" >
              <div class="figure">
                <img style="position:relative;top:-8px" src="/assets/publications/2022_thesis/thesis.png" width="220" height="110">
              </div>
            </div>
            <div class="eight columns" style="width:69%;">
          <p class="title"><b>Audio-Visual Scene Understanding Towards Unified, Explainable, and Robust Multisensory Perception</b></p>
          <p><b>Yapeng Tian</b></p>
          <p><i>PhD Thesis </i></p>
           
           <div class="paper-buttons">
            
              <a class="button" href="https://www.proquest.com/openview/99bef5e8207df0ebab29e6b1f2afbad8/1.pdf?pq-origsite=gscholar&cbl=18750&diss=y" target="_blank">Paper</a>
            

            

            

            

            

            

            
           </div>
            </div>
          </div>


        </div>
      
        <div class="paper">
          <div class="row">
            <div class="four columns" style="margin-right:-35px;" >
              <div class="figure">
                <img style="position:relative;top:-8px" src="/assets/publications/2022_dudocaf/teaser.png" width="220" height="110">
              </div>
            </div>
            <div class="eight columns" style="width:69%;">
          <p class="title"><b>DuDoCAF: Dual-Domain Cross-Attention Fusion with Recurrent Transformer for Fast Multi-contrast MR Imaging</b></p>
          <p>Jun Lyu, Bin Sui, Chengyan Wang, <b>Yapeng Tian</b>, Qi Dou, and Jing Qin</p>
          <p><i>MICCAI'22: Medical Image Computing and Computer Assisted Intervention. </i></p>
           
           <div class="paper-buttons">
            
              <a class="button" href="/assets/publications/2022_dudocaf/paper.pdf" target="_blank">Paper</a>
            

            

            

            

            

            

            
           </div>
            </div>
          </div>


        </div>
      
        <div class="paper">
          <div class="row">
            <div class="four columns" style="margin-right:-35px;" >
              <div class="figure">
                <img style="position:relative;top:-8px" src="/assets/publications/2022_avol/teaser.png" width="220" height="110">
              </div>
            </div>
            <div class="eight columns" style="width:69%;">
          <p class="title"><b>Audio-Visual Object Localization in Egocentric Videos</b></p>
          <p>Chao Huang, <b>Yapeng Tian</b>, Anurag Kumar, and Chenliang Xu</p>
          <p><i>CVPRW'22: CVPR Workshops</i></p>
          
          <p style="color:red">Egocentric audio-visual learning.</p>
         
           <div class="paper-buttons">
            
              <a class="button" href="https://sightsound.org/papers/2022/Huang_Audio-Visual_Object_Localization_in_Egocentric_Videos.pdf" target="_blank">Paper</a>
            

            

            

            

            

            

            
           </div>
            </div>
          </div>


        </div>
      
        <div class="paper">
          <div class="row">
            <div class="four columns" style="margin-right:-35px;" >
              <div class="figure">
                <img style="position:relative;top:-8px" src="/assets/publications/2022_avqa/teaser.png" width="220" height="110">
              </div>
            </div>
            <div class="eight columns" style="width:69%;">
          <p class="title"><b>Learning to Answer Questions in Dynamic Audio-Visual Scenarios</b></p>
          <p>Guangyao Li<sup>‡</sup>, Yake Wei<sup>‡</sup>, <b>Yapeng Tian<sup>‡</sup></b>, Chenliang Xu, Ji-Rong Wen, and Di Hu</p>
          <p><i>CVPR'22 Oral: IEEE/CVF Conference on Computer Vision and Pattern Recognition. </i></p>
           
           <div class="paper-buttons">
            
              <a class="button" href="https://arxiv.org/pdf/2203.14072.pdf" target="_blank">Paper</a>
            

            

            

            
              <a class="button" href="https://www.youtube.com/watch?v=JH3t5gwe9Xw" target="_blank">Video</a>
            

            
              <a class="button" href="https://github.com/GeWu-Lab/MUSIC-AVQA" target="_blank">Code</a>
            

            

            
              <a class="button" href="https://gewu-lab.github.io/MUSIC-AVQA/" target="_blank">Project</a>
            
           </div>
            </div>
          </div>


        </div>
      
        <div class="paper">
          <div class="row">
            <div class="four columns" style="margin-right:-35px;" >
              <div class="figure">
                <img style="position:relative;top:-8px" src="/assets/publications/2022_mrisr/teaser.png" width="220" height="110">
              </div>
            </div>
            <div class="eight columns" style="width:69%;">
          <p class="title"><b>Transformer-empowered Multi-contrast MRI Super-Resolution</b></p>
          <p>Guangyuan Li, Jun Lv, <b>Yapeng Tian</b>, Qi Dou, Chengyan Wang, Chenliang Xu, Jing Qin</p>
          <p><i>CVPR'22: IEEE/CVF Conference on Computer Vision and Pattern Recognition.</i></p>
           
           <div class="paper-buttons">
            
              <a class="button" href="https://arxiv.org/pdf/2203.13963.pdf" target="_blank">Paper</a>
            

            

            

            

            
              <a class="button" href="https://github.com/XAIMI-Lab/McMRSR" target="_blank">Code</a>
            

            

            
           </div>
            </div>
          </div>


        </div>
      
        <div class="paper">
          <div class="row">
            <div class="four columns" style="margin-right:-35px;" >
              <div class="figure">
                <img style="position:relative;top:-8px" src="/assets/publications/2022_amsa/teaser.png" width="220" height="110">
              </div>
            </div>
            <div class="eight columns" style="width:69%;">
          <p class="title"><b>Coarse-to-Fine Embedded PatchMatch and Multi-Scale Dynamic Aggregation for Reference-based Super-Resolution</b></p>
          <p>Bin Xia, <b>Yapeng Tian</b>, Yucheng Hang, Wenming Yang, Qingmin Liao, Jie Zhou</p>
          <p><i>AAAI'22: The AAAI Conference on Artificial Intelligence.</i></p>
           
           <div class="paper-buttons">
            
              <a class="button" href="https://arxiv.org/pdf/2201.04358.pdf" target="_blank">Paper</a>
            

            

            

            

            
              <a class="button" href="https://github.com/Zj-BinXia/AMSA" target="_blank">Code</a>
            

            

            
           </div>
            </div>
          </div>


        </div>
      
        <div class="paper">
          <div class="row">
            <div class="four columns" style="margin-right:-35px;" >
              <div class="figure">
                <img style="position:relative;top:-8px" src="/assets/publications/2022_enlca/teaser.png" width="220" height="110">
              </div>
            </div>
            <div class="eight columns" style="width:69%;">
          <p class="title"><b>Efficient Non-Local Contrastive Attention for Image Super-Resolution</b></p>
          <p>Bin Xia<sup>‡</sup>, Yucheng Hang<sup>‡</sup>, <b>Yapeng Tian</b>, Wenming Yang, Qingmin Liao, Jie Zhou</p>
          <p><i>AAAI'22: The AAAI Conference on Artificial Intelligence. </i></p>
           
           <div class="paper-buttons">
            
              <a class="button" href="https://arxiv.org/pdf/2201.03794.pdf" target="_blank">Paper</a>
            

            

            

            

            
              <a class="button" href="https://github.com/Zj-BinXia/ENLCA" target="_blank">Code</a>
            

            

            
           </div>
            </div>
          </div>


        </div>
      
        <div class="paper">
          <div class="row">
            <div class="four columns" style="margin-right:-35px;" >
              <div class="figure">
                <img style="position:relative;top:-8px" src="/assets/publications/2021_stm/teaser.png" width="220" height="110">
              </div>
            </div>
            <div class="eight columns" style="width:69%;">
          <p class="title"><b>Space-Time Memory Network for Sounding Object Localization in Videos</b></p>
          <p>Sizhe Li<sup>‡</sup>, <b>Yapeng Tian<sup>‡</sup></b>, and Chenliang Xu</p>
          <p><i>BMVC'21: The British Machine Vision Conference. </i></p>
           
           <div class="paper-buttons">
            
              <a class="button" href="https://arxiv.org/pdf/2111.05526.pdf" target="_blank">Paper</a>
            

            

            

            

            
              <a class="button" href="https://github.com/lester0866/Space-Time-Memory-Network-for-Sounding-Object-Localization-in-Videos" target="_blank">Code</a>
            

            

            
              <a class="button" href="https://sites.google.com/view/bmvc2021stm" target="_blank">Project</a>
            
           </div>
            </div>
          </div>


        </div>
      
        <div class="paper">
          <div class="row">
            <div class="four columns" style="margin-right:-35px;" >
              <div class="figure">
                <img style="position:relative;top:-8px" src="/assets/publications/2021_matting/teaser.png" width="220" height="110">
              </div>
            </div>
            <div class="eight columns" style="width:69%;">
          <p class="title"><b>Video Matting via Consistency-Regularized Graph Neural Networks</b></p>
          <p>Tiantian Wang, Sifei Liu, <b>Yapeng Tian</b>, Kai Li, and Ming-Hsuan Yang</p>
          <p><i>ICCV'21: IEEE/CVF International Conference on Computer Vision. </i></p>
           
           <div class="paper-buttons">
            
              <a class="button" href="https://faculty.ucmerced.edu/mhyang/papers/iccv2021_video_matting.pdf" target="_blank">Paper</a>
            

            

            

            

            
              <a class="button" href="https://github.com/TiantianWang/VideoMatting-CRGNN" target="_blank">Code</a>
            

            

            
           </div>
            </div>
          </div>


        </div>
      
        <div class="paper">
          <div class="row">
            <div class="four columns" style="margin-right:-35px;" >
              <div class="figure">
                <img style="position:relative;top:-8px" src="/assets/publications/2021_robustness/teaser.png" width="220" height="110">
              </div>
            </div>
            <div class="eight columns" style="width:69%;">
          <p class="title"><b>Can audio-visual integration strengthen robustness under multimodal attacks?</b></p>
          <p><b>Yapeng Tian</b> and Chenliang Xu</p>
          <p><i>CVPR'21: IEEE/CVF Conference on Computer Vision and Pattern Recognition. </i></p>
           
           <div class="paper-buttons">
            
              <a class="button" href="https://arxiv.org/pdf/2104.02000.pdf" target="_blank">Paper</a>
            

            

            

            

            
              <a class="button" href="https://github.com/YapengTian/AV-Robustness-CVPR21" target="_blank">Code</a>
            

            

            
           </div>
            </div>
          </div>


        </div>
      
        <div class="paper">
          <div class="row">
            <div class="four columns" style="margin-right:-35px;" >
              <div class="figure">
                <img style="position:relative;top:-8px" src="/assets/publications/2021_ccol/teaser.png" width="220" height="110">
              </div>
            </div>
            <div class="eight columns" style="width:69%;">
          <p class="title"><b>Cyclic Co-Learning of Sounding Object Visual Grounding and Sound Separation</b></p>
          <p><b>Yapeng Tian</b>, Di Hu, and Chenliang Xu</p>
          <p><i>CVPR'21: IEEE/CVF Conference on Computer Vision and Pattern Recognition.</i></p>
           
           <div class="paper-buttons">
            
              <a class="button" href="https://arxiv.org/pdf/2104.02026.pdf" target="_blank">Paper</a>
            

            

            

            

            
              <a class="button" href="https://github.com/YapengTian/CCOL-CVPR21" target="_blank">Code</a>
            

            

            
           </div>
            </div>
          </div>


        </div>
      
        <div class="paper">
          <div class="row">
            <div class="four columns" style="margin-right:-35px;" >
              <div class="figure">
                <img style="position:relative;top:-8px" src="/assets/publications/2020_avvp/teaser.png" width="220" height="110">
              </div>
            </div>
            <div class="eight columns" style="width:69%;">
          <p class="title"><b>Unified Multisensory Perception: Weakly-Supervised Audio-Visual Video Parsing</b></p>
          <p><b>Yapeng Tian</b>, Dingzeyu Li, and Chenliang Xu</p>
          <p><i>ECCV'20 Spotlight: European Conference on Computer Vision.</i></p>
           
           <div class="paper-buttons">
            
              <a class="button" href="https://arxiv.org/pdf/2007.10558.pdf" target="_blank">Paper</a>
            

            

            

            

            
              <a class="button" href="https://github.com/YapengTian/AVVP-ECCV20" target="_blank">Code</a>
            

            
              <a class="button" href="https://github.com/YapengTian/AVVP-ECCV20" target="_blank">Data</a>
            

            
           </div>
            </div>
          </div>


        </div>
      
        <div class="paper">
          <div class="row">
            <div class="four columns" style="margin-right:-35px;" >
              <div class="figure">
                <img style="position:relative;top:-8px" src="/assets/publications/2020_zsm/teaser.png" width="220" height="110">
              </div>
            </div>
            <div class="eight columns" style="width:69%;">
          <p class="title"><b>Zooming Slow-Mo: Fast and Accurate One-Stage Space-Time Video Super-Resolution</b></p>
          <p>Xiaoyu Xiang<sup>‡</sup>, <b>Yapeng Tian<sup>‡</sup></b>, Yulun Zhang, Yun Fu, Jan Allebach, and Chenliang Xu</p>
          <p><i>CVPR'20: IEEE/CVF Conference on Computer Vision and Pattern Recognition.</i></p>
           
           <div class="paper-buttons">
            
              <a class="button" href="https://arxiv.org/pdf/2002.11616.pdf" target="_blank">Paper</a>
            

            

            

            
              <a class="button" href="https://www.youtube.com/watch?v=8mgD8JxBOus" target="_blank">Video</a>
            

            
              <a class="button" href="https://github.com/Mukosame/Zooming-Slow-Mo-CVPR-2020" target="_blank">Code</a>
            

            

            
           </div>
            </div>
          </div>


        </div>
      
        <div class="paper">
          <div class="row">
            <div class="four columns" style="margin-right:-35px;" >
              <div class="figure">
                <img style="position:relative;top:-8px" src="/assets/publications/2020_tdan/teaser.png" width="220" height="110">
              </div>
            </div>
            <div class="eight columns" style="width:69%;">
          <p class="title"><b>TDAN: Temporally Deformable Alignment Network for Video Super-Resolution</b></p>
          <p><b>Yapeng Tian</b>, Yulun Zhang, Yun Fu, and Chenliang Xu</p>
          <p><i>CVPR'20: IEEE/CVF Conference on Computer Vision and Pattern Recognition.</i></p>
          
          <p style="color:red">This is the first work that uses deformable alignment to address video restoration.</p>
         
           <div class="paper-buttons">
            
              <a class="button" href="https://openaccess.thecvf.com/content_CVPR_2020/papers/Tian_TDAN_Temporally-Deformable_Alignment_Network_for_Video_Super-Resolution_CVPR_2020_paper.pdf" target="_blank">Paper</a>
            

            

            

            
              <a class="button" href="https://www.youtube.com/watch?v=eZExENE50I0" target="_blank">Video</a>
            

            
              <a class="button" href="https://github.com/YapengTian/TDAN-VSR-CVPR-2020" target="_blank">Code</a>
            

            

            
           </div>
            </div>
          </div>


        </div>
      
        <div class="paper">
          <div class="row">
            <div class="four columns" style="margin-right:-35px;" >
              <div class="figure">
                <img style="position:relative;top:-8px" src="/assets/publications/2020_dap/teaser.png" width="220" height="110">
              </div>
            </div>
            <div class="eight columns" style="width:69%;">
          <p class="title"><b>Deep Audio Prior</b></p>
          <p><b>Yapeng Tian</b>, Chenliang Xu, and Dingzeyu Li</p>
          <p><i>CVPRW'20: CVPR Workshops.</i></p>
           
           <div class="paper-buttons">
            
              <a class="button" href="https://arxiv.org/pdf/1912.10292v1.pdf" target="_blank">Paper</a>
            

            

            

            

            
              <a class="button" href="https://github.com/adobe/Deep-Audio-Prior" target="_blank">Code</a>
            

            

            
              <a class="button" href="https://opensource.adobe.com/Deep-Audio-Prior/" target="_blank">Project</a>
            
           </div>
            </div>
          </div>


        </div>
      
        <div class="paper">
          <div class="row">
            <div class="four columns" style="margin-right:-35px;" >
              <div class="figure">
                <img style="position:relative;top:-8px" src="/assets/publications/2020_rdnpami/teaser.png" width="220" height="110">
              </div>
            </div>
            <div class="eight columns" style="width:69%;">
          <p class="title"><b>Residual Dense Network for Image Super-Resolution</b></p>
          <p>Yulun Zhang, <b>Yapeng Tian</b>, Yu Kong , Bineng Zhong, Yun Fu</p>
          <p><i>TPAMI'20: IEEE Transactions on Pattern Analysis and Machine Intelligence.</i></p>
           
           <div class="paper-buttons">
            
              <a class="button" href="https://arxiv.org/pdf/1812.10477.pdf" target="_blank">Paper</a>
            

            

            

            

            
              <a class="button" href="https://github.com/yulunzhang/RDN" target="_blank">Code</a>
            

            

            
           </div>
            </div>
          </div>


        </div>
      
        <div class="paper">
          <div class="row">
            <div class="four columns" style="margin-right:-35px;" >
              <div class="figure">
                <img style="position:relative;top:-8px" src="/assets/publications/2019_csf/teaser.png" width="220" height="110">
              </div>
            </div>
            <div class="eight columns" style="width:69%;">
          <p class="title"><b>CFSNet: Toward a Controllable Feature Space for Image Restoration</b></p>
          <p>Wei Wang<sup>‡</sup>, Ruiming Guo<sup>‡</sup>, <b>Yapeng Tian</b>, and Wenming Yang</p>
          <p><i>ICCV'19: IEEE/CVF International Conference on Computer Vision.</i></p>
           
           <div class="paper-buttons">
            
              <a class="button" href="https://arxiv.org/pdf/1904.00634.pdf" target="_blank">Paper</a>
            

            

            

            

            
              <a class="button" href="https://github.com/qibao77/CFSNet" target="_blank">Code</a>
            

            

            
           </div>
            </div>
          </div>


        </div>
      
        <div class="paper">
          <div class="row">
            <div class="four columns" style="margin-right:-35px;" >
              <div class="figure">
                <img style="position:relative;top:-8px" src="/assets/publications/2019_avc/teaser.png" width="220" height="110">
              </div>
            </div>
            <div class="eight columns" style="width:69%;">
          <p class="title"><b>Interpretable and Controllable Audio-Visual Video Captioning</b></p>
          <p><b>Yapeng Tian</b>, Chenxiao Guan, Goodman Justin, Marc Moore, and Chenliang Xu</p>
          <p><i>CVPRW'19: CVPR Workshops.</i></p>
          
          <p style="color:red">Multisensory interpretability in terms of the audio-visual video captioning task.</p>
         
           <div class="paper-buttons">
            
              <a class="button" href="https://openaccess.thecvf.com/content_CVPRW_2019/papers/Sight%20and%20Sound/Yapeng_Tian_Audio-Visual_Interpretable_and_Controllable_Video_Captioning_CVPRW_2019_paper.pdf" target="_blank">Paper</a>
            

            

            

            

            

            

            
           </div>
            </div>
          </div>


        </div>
      
        <div class="paper">
          <div class="row">
            <div class="four columns" style="margin-right:-35px;" >
              <div class="figure">
                <img style="position:relative;top:-8px" src="/assets/publications/2019_lcsc/teaser.png" width="220" height="110">
              </div>
            </div>
            <div class="eight columns" style="width:69%;">
          <p class="title"><b>LCSCNet: Linear Compressing Based Skip-Connecting Network for ISR</b></p>
          <p>Wenming Yang, Xuechen Zhang, <b>Yapeng Tian</b>, Wei Wang, Jing-Hao Xue, Qingmin Liao</p>
          <p><i>TIP'19: IEEE Trans. Image Processing.</i></p>
           
           <div class="paper-buttons">
            
              <a class="button" href="https://arxiv.org/abs/1909.03573" target="_blank">Paper</a>
            

            

            

            

            

            

            
           </div>
            </div>
          </div>


        </div>
      
        <div class="paper">
          <div class="row">
            <div class="four columns" style="margin-right:-35px;" >
              <div class="figure">
                <img style="position:relative;top:-8px" src="/assets/publications/2019_review/teaser.png" width="220" height="110">
              </div>
            </div>
            <div class="eight columns" style="width:69%;">
          <p class="title"><b>Deep Learning for Single Image Super-Resolution: A Brief Review</b></p>
          <p>Wenming Yang, Xuechen Zhang, <b>Yapeng Tian</b>, Wei Wang, JingHao Xue, Qingmin Liao</p>
          <p><i>TMM'19: IEEE Trans. Multimedia.</i></p>
           
           <div class="paper-buttons">
            
              <a class="button" href="https://arxiv.org/pdf/1808.03344.pdf" target="_blank">Paper</a>
            

            

            

            

            

            

            
           </div>
            </div>
          </div>


        </div>
      
        <div class="paper">
          <div class="row">
            <div class="four columns" style="margin-right:-35px;" >
              <div class="figure">
                <img style="position:relative;top:-8px" src="/assets/publications/2018_ave/teaser.png" width="220" height="110">
              </div>
            </div>
            <div class="eight columns" style="width:69%;">
          <p class="title"><b>Audio-Visual Event Localization in Unconstrained Videos</b></p>
          <p><b>Yapeng Tian</b>, Jing Shi, Bochen Li, Zhiyao Duan, Chenliang Xu</p>
          <p><i>ECCV'18: European Conference on Computer Vision.</i></p>
           
           <div class="paper-buttons">
            
              <a class="button" href="https://openaccess.thecvf.com/content_ECCV_2018/papers/Yapeng_Tian_Audio-Visual_Event_Localization_ECCV_2018_paper.pdf" target="_blank">Paper</a>
            

            

            

            
              <a class="button" href="https://www.youtube.com/watch?v=m6r6BbD5MSc" target="_blank">Video</a>
            

            
              <a class="button" href="https://github.com/YapengTian/AVE-ECCV18" target="_blank">Code</a>
            

            
              <a class="button" href="https://drive.google.com/file/d/1FjKwe79e0u96vdjIVwfRQ1V6SoDHe7kK" target="_blank">Data</a>
            

            
              <a class="button" href="https://sites.google.com/view/audiovisualresearch" target="_blank">Project</a>
            
           </div>
            </div>
          </div>


        </div>
      
        <div class="paper">
          <div class="row">
            <div class="four columns" style="margin-right:-35px;" >
              <div class="figure">
                <img style="position:relative;top:-8px" src="/assets/publications/2018_rdn/teaser.png" width="220" height="110">
              </div>
            </div>
            <div class="eight columns" style="width:69%;">
          <p class="title"><b>Residual Dense Network for Image Super-Resolution</b></p>
          <p>Yulun Zhang, <b>Yapeng Tian</b>, Yu Kong , Bineng Zhong, Yun Fu</p>
          <p><i>CVPR'18 Spotlight: IEEE/CVF Conf. on Computer Vision and Pattern Recognition.</i></p>
           
           <div class="paper-buttons">
            
              <a class="button" href="https://arxiv.org/pdf/1802.08797.pdf" target="_blank">Paper</a>
            

            

            

            

            
              <a class="button" href="https://github.com/yulunzhang/RDN" target="_blank">Code</a>
            

            

            
           </div>
            </div>
          </div>


        </div>
      
        <div class="paper">
          <div class="row">
            <div class="four columns" style="margin-right:-35px;" >
              <div class="figure">
                <img style="position:relative;top:-8px" src="/assets/publications/2017_ntire/teaser.png" width="220" height="110">
              </div>
            </div>
            <div class="eight columns" style="width:69%;">
          <p class="title"><b>NTIRE 2017 Challenge on Single Image Super-Resolution: Methods and Results</b></p>
          <p>Timofte et al.</p>
          <p><i>CVPRW'17: CVPR Workshops.</i></p>
           
           <div class="paper-buttons">
            
              <a class="button" href="https://people.ee.ethz.ch/~timofter/publications/Timofte-CVPRW-2017.pdf" target="_blank">Paper</a>
            

            

            

            

            

            

            
           </div>
            </div>
          </div>


        </div>
      
        <div class="paper">
          <div class="row">
            <div class="four columns" style="margin-right:-35px;" >
              <div class="figure">
                <img style="position:relative;top:-8px" src="/assets/publications/2016_ccs/teaser.png" width="220" height="110">
              </div>
            </div>
            <div class="eight columns" style="width:69%;">
          <p class="title"><b>Consistent Coding Scheme for Single-Image Super-Resolution</b></p>
          <p>Wenming Yang, <b>Yapeng Tian</b>, Fei Zhou, Qingmin Liao, Hai Chen, Chenglin Zheng</p>
          <p><i>TMM'16: EEE Trans. Multimedia. (First student author)</i></p>
           
           <div class="paper-buttons">
            
              <a class="button" href="https://drive.google.com/file/d/1MpEM5qmSJi1GtY9TftNNV0cgSHqMT_KQ/view" target="_blank">Paper</a>
            

            

            

            

            

            

            
           </div>
            </div>
          </div>


        </div>
      
        <div class="paper">
          <div class="row">
            <div class="four columns" style="margin-right:-35px;" >
              <div class="figure">
                <img style="position:relative;top:-8px" src="/assets/publications/2016_anrse/teaser.png" width="220" height="110">
              </div>
            </div>
            <div class="eight columns" style="width:69%;">
          <p class="title"><b>Anchored Neighborhood Regression based SISR from Self-examples</b></p>
          <p><b>Yapeng Tian</b>, Fei Zhou, Wenming Yang, Xuesen Shang, Qingmin Liao</p>
          <p><i>ICIP'16: IEEE International Conference on Image Processing.</i></p>
           
           <div class="paper-buttons">
            
              <a class="button" href="https://drive.google.com/file/d/1Ts_gYIp57llzK53Wyt7hwu4lZ9GQsbis/view" target="_blank">Paper</a>
            

            

            

            

            
              <a class="button" href="https://github.com/YapengTian/ICIP2016" target="_blank">Code</a>
            

            

            
           </div>
            </div>
          </div>


        </div>
      
        <div class="paper">
          <div class="row">
            <div class="four columns" style="margin-right:-35px;" >
              <div class="figure">
                <img style="position:relative;top:-8px" src="/assets/publications/2015_pfsr/teaser.png" width="220" height="110">
              </div>
            </div>
            <div class="eight columns" style="width:69%;">
          <p class="title"><b>SISR Using Clustering-Based Global Regression and Propagation Filtering</b></p>
          <p>Wenming Yang, <b>Yapeng Tian</b>, Fei Zhou, ..., Qingmin Liao</p>
          <p><i>ACPR'15 Oral: Asian Conference on Pattern Recognition. (First student author)</i></p>
           
           <div class="paper-buttons">
            
              <a class="button" href="https://drive.google.com/file/d/12tqTHt0aLn7-B1jEgEJBYY64uhwfEezA/view" target="_blank">Paper</a>
            

            

            

            

            

            

            
           </div>
            </div>
          </div>


        </div>
      
    </div> -->


  <div class="tab-content">
    <div class="tab-pane active" id="papers-all">
      
      
    
        <div >
          <div class="figure">
            <img style="float:left;margin-bottom:20px;margin-right:30px;vertical-align:middle;" src="/assets/publications/2023_avnerf/teaser.png" width="220" height="110" /> 
          </div>
        <div class="paper">
          <p class="title"><b>AV-NeRF: Learning Neural Fields for Real-World Audio-Visual Scene Synthesis</b></p>
          <p>Susan Liang, Chao Huang, <b>Yapeng Tian</b>, Anurag Kumar, Chenliang Xu</p>
          <p><i>Preprint'23. </i></p>
           
           <div class="paper-buttons">
            
              <a class="button" href="https://arxiv.org/pdf/2302.02088.pdf" target="_blank">Paper</a>
            

            

            

            

            

            

            
              <a class="button" href="https://liangsusan-git.github.io/project/avnerf/" target="_blank">Project</a>
            
           </div>


        </div>
          </div>
      
    
        <div >
          <div class="figure">
            <img style="float:left;margin-bottom:20px;margin-right:30px;vertical-align:middle;" src="/assets/publications/2022_avsurvey/teaser.png" width="220" height="110" /> 
          </div>
        <div class="paper">
          <p class="title"><b>Learning in Audio-visual Context: A Review, Analysis, and New Perspective</b></p>
          <p>Yake Wei, Di Hu, <b>Yapeng Tian</b>, Xuelong Li</p>
          <p><i>Preprint'22. </i></p>
           
           <div class="paper-buttons">
            
              <a class="button" href="https://arxiv.org/pdf/2208.09579.pdf" target="_blank">Paper</a>
            

            

            

            

            

            

            
              <a class="button" href="https://gewu-lab.github.io/audio-visual-learning/" target="_blank">Project</a>
            
           </div>


        </div>
          </div>
      
    
        <div >
          <div class="figure">
            <img style="float:left;margin-bottom:20px;margin-right:30px;vertical-align:middle;" src="/assets/publications/2023_iclrkd/teaser.png" width="220" height="110" /> 
          </div>
        <div class="paper">
          <p class="title"><b>Knowledge Distillation based Degradation Estimation for Blind Super-Resolution</b></p>
          <p>Bin Xia, Yulun Zhang, Yitong Wang, <b>Yapeng Tian</b>, Wenming Yang, Radu Timofte, Luc Van Gool</p>
          <p><i>ICLR'23: International Conference on Learning Representations.</i></p>
           
           <div class="paper-buttons">
            
              <a class="button" href="https://arxiv.org/abs/2211.16928" target="_blank">Paper</a>
            

            

            

            

            

            

            
           </div>


        </div>
          </div>
      
    
        <div >
          <div class="figure">
            <img style="float:left;margin-bottom:20px;margin-right:30px;vertical-align:middle;" src="/assets/publications/2023_iclrbbcu/teaser.png" width="220" height="110" /> 
          </div>
        <div class="paper">
          <p class="title"><b>Basic Binary Convolution Unit for Binarized Image Restoration Network</b></p>
          <p>Bin Xia, Yulun Zhang, Yitong Wang, <b>Yapeng Tian</b>, Wenming Yang, Radu Timofte, Luc Van Gool</p>
          <p><i>ICLR'23: International Conference on Learning Representations.</i></p>
           
           <div class="paper-buttons">
            
              <a class="button" href="https://arxiv.org/pdf/2210.00405.pdf" target="_blank">Paper</a>
            

            

            

            

            

            

            
           </div>


        </div>
          </div>
      
    
        <div >
          <div class="figure">
            <img style="float:left;margin-bottom:20px;margin-right:30px;vertical-align:middle;" src="/assets/publications/2023_aaainfh/teaser.png" width="220" height="110" /> 
          </div>
        <div class="paper">
          <p class="title"><b>Towards Unified, Explainable, and Robust Multisensory Perception</b></p>
          <p>Yapeng Tian</p>
          <p><i>AAAI'23: AAAI Conference on Artificial Intelligence. (NFH program)</i></p>
           
           <div class="paper-buttons">
            
              <a class="button" href="/assets/publications/2023_aaainfh/paper.pdf" target="_blank">Paper</a>
            

            

            

            

            

            

            
           </div>


        </div>
          </div>
      
    
        <div >
          <div class="figure">
            <img style="float:left;margin-bottom:20px;margin-right:30px;vertical-align:middle;" src="/assets/publications/2022_mgn/teaser.png" width="220" height="110" /> 
          </div>
        <div class="paper">
          <p class="title"><b>Multi-modal Grouping Network for Weakly-Supervised Audio-Visual Video Parsing</b></p>
          <p>Shentong Mo, <b>Yapeng Tian</b></p>
          <p><i>NeurIPS'22: The Annual Conference on Neural Information Processing Systems. </i></p>
           
           <div class="paper-buttons">
            
              <a class="button" href="https://openreview.net/pdf?id=zfo2LqFEVY" target="_blank">Paper</a>
            

            

            

            

            
              <a class="button" href="https://github.com/stoneMo/MGN" target="_blank">Code</a>
            

            

            
           </div>


        </div>
          </div>
      
    
        <div >
          <div class="figure">
            <img style="float:left;margin-bottom:20px;margin-right:30px;vertical-align:middle;" src="/assets/publications/2022_std/teaser.png" width="220" height="110" /> 
          </div>
        <div class="paper">
          <p class="title"><b>Learning Spatio-Temporal Downsampling for Effective Video Upscaling</b></p>
          <p>Xiaoyu Xiang, <b>Yapeng Tian</b>, Vijay Rengarajan, Lucas Young, Bo Zhu, Rakesh Ranjan</p>
          <p><i>ECCV'22: European Conference on Computer Vision. </i></p>
           
           <div class="paper-buttons">
            
              <a class="button" href="https://www.ecva.net/papers/eccv_2022/papers_ECCV/papers/136780159.pdf" target="_blank">Paper</a>
            

            

            

            

            

            

            
           </div>


        </div>
          </div>
      
    
        <div >
          <div class="figure">
            <img style="float:left;margin-bottom:20px;margin-right:30px;vertical-align:middle;" src="/assets/publications/2022_thesis/thesis.png" width="220" height="110" /> 
          </div>
        <div class="paper">
          <p class="title"><b>Audio-Visual Scene Understanding Towards Unified, Explainable, and Robust Multisensory Perception</b></p>
          <p><b>Yapeng Tian</b></p>
          <p><i>PhD Thesis </i></p>
           
           <div class="paper-buttons">
            
              <a class="button" href="https://www.proquest.com/openview/99bef5e8207df0ebab29e6b1f2afbad8/1.pdf?pq-origsite=gscholar&cbl=18750&diss=y" target="_blank">Paper</a>
            

            

            

            

            

            

            
           </div>


        </div>
          </div>
      
    
        <div >
          <div class="figure">
            <img style="float:left;margin-bottom:20px;margin-right:30px;vertical-align:middle;" src="/assets/publications/2022_dudocaf/teaser.png" width="220" height="110" /> 
          </div>
        <div class="paper">
          <p class="title"><b>DuDoCAF: Dual-Domain Cross-Attention Fusion with Recurrent Transformer for Fast Multi-contrast MR Imaging</b></p>
          <p>Jun Lyu, Bin Sui, Chengyan Wang, <b>Yapeng Tian</b>, Qi Dou, and Jing Qin</p>
          <p><i>MICCAI'22: Medical Image Computing and Computer Assisted Intervention. </i></p>
           
           <div class="paper-buttons">
            
              <a class="button" href="/assets/publications/2022_dudocaf/paper.pdf" target="_blank">Paper</a>
            

            

            

            

            

            

            
           </div>


        </div>
          </div>
      
    
        <div >
          <div class="figure">
            <img style="float:left;margin-bottom:20px;margin-right:30px;vertical-align:middle;" src="/assets/publications/2022_avol/teaser.png" width="220" height="110" /> 
          </div>
        <div class="paper">
          <p class="title"><b>Audio-Visual Object Localization in Egocentric Videos</b></p>
          <p>Chao Huang, <b>Yapeng Tian</b>, Anurag Kumar, and Chenliang Xu</p>
          <p><i>CVPRW'22: CVPR Workshops</i></p>
          
          <p style="color:red">Egocentric audio-visual learning.</p>
         
           <div class="paper-buttons">
            
              <a class="button" href="https://sightsound.org/papers/2022/Huang_Audio-Visual_Object_Localization_in_Egocentric_Videos.pdf" target="_blank">Paper</a>
            

            

            

            

            

            

            
           </div>


        </div>
          </div>
      
    
        <div >
          <div class="figure">
            <img style="float:left;margin-bottom:20px;margin-right:30px;vertical-align:middle;" src="/assets/publications/2022_avqa/teaser.png" width="220" height="110" /> 
          </div>
        <div class="paper">
          <p class="title"><b>Learning to Answer Questions in Dynamic Audio-Visual Scenarios</b></p>
          <p>Guangyao Li<sup>‡</sup>, Yake Wei<sup>‡</sup>, <b>Yapeng Tian<sup>‡</sup></b>, Chenliang Xu, Ji-Rong Wen, and Di Hu</p>
          <p><i>CVPR'22 Oral: IEEE/CVF Conference on Computer Vision and Pattern Recognition. </i></p>
           
           <div class="paper-buttons">
            
              <a class="button" href="https://arxiv.org/pdf/2203.14072.pdf" target="_blank">Paper</a>
            

            

            

            
              <a class="button" href="https://www.youtube.com/watch?v=JH3t5gwe9Xw" target="_blank">Video</a>
            

            
              <a class="button" href="https://github.com/GeWu-Lab/MUSIC-AVQA" target="_blank">Code</a>
            

            

            
              <a class="button" href="https://gewu-lab.github.io/MUSIC-AVQA/" target="_blank">Project</a>
            
           </div>


        </div>
          </div>
      
    
        <div >
          <div class="figure">
            <img style="float:left;margin-bottom:20px;margin-right:30px;vertical-align:middle;" src="/assets/publications/2022_mrisr/teaser.png" width="220" height="110" /> 
          </div>
        <div class="paper">
          <p class="title"><b>Transformer-empowered Multi-contrast MRI Super-Resolution</b></p>
          <p>Guangyuan Li, Jun Lv, <b>Yapeng Tian</b>, Qi Dou, Chengyan Wang, Chenliang Xu, Jing Qin</p>
          <p><i>CVPR'22: IEEE/CVF Conference on Computer Vision and Pattern Recognition.</i></p>
           
           <div class="paper-buttons">
            
              <a class="button" href="https://arxiv.org/pdf/2203.13963.pdf" target="_blank">Paper</a>
            

            

            

            

            
              <a class="button" href="https://github.com/XAIMI-Lab/McMRSR" target="_blank">Code</a>
            

            

            
           </div>


        </div>
          </div>
      
    
        <div >
          <div class="figure">
            <img style="float:left;margin-bottom:20px;margin-right:30px;vertical-align:middle;" src="/assets/publications/2022_amsa/teaser.png" width="220" height="110" /> 
          </div>
        <div class="paper">
          <p class="title"><b>Coarse-to-Fine Embedded PatchMatch and Multi-Scale Dynamic Aggregation for Reference-based Super-Resolution</b></p>
          <p>Bin Xia, <b>Yapeng Tian</b>, Yucheng Hang, Wenming Yang, Qingmin Liao, Jie Zhou</p>
          <p><i>AAAI'22: The AAAI Conference on Artificial Intelligence.</i></p>
           
           <div class="paper-buttons">
            
              <a class="button" href="https://arxiv.org/pdf/2201.04358.pdf" target="_blank">Paper</a>
            

            

            

            

            
              <a class="button" href="https://github.com/Zj-BinXia/AMSA" target="_blank">Code</a>
            

            

            
           </div>


        </div>
          </div>
      
    
        <div >
          <div class="figure">
            <img style="float:left;margin-bottom:20px;margin-right:30px;vertical-align:middle;" src="/assets/publications/2022_enlca/teaser.png" width="220" height="110" /> 
          </div>
        <div class="paper">
          <p class="title"><b>Efficient Non-Local Contrastive Attention for Image Super-Resolution</b></p>
          <p>Bin Xia<sup>‡</sup>, Yucheng Hang<sup>‡</sup>, <b>Yapeng Tian</b>, Wenming Yang, Qingmin Liao, Jie Zhou</p>
          <p><i>AAAI'22: The AAAI Conference on Artificial Intelligence. </i></p>
           
           <div class="paper-buttons">
            
              <a class="button" href="https://arxiv.org/pdf/2201.03794.pdf" target="_blank">Paper</a>
            

            

            

            

            
              <a class="button" href="https://github.com/Zj-BinXia/ENLCA" target="_blank">Code</a>
            

            

            
           </div>


        </div>
          </div>
      
    
        <div >
          <div class="figure">
            <img style="float:left;margin-bottom:20px;margin-right:30px;vertical-align:middle;" src="/assets/publications/2021_stm/teaser.png" width="220" height="110" /> 
          </div>
        <div class="paper">
          <p class="title"><b>Space-Time Memory Network for Sounding Object Localization in Videos</b></p>
          <p>Sizhe Li<sup>‡</sup>, <b>Yapeng Tian<sup>‡</sup></b>, and Chenliang Xu</p>
          <p><i>BMVC'21: The British Machine Vision Conference. </i></p>
           
           <div class="paper-buttons">
            
              <a class="button" href="https://arxiv.org/pdf/2111.05526.pdf" target="_blank">Paper</a>
            

            

            

            

            
              <a class="button" href="https://github.com/lester0866/Space-Time-Memory-Network-for-Sounding-Object-Localization-in-Videos" target="_blank">Code</a>
            

            

            
              <a class="button" href="https://sites.google.com/view/bmvc2021stm" target="_blank">Project</a>
            
           </div>


        </div>
          </div>
      
    
        <div >
          <div class="figure">
            <img style="float:left;margin-bottom:20px;margin-right:30px;vertical-align:middle;" src="/assets/publications/2021_matting/teaser.png" width="220" height="110" /> 
          </div>
        <div class="paper">
          <p class="title"><b>Video Matting via Consistency-Regularized Graph Neural Networks</b></p>
          <p>Tiantian Wang, Sifei Liu, <b>Yapeng Tian</b>, Kai Li, and Ming-Hsuan Yang</p>
          <p><i>ICCV'21: IEEE/CVF International Conference on Computer Vision. </i></p>
           
           <div class="paper-buttons">
            
              <a class="button" href="https://faculty.ucmerced.edu/mhyang/papers/iccv2021_video_matting.pdf" target="_blank">Paper</a>
            

            

            

            

            
              <a class="button" href="https://github.com/TiantianWang/VideoMatting-CRGNN" target="_blank">Code</a>
            

            

            
           </div>


        </div>
          </div>
      
    
        <div >
          <div class="figure">
            <img style="float:left;margin-bottom:20px;margin-right:30px;vertical-align:middle;" src="/assets/publications/2021_robustness/teaser.png" width="220" height="110" /> 
          </div>
        <div class="paper">
          <p class="title"><b>Can audio-visual integration strengthen robustness under multimodal attacks?</b></p>
          <p><b>Yapeng Tian</b> and Chenliang Xu</p>
          <p><i>CVPR'21: IEEE/CVF Conference on Computer Vision and Pattern Recognition. </i></p>
           
           <div class="paper-buttons">
            
              <a class="button" href="https://arxiv.org/pdf/2104.02000.pdf" target="_blank">Paper</a>
            

            

            

            

            
              <a class="button" href="https://github.com/YapengTian/AV-Robustness-CVPR21" target="_blank">Code</a>
            

            

            
           </div>


        </div>
          </div>
      
    
        <div >
          <div class="figure">
            <img style="float:left;margin-bottom:20px;margin-right:30px;vertical-align:middle;" src="/assets/publications/2021_ccol/teaser.png" width="220" height="110" /> 
          </div>
        <div class="paper">
          <p class="title"><b>Cyclic Co-Learning of Sounding Object Visual Grounding and Sound Separation</b></p>
          <p><b>Yapeng Tian</b>, Di Hu, and Chenliang Xu</p>
          <p><i>CVPR'21: IEEE/CVF Conference on Computer Vision and Pattern Recognition.</i></p>
           
           <div class="paper-buttons">
            
              <a class="button" href="https://arxiv.org/pdf/2104.02026.pdf" target="_blank">Paper</a>
            

            

            

            

            
              <a class="button" href="https://github.com/YapengTian/CCOL-CVPR21" target="_blank">Code</a>
            

            

            
           </div>


        </div>
          </div>
      
    
        <div >
          <div class="figure">
            <img style="float:left;margin-bottom:20px;margin-right:30px;vertical-align:middle;" src="/assets/publications/2020_avvp/teaser.png" width="220" height="110" /> 
          </div>
        <div class="paper">
          <p class="title"><b>Unified Multisensory Perception: Weakly-Supervised Audio-Visual Video Parsing</b></p>
          <p><b>Yapeng Tian</b>, Dingzeyu Li, and Chenliang Xu</p>
          <p><i>ECCV'20 Spotlight: European Conference on Computer Vision.</i></p>
           
           <div class="paper-buttons">
            
              <a class="button" href="https://arxiv.org/pdf/2007.10558.pdf" target="_blank">Paper</a>
            

            

            

            

            
              <a class="button" href="https://github.com/YapengTian/AVVP-ECCV20" target="_blank">Code</a>
            

            
              <a class="button" href="https://github.com/YapengTian/AVVP-ECCV20" target="_blank">Data</a>
            

            
           </div>


        </div>
          </div>
      
    
        <div >
          <div class="figure">
            <img style="float:left;margin-bottom:20px;margin-right:30px;vertical-align:middle;" src="/assets/publications/2020_zsm/teaser.png" width="220" height="110" /> 
          </div>
        <div class="paper">
          <p class="title"><b>Zooming Slow-Mo: Fast and Accurate One-Stage Space-Time Video Super-Resolution</b></p>
          <p>Xiaoyu Xiang<sup>‡</sup>, <b>Yapeng Tian<sup>‡</sup></b>, Yulun Zhang, Yun Fu, Jan Allebach, and Chenliang Xu</p>
          <p><i>CVPR'20: IEEE/CVF Conference on Computer Vision and Pattern Recognition.</i></p>
           
           <div class="paper-buttons">
            
              <a class="button" href="https://arxiv.org/pdf/2002.11616.pdf" target="_blank">Paper</a>
            

            

            

            
              <a class="button" href="https://www.youtube.com/watch?v=8mgD8JxBOus" target="_blank">Video</a>
            

            
              <a class="button" href="https://github.com/Mukosame/Zooming-Slow-Mo-CVPR-2020" target="_blank">Code</a>
            

            

            
           </div>


        </div>
          </div>
      
    
        <div >
          <div class="figure">
            <img style="float:left;margin-bottom:20px;margin-right:30px;vertical-align:middle;" src="/assets/publications/2020_tdan/teaser.png" width="220" height="110" /> 
          </div>
        <div class="paper">
          <p class="title"><b>TDAN: Temporally Deformable Alignment Network for Video Super-Resolution</b></p>
          <p><b>Yapeng Tian</b>, Yulun Zhang, Yun Fu, and Chenliang Xu</p>
          <p><i>CVPR'20: IEEE/CVF Conference on Computer Vision and Pattern Recognition.</i></p>
          
          <p style="color:red">This is the first work that uses deformable alignment to address video restoration.</p>
         
           <div class="paper-buttons">
            
              <a class="button" href="https://openaccess.thecvf.com/content_CVPR_2020/papers/Tian_TDAN_Temporally-Deformable_Alignment_Network_for_Video_Super-Resolution_CVPR_2020_paper.pdf" target="_blank">Paper</a>
            

            

            

            
              <a class="button" href="https://www.youtube.com/watch?v=eZExENE50I0" target="_blank">Video</a>
            

            
              <a class="button" href="https://github.com/YapengTian/TDAN-VSR-CVPR-2020" target="_blank">Code</a>
            

            

            
           </div>


        </div>
          </div>
      
    
        <div >
          <div class="figure">
            <img style="float:left;margin-bottom:20px;margin-right:30px;vertical-align:middle;" src="/assets/publications/2020_dap/teaser.png" width="220" height="110" /> 
          </div>
        <div class="paper">
          <p class="title"><b>Deep Audio Prior</b></p>
          <p><b>Yapeng Tian</b>, Chenliang Xu, and Dingzeyu Li</p>
          <p><i>CVPRW'20: CVPR Workshops.</i></p>
           
           <div class="paper-buttons">
            
              <a class="button" href="https://arxiv.org/pdf/1912.10292v1.pdf" target="_blank">Paper</a>
            

            

            

            

            
              <a class="button" href="https://github.com/adobe/Deep-Audio-Prior" target="_blank">Code</a>
            

            

            
              <a class="button" href="https://opensource.adobe.com/Deep-Audio-Prior/" target="_blank">Project</a>
            
           </div>


        </div>
          </div>
      
    
        <div >
          <div class="figure">
            <img style="float:left;margin-bottom:20px;margin-right:30px;vertical-align:middle;" src="/assets/publications/2020_rdnpami/teaser.png" width="220" height="110" /> 
          </div>
        <div class="paper">
          <p class="title"><b>Residual Dense Network for Image Super-Resolution</b></p>
          <p>Yulun Zhang, <b>Yapeng Tian</b>, Yu Kong , Bineng Zhong, Yun Fu</p>
          <p><i>TPAMI'20: IEEE Transactions on Pattern Analysis and Machine Intelligence.</i></p>
           
           <div class="paper-buttons">
            
              <a class="button" href="https://arxiv.org/pdf/1812.10477.pdf" target="_blank">Paper</a>
            

            

            

            

            
              <a class="button" href="https://github.com/yulunzhang/RDN" target="_blank">Code</a>
            

            

            
           </div>


        </div>
          </div>
      
    
        <div >
          <div class="figure">
            <img style="float:left;margin-bottom:20px;margin-right:30px;vertical-align:middle;" src="/assets/publications/2019_csf/teaser.png" width="220" height="110" /> 
          </div>
        <div class="paper">
          <p class="title"><b>CFSNet: Toward a Controllable Feature Space for Image Restoration</b></p>
          <p>Wei Wang<sup>‡</sup>, Ruiming Guo<sup>‡</sup>, <b>Yapeng Tian</b>, and Wenming Yang</p>
          <p><i>ICCV'19: IEEE/CVF International Conference on Computer Vision.</i></p>
           
           <div class="paper-buttons">
            
              <a class="button" href="https://arxiv.org/pdf/1904.00634.pdf" target="_blank">Paper</a>
            

            

            

            

            
              <a class="button" href="https://github.com/qibao77/CFSNet" target="_blank">Code</a>
            

            

            
           </div>


        </div>
          </div>
      
    
        <div >
          <div class="figure">
            <img style="float:left;margin-bottom:20px;margin-right:30px;vertical-align:middle;" src="/assets/publications/2019_avc/teaser.png" width="220" height="110" /> 
          </div>
        <div class="paper">
          <p class="title"><b>Interpretable and Controllable Audio-Visual Video Captioning</b></p>
          <p><b>Yapeng Tian</b>, Chenxiao Guan, Goodman Justin, Marc Moore, and Chenliang Xu</p>
          <p><i>CVPRW'19: CVPR Workshops.</i></p>
          
          <p style="color:red">Multisensory interpretability in terms of the audio-visual video captioning task.</p>
         
           <div class="paper-buttons">
            
              <a class="button" href="https://openaccess.thecvf.com/content_CVPRW_2019/papers/Sight%20and%20Sound/Yapeng_Tian_Audio-Visual_Interpretable_and_Controllable_Video_Captioning_CVPRW_2019_paper.pdf" target="_blank">Paper</a>
            

            

            

            

            

            

            
           </div>


        </div>
          </div>
      
    
        <div >
          <div class="figure">
            <img style="float:left;margin-bottom:20px;margin-right:30px;vertical-align:middle;" src="/assets/publications/2019_lcsc/teaser.png" width="220" height="110" /> 
          </div>
        <div class="paper">
          <p class="title"><b>LCSCNet: Linear Compressing Based Skip-Connecting Network for ISR</b></p>
          <p>Wenming Yang, Xuechen Zhang, <b>Yapeng Tian</b>, Wei Wang, Jing-Hao Xue, Qingmin Liao</p>
          <p><i>TIP'19: IEEE Trans. Image Processing.</i></p>
           
           <div class="paper-buttons">
            
              <a class="button" href="https://arxiv.org/abs/1909.03573" target="_blank">Paper</a>
            

            

            

            

            

            

            
           </div>


        </div>
          </div>
      
    
        <div >
          <div class="figure">
            <img style="float:left;margin-bottom:20px;margin-right:30px;vertical-align:middle;" src="/assets/publications/2019_review/teaser.png" width="220" height="110" /> 
          </div>
        <div class="paper">
          <p class="title"><b>Deep Learning for Single Image Super-Resolution: A Brief Review</b></p>
          <p>Wenming Yang, Xuechen Zhang, <b>Yapeng Tian</b>, Wei Wang, JingHao Xue, Qingmin Liao</p>
          <p><i>TMM'19: IEEE Trans. Multimedia.</i></p>
           
           <div class="paper-buttons">
            
              <a class="button" href="https://arxiv.org/pdf/1808.03344.pdf" target="_blank">Paper</a>
            

            

            

            

            

            

            
           </div>


        </div>
          </div>
      
    
        <div >
          <div class="figure">
            <img style="float:left;margin-bottom:20px;margin-right:30px;vertical-align:middle;" src="/assets/publications/2018_ave/teaser.png" width="220" height="110" /> 
          </div>
        <div class="paper">
          <p class="title"><b>Audio-Visual Event Localization in Unconstrained Videos</b></p>
          <p><b>Yapeng Tian</b>, Jing Shi, Bochen Li, Zhiyao Duan, Chenliang Xu</p>
          <p><i>ECCV'18: European Conference on Computer Vision.</i></p>
           
           <div class="paper-buttons">
            
              <a class="button" href="https://openaccess.thecvf.com/content_ECCV_2018/papers/Yapeng_Tian_Audio-Visual_Event_Localization_ECCV_2018_paper.pdf" target="_blank">Paper</a>
            

            

            

            
              <a class="button" href="https://www.youtube.com/watch?v=m6r6BbD5MSc" target="_blank">Video</a>
            

            
              <a class="button" href="https://github.com/YapengTian/AVE-ECCV18" target="_blank">Code</a>
            

            
              <a class="button" href="https://drive.google.com/file/d/1FjKwe79e0u96vdjIVwfRQ1V6SoDHe7kK" target="_blank">Data</a>
            

            
              <a class="button" href="https://sites.google.com/view/audiovisualresearch" target="_blank">Project</a>
            
           </div>


        </div>
          </div>
      
    
        <div >
          <div class="figure">
            <img style="float:left;margin-bottom:20px;margin-right:30px;vertical-align:middle;" src="/assets/publications/2018_rdn/teaser.png" width="220" height="110" /> 
          </div>
        <div class="paper">
          <p class="title"><b>Residual Dense Network for Image Super-Resolution</b></p>
          <p>Yulun Zhang, <b>Yapeng Tian</b>, Yu Kong , Bineng Zhong, Yun Fu</p>
          <p><i>CVPR'18 Spotlight: IEEE/CVF Conf. on Computer Vision and Pattern Recognition.</i></p>
           
           <div class="paper-buttons">
            
              <a class="button" href="https://arxiv.org/pdf/1802.08797.pdf" target="_blank">Paper</a>
            

            

            

            

            
              <a class="button" href="https://github.com/yulunzhang/RDN" target="_blank">Code</a>
            

            

            
           </div>


        </div>
          </div>
      
    
        <div >
          <div class="figure">
            <img style="float:left;margin-bottom:20px;margin-right:30px;vertical-align:middle;" src="/assets/publications/2017_ntire/teaser.png" width="220" height="110" /> 
          </div>
        <div class="paper">
          <p class="title"><b>NTIRE 2017 Challenge on Single Image Super-Resolution: Methods and Results</b></p>
          <p>Timofte et al.</p>
          <p><i>CVPRW'17: CVPR Workshops.</i></p>
           
           <div class="paper-buttons">
            
              <a class="button" href="https://people.ee.ethz.ch/~timofter/publications/Timofte-CVPRW-2017.pdf" target="_blank">Paper</a>
            

            

            

            

            

            

            
           </div>


        </div>
          </div>
      
    
        <div >
          <div class="figure">
            <img style="float:left;margin-bottom:20px;margin-right:30px;vertical-align:middle;" src="/assets/publications/2016_ccs/teaser.png" width="220" height="110" /> 
          </div>
        <div class="paper">
          <p class="title"><b>Consistent Coding Scheme for Single-Image Super-Resolution</b></p>
          <p>Wenming Yang, <b>Yapeng Tian</b>, Fei Zhou, Qingmin Liao, Hai Chen, Chenglin Zheng</p>
          <p><i>TMM'16: EEE Trans. Multimedia. (First student author)</i></p>
           
           <div class="paper-buttons">
            
              <a class="button" href="https://drive.google.com/file/d/1MpEM5qmSJi1GtY9TftNNV0cgSHqMT_KQ/view" target="_blank">Paper</a>
            

            

            

            

            

            

            
           </div>


        </div>
          </div>
      
    
        <div >
          <div class="figure">
            <img style="float:left;margin-bottom:20px;margin-right:30px;vertical-align:middle;" src="/assets/publications/2016_anrse/teaser.png" width="220" height="110" /> 
          </div>
        <div class="paper">
          <p class="title"><b>Anchored Neighborhood Regression based SISR from Self-examples</b></p>
          <p><b>Yapeng Tian</b>, Fei Zhou, Wenming Yang, Xuesen Shang, Qingmin Liao</p>
          <p><i>ICIP'16: IEEE International Conference on Image Processing.</i></p>
           
           <div class="paper-buttons">
            
              <a class="button" href="https://drive.google.com/file/d/1Ts_gYIp57llzK53Wyt7hwu4lZ9GQsbis/view" target="_blank">Paper</a>
            

            

            

            

            
              <a class="button" href="https://github.com/YapengTian/ICIP2016" target="_blank">Code</a>
            

            

            
           </div>


        </div>
          </div>
      
    
        <div >
          <div class="figure">
            <img style="float:left;margin-bottom:20px;margin-right:30px;vertical-align:middle;" src="/assets/publications/2015_pfsr/teaser.png" width="220" height="110" /> 
          </div>
        <div class="paper">
          <p class="title"><b>SISR Using Clustering-Based Global Regression and Propagation Filtering</b></p>
          <p>Wenming Yang, <b>Yapeng Tian</b>, Fei Zhou, ..., Qingmin Liao</p>
          <p><i>ACPR'15 Oral: Asian Conference on Pattern Recognition. (First student author)</i></p>
           
           <div class="paper-buttons">
            
              <a class="button" href="https://drive.google.com/file/d/12tqTHt0aLn7-B1jEgEJBYY64uhwfEezA/view" target="_blank">Paper</a>
            

            

            

            

            

            

            
           </div>


        </div>
          </div>
      
    </div>


    <div class="tab-pane" id="papers-selected">
      
      
      <div >
        <div class="figure">
          <img style="float:left;margin-bottom:20px;margin-right:30px;vertical-align:middle;" class="hidden-xs hidden-sm hidden-md" src="/assets/publications/2023_avnerf/teaser.png" width="220" height="110" /> 
        </div>
      <div class="paper">
        <p class="title"><b>AV-NeRF: Learning Neural Fields for Real-World Audio-Visual Scene Synthesis</b></p>
        <p>Susan Liang, Chao Huang, <b>Yapeng Tian</b>, Anurag Kumar, Chenliang Xu</p>
        <p><i>Preprint'23. </i></p>
         
         <div class="paper-buttons">
          
            <a class="button" href="https://arxiv.org/pdf/2302.02088.pdf" target="_blank">Paper</a>
          

          

          

          

          

          

          
            <a class="button" href="https://liangsusan-git.github.io/project/avnerf/" target="_blank">Project</a>
          
         </div>


      </div>
        </div>
      
      <div >
        <div class="figure">
          <img style="float:left;margin-bottom:20px;margin-right:30px;vertical-align:middle;" class="hidden-xs hidden-sm hidden-md" src="/assets/publications/2022_avsurvey/teaser.png" width="220" height="110" /> 
        </div>
      <div class="paper">
        <p class="title"><b>Learning in Audio-visual Context: A Review, Analysis, and New Perspective</b></p>
        <p>Yake Wei, Di Hu, <b>Yapeng Tian</b>, Xuelong Li</p>
        <p><i>Preprint'22. </i></p>
         
         <div class="paper-buttons">
          
            <a class="button" href="https://arxiv.org/pdf/2208.09579.pdf" target="_blank">Paper</a>
          

          

          

          

          

          

          
            <a class="button" href="https://gewu-lab.github.io/audio-visual-learning/" target="_blank">Project</a>
          
         </div>


      </div>
        </div>
      
      <div >
        <div class="figure">
          <img style="float:left;margin-bottom:20px;margin-right:30px;vertical-align:middle;" class="hidden-xs hidden-sm hidden-md" src="/assets/publications/2023_aaainfh/teaser.png" width="220" height="110" /> 
        </div>
      <div class="paper">
        <p class="title"><b>Towards Unified, Explainable, and Robust Multisensory Perception</b></p>
        <p>Yapeng Tian</p>
        <p><i>AAAI'23: AAAI Conference on Artificial Intelligence. (NFH program)</i></p>
         
         <div class="paper-buttons">
          
            <a class="button" href="/assets/publications/2023_aaainfh/paper.pdf" target="_blank">Paper</a>
          

          

          

          

          

          

          
         </div>


      </div>
        </div>
      
      <div >
        <div class="figure">
          <img style="float:left;margin-bottom:20px;margin-right:30px;vertical-align:middle;" class="hidden-xs hidden-sm hidden-md" src="/assets/publications/2022_mgn/teaser.png" width="220" height="110" /> 
        </div>
      <div class="paper">
        <p class="title"><b>Multi-modal Grouping Network for Weakly-Supervised Audio-Visual Video Parsing</b></p>
        <p>Shentong Mo, <b>Yapeng Tian</b></p>
        <p><i>NeurIPS'22: The Annual Conference on Neural Information Processing Systems. </i></p>
         
         <div class="paper-buttons">
          
            <a class="button" href="https://openreview.net/pdf?id=zfo2LqFEVY" target="_blank">Paper</a>
          

          

          

          

          
            <a class="button" href="https://github.com/stoneMo/MGN" target="_blank">Code</a>
          

          

          
         </div>


      </div>
        </div>
      
      <div >
        <div class="figure">
          <img style="float:left;margin-bottom:20px;margin-right:30px;vertical-align:middle;" class="hidden-xs hidden-sm hidden-md" src="/assets/publications/2022_std/teaser.png" width="220" height="110" /> 
        </div>
      <div class="paper">
        <p class="title"><b>Learning Spatio-Temporal Downsampling for Effective Video Upscaling</b></p>
        <p>Xiaoyu Xiang, <b>Yapeng Tian</b>, Vijay Rengarajan, Lucas Young, Bo Zhu, Rakesh Ranjan</p>
        <p><i>ECCV'22: European Conference on Computer Vision. </i></p>
         
         <div class="paper-buttons">
          
            <a class="button" href="https://www.ecva.net/papers/eccv_2022/papers_ECCV/papers/136780159.pdf" target="_blank">Paper</a>
          

          

          

          

          

          

          
         </div>


      </div>
        </div>
      
      <div >
        <div class="figure">
          <img style="float:left;margin-bottom:20px;margin-right:30px;vertical-align:middle;" class="hidden-xs hidden-sm hidden-md" src="/assets/publications/2022_thesis/thesis.png" width="220" height="110" /> 
        </div>
      <div class="paper">
        <p class="title"><b>Audio-Visual Scene Understanding Towards Unified, Explainable, and Robust Multisensory Perception</b></p>
        <p><b>Yapeng Tian</b></p>
        <p><i>PhD Thesis </i></p>
         
         <div class="paper-buttons">
          
            <a class="button" href="https://www.proquest.com/openview/99bef5e8207df0ebab29e6b1f2afbad8/1.pdf?pq-origsite=gscholar&cbl=18750&diss=y" target="_blank">Paper</a>
          

          

          

          

          

          

          
         </div>


      </div>
        </div>
      
      <div >
        <div class="figure">
          <img style="float:left;margin-bottom:20px;margin-right:30px;vertical-align:middle;" class="hidden-xs hidden-sm hidden-md" src="/assets/publications/2022_avol/teaser.png" width="220" height="110" /> 
        </div>
      <div class="paper">
        <p class="title"><b>Audio-Visual Object Localization in Egocentric Videos</b></p>
        <p>Chao Huang, <b>Yapeng Tian</b>, Anurag Kumar, and Chenliang Xu</p>
        <p><i>CVPRW'22: CVPR Workshops</i></p>
        
        <p style="color:red">Egocentric audio-visual learning.</p>
       
         <div class="paper-buttons">
          
            <a class="button" href="https://sightsound.org/papers/2022/Huang_Audio-Visual_Object_Localization_in_Egocentric_Videos.pdf" target="_blank">Paper</a>
          

          

          

          

          

          

          
         </div>


      </div>
        </div>
      
      <div >
        <div class="figure">
          <img style="float:left;margin-bottom:20px;margin-right:30px;vertical-align:middle;" class="hidden-xs hidden-sm hidden-md" src="/assets/publications/2022_avqa/teaser.png" width="220" height="110" /> 
        </div>
      <div class="paper">
        <p class="title"><b>Learning to Answer Questions in Dynamic Audio-Visual Scenarios</b></p>
        <p>Guangyao Li<sup>‡</sup>, Yake Wei<sup>‡</sup>, <b>Yapeng Tian<sup>‡</sup></b>, Chenliang Xu, Ji-Rong Wen, and Di Hu</p>
        <p><i>CVPR'22 Oral: IEEE/CVF Conference on Computer Vision and Pattern Recognition. </i></p>
         
         <div class="paper-buttons">
          
            <a class="button" href="https://arxiv.org/pdf/2203.14072.pdf" target="_blank">Paper</a>
          

          

          

          
            <a class="button" href="https://www.youtube.com/watch?v=JH3t5gwe9Xw" target="_blank">Video</a>
          

          
            <a class="button" href="https://github.com/GeWu-Lab/MUSIC-AVQA" target="_blank">Code</a>
          

          

          
            <a class="button" href="https://gewu-lab.github.io/MUSIC-AVQA/" target="_blank">Project</a>
          
         </div>


      </div>
        </div>
      
      <div >
        <div class="figure">
          <img style="float:left;margin-bottom:20px;margin-right:30px;vertical-align:middle;" class="hidden-xs hidden-sm hidden-md" src="/assets/publications/2021_robustness/teaser.png" width="220" height="110" /> 
        </div>
      <div class="paper">
        <p class="title"><b>Can audio-visual integration strengthen robustness under multimodal attacks?</b></p>
        <p><b>Yapeng Tian</b> and Chenliang Xu</p>
        <p><i>CVPR'21: IEEE/CVF Conference on Computer Vision and Pattern Recognition. </i></p>
         
         <div class="paper-buttons">
          
            <a class="button" href="https://arxiv.org/pdf/2104.02000.pdf" target="_blank">Paper</a>
          

          

          

          

          
            <a class="button" href="https://github.com/YapengTian/AV-Robustness-CVPR21" target="_blank">Code</a>
          

          

          
         </div>


      </div>
        </div>
      
      <div >
        <div class="figure">
          <img style="float:left;margin-bottom:20px;margin-right:30px;vertical-align:middle;" class="hidden-xs hidden-sm hidden-md" src="/assets/publications/2021_ccol/teaser.png" width="220" height="110" /> 
        </div>
      <div class="paper">
        <p class="title"><b>Cyclic Co-Learning of Sounding Object Visual Grounding and Sound Separation</b></p>
        <p><b>Yapeng Tian</b>, Di Hu, and Chenliang Xu</p>
        <p><i>CVPR'21: IEEE/CVF Conference on Computer Vision and Pattern Recognition.</i></p>
         
         <div class="paper-buttons">
          
            <a class="button" href="https://arxiv.org/pdf/2104.02026.pdf" target="_blank">Paper</a>
          

          

          

          

          
            <a class="button" href="https://github.com/YapengTian/CCOL-CVPR21" target="_blank">Code</a>
          

          

          
         </div>


      </div>
        </div>
      
      <div >
        <div class="figure">
          <img style="float:left;margin-bottom:20px;margin-right:30px;vertical-align:middle;" class="hidden-xs hidden-sm hidden-md" src="/assets/publications/2020_avvp/teaser.png" width="220" height="110" /> 
        </div>
      <div class="paper">
        <p class="title"><b>Unified Multisensory Perception: Weakly-Supervised Audio-Visual Video Parsing</b></p>
        <p><b>Yapeng Tian</b>, Dingzeyu Li, and Chenliang Xu</p>
        <p><i>ECCV'20 Spotlight: European Conference on Computer Vision.</i></p>
         
         <div class="paper-buttons">
          
            <a class="button" href="https://arxiv.org/pdf/2007.10558.pdf" target="_blank">Paper</a>
          

          

          

          

          
            <a class="button" href="https://github.com/YapengTian/AVVP-ECCV20" target="_blank">Code</a>
          

          
            <a class="button" href="https://github.com/YapengTian/AVVP-ECCV20" target="_blank">Data</a>
          

          
         </div>


      </div>
        </div>
      
      <div >
        <div class="figure">
          <img style="float:left;margin-bottom:20px;margin-right:30px;vertical-align:middle;" class="hidden-xs hidden-sm hidden-md" src="/assets/publications/2020_zsm/teaser.png" width="220" height="110" /> 
        </div>
      <div class="paper">
        <p class="title"><b>Zooming Slow-Mo: Fast and Accurate One-Stage Space-Time Video Super-Resolution</b></p>
        <p>Xiaoyu Xiang<sup>‡</sup>, <b>Yapeng Tian<sup>‡</sup></b>, Yulun Zhang, Yun Fu, Jan Allebach, and Chenliang Xu</p>
        <p><i>CVPR'20: IEEE/CVF Conference on Computer Vision and Pattern Recognition.</i></p>
         
         <div class="paper-buttons">
          
            <a class="button" href="https://arxiv.org/pdf/2002.11616.pdf" target="_blank">Paper</a>
          

          

          

          
            <a class="button" href="https://www.youtube.com/watch?v=8mgD8JxBOus" target="_blank">Video</a>
          

          
            <a class="button" href="https://github.com/Mukosame/Zooming-Slow-Mo-CVPR-2020" target="_blank">Code</a>
          

          

          
         </div>


      </div>
        </div>
      
      <div >
        <div class="figure">
          <img style="float:left;margin-bottom:20px;margin-right:30px;vertical-align:middle;" class="hidden-xs hidden-sm hidden-md" src="/assets/publications/2020_tdan/teaser.png" width="220" height="110" /> 
        </div>
      <div class="paper">
        <p class="title"><b>TDAN: Temporally Deformable Alignment Network for Video Super-Resolution</b></p>
        <p><b>Yapeng Tian</b>, Yulun Zhang, Yun Fu, and Chenliang Xu</p>
        <p><i>CVPR'20: IEEE/CVF Conference on Computer Vision and Pattern Recognition.</i></p>
        
        <p style="color:red">This is the first work that uses deformable alignment to address video restoration.</p>
       
         <div class="paper-buttons">
          
            <a class="button" href="https://openaccess.thecvf.com/content_CVPR_2020/papers/Tian_TDAN_Temporally-Deformable_Alignment_Network_for_Video_Super-Resolution_CVPR_2020_paper.pdf" target="_blank">Paper</a>
          

          

          

          
            <a class="button" href="https://www.youtube.com/watch?v=eZExENE50I0" target="_blank">Video</a>
          

          
            <a class="button" href="https://github.com/YapengTian/TDAN-VSR-CVPR-2020" target="_blank">Code</a>
          

          

          
         </div>


      </div>
        </div>
      
      <div >
        <div class="figure">
          <img style="float:left;margin-bottom:20px;margin-right:30px;vertical-align:middle;" class="hidden-xs hidden-sm hidden-md" src="/assets/publications/2020_dap/teaser.png" width="220" height="110" /> 
        </div>
      <div class="paper">
        <p class="title"><b>Deep Audio Prior</b></p>
        <p><b>Yapeng Tian</b>, Chenliang Xu, and Dingzeyu Li</p>
        <p><i>CVPRW'20: CVPR Workshops.</i></p>
         
         <div class="paper-buttons">
          
            <a class="button" href="https://arxiv.org/pdf/1912.10292v1.pdf" target="_blank">Paper</a>
          

          

          

          

          
            <a class="button" href="https://github.com/adobe/Deep-Audio-Prior" target="_blank">Code</a>
          

          

          
            <a class="button" href="https://opensource.adobe.com/Deep-Audio-Prior/" target="_blank">Project</a>
          
         </div>


      </div>
        </div>
      
      <div >
        <div class="figure">
          <img style="float:left;margin-bottom:20px;margin-right:30px;vertical-align:middle;" class="hidden-xs hidden-sm hidden-md" src="/assets/publications/2019_avc/teaser.png" width="220" height="110" /> 
        </div>
      <div class="paper">
        <p class="title"><b>Interpretable and Controllable Audio-Visual Video Captioning</b></p>
        <p><b>Yapeng Tian</b>, Chenxiao Guan, Goodman Justin, Marc Moore, and Chenliang Xu</p>
        <p><i>CVPRW'19: CVPR Workshops.</i></p>
        
        <p style="color:red">Multisensory interpretability in terms of the audio-visual video captioning task.</p>
       
         <div class="paper-buttons">
          
            <a class="button" href="https://openaccess.thecvf.com/content_CVPRW_2019/papers/Sight%20and%20Sound/Yapeng_Tian_Audio-Visual_Interpretable_and_Controllable_Video_Captioning_CVPRW_2019_paper.pdf" target="_blank">Paper</a>
          

          

          

          

          

          

          
         </div>


      </div>
        </div>
      
      <div >
        <div class="figure">
          <img style="float:left;margin-bottom:20px;margin-right:30px;vertical-align:middle;" class="hidden-xs hidden-sm hidden-md" src="/assets/publications/2018_ave/teaser.png" width="220" height="110" /> 
        </div>
      <div class="paper">
        <p class="title"><b>Audio-Visual Event Localization in Unconstrained Videos</b></p>
        <p><b>Yapeng Tian</b>, Jing Shi, Bochen Li, Zhiyao Duan, Chenliang Xu</p>
        <p><i>ECCV'18: European Conference on Computer Vision.</i></p>
         
         <div class="paper-buttons">
          
            <a class="button" href="https://openaccess.thecvf.com/content_ECCV_2018/papers/Yapeng_Tian_Audio-Visual_Event_Localization_ECCV_2018_paper.pdf" target="_blank">Paper</a>
          

          

          

          
            <a class="button" href="https://www.youtube.com/watch?v=m6r6BbD5MSc" target="_blank">Video</a>
          

          
            <a class="button" href="https://github.com/YapengTian/AVE-ECCV18" target="_blank">Code</a>
          

          
            <a class="button" href="https://drive.google.com/file/d/1FjKwe79e0u96vdjIVwfRQ1V6SoDHe7kK" target="_blank">Data</a>
          

          
            <a class="button" href="https://sites.google.com/view/audiovisualresearch" target="_blank">Project</a>
          
         </div>


      </div>
        </div>
      
    </div>


    <div class="tab-pane" id="papers-audiovisual">
      
      
      <div >
        <div class="figure">
          <img style="float:left;margin-bottom:20px;margin-right:30px;vertical-align:middle;" class="hidden-xs hidden-sm hidden-md" src="/assets/publications/2023_avnerf/teaser.png" width="220" height="110" /> 
        </div>
      <div class="paper">
        <p class="title"><b>AV-NeRF: Learning Neural Fields for Real-World Audio-Visual Scene Synthesis</b></p>
        <p>Susan Liang, Chao Huang, <b>Yapeng Tian</b>, Anurag Kumar, Chenliang Xu</p>
        <p><i>Preprint'23. </i></p>
         
         <div class="paper-buttons">
          
            <a class="button" href="https://arxiv.org/pdf/2302.02088.pdf" target="_blank">Paper</a>
          

          

          

          

          

          

          
            <a class="button" href="https://liangsusan-git.github.io/project/avnerf/" target="_blank">Project</a>
          
         </div>


      </div>
        </div>
      
      <div >
        <div class="figure">
          <img style="float:left;margin-bottom:20px;margin-right:30px;vertical-align:middle;" class="hidden-xs hidden-sm hidden-md" src="/assets/publications/2022_avsurvey/teaser.png" width="220" height="110" /> 
        </div>
      <div class="paper">
        <p class="title"><b>Learning in Audio-visual Context: A Review, Analysis, and New Perspective</b></p>
        <p>Yake Wei, Di Hu, <b>Yapeng Tian</b>, Xuelong Li</p>
        <p><i>Preprint'22. </i></p>
         
         <div class="paper-buttons">
          
            <a class="button" href="https://arxiv.org/pdf/2208.09579.pdf" target="_blank">Paper</a>
          

          

          

          

          

          

          
            <a class="button" href="https://gewu-lab.github.io/audio-visual-learning/" target="_blank">Project</a>
          
         </div>


      </div>
        </div>
      
      <div >
        <div class="figure">
          <img style="float:left;margin-bottom:20px;margin-right:30px;vertical-align:middle;" class="hidden-xs hidden-sm hidden-md" src="/assets/publications/2023_aaainfh/teaser.png" width="220" height="110" /> 
        </div>
      <div class="paper">
        <p class="title"><b>Towards Unified, Explainable, and Robust Multisensory Perception</b></p>
        <p>Yapeng Tian</p>
        <p><i>AAAI'23: AAAI Conference on Artificial Intelligence. (NFH program)</i></p>
         
         <div class="paper-buttons">
          
            <a class="button" href="/assets/publications/2023_aaainfh/paper.pdf" target="_blank">Paper</a>
          

          

          

          

          

          

          
         </div>


      </div>
        </div>
      
      <div >
        <div class="figure">
          <img style="float:left;margin-bottom:20px;margin-right:30px;vertical-align:middle;" class="hidden-xs hidden-sm hidden-md" src="/assets/publications/2022_mgn/teaser.png" width="220" height="110" /> 
        </div>
      <div class="paper">
        <p class="title"><b>Multi-modal Grouping Network for Weakly-Supervised Audio-Visual Video Parsing</b></p>
        <p>Shentong Mo, <b>Yapeng Tian</b></p>
        <p><i>NeurIPS'22: The Annual Conference on Neural Information Processing Systems. </i></p>
         
         <div class="paper-buttons">
          
            <a class="button" href="https://openreview.net/pdf?id=zfo2LqFEVY" target="_blank">Paper</a>
          

          

          

          

          
            <a class="button" href="https://github.com/stoneMo/MGN" target="_blank">Code</a>
          

          

          
         </div>


      </div>
        </div>
      
      <div >
        <div class="figure">
          <img style="float:left;margin-bottom:20px;margin-right:30px;vertical-align:middle;" class="hidden-xs hidden-sm hidden-md" src="/assets/publications/2022_thesis/thesis.png" width="220" height="110" /> 
        </div>
      <div class="paper">
        <p class="title"><b>Audio-Visual Scene Understanding Towards Unified, Explainable, and Robust Multisensory Perception</b></p>
        <p><b>Yapeng Tian</b></p>
        <p><i>PhD Thesis </i></p>
         
         <div class="paper-buttons">
          
            <a class="button" href="https://www.proquest.com/openview/99bef5e8207df0ebab29e6b1f2afbad8/1.pdf?pq-origsite=gscholar&cbl=18750&diss=y" target="_blank">Paper</a>
          

          

          

          

          

          

          
         </div>


      </div>
        </div>
      
      <div >
        <div class="figure">
          <img style="float:left;margin-bottom:20px;margin-right:30px;vertical-align:middle;" class="hidden-xs hidden-sm hidden-md" src="/assets/publications/2022_avol/teaser.png" width="220" height="110" /> 
        </div>
      <div class="paper">
        <p class="title"><b>Audio-Visual Object Localization in Egocentric Videos</b></p>
        <p>Chao Huang, <b>Yapeng Tian</b>, Anurag Kumar, and Chenliang Xu</p>
        <p><i>CVPRW'22: CVPR Workshops</i></p>
        
        <p style="color:red">Egocentric audio-visual learning.</p>
       
         <div class="paper-buttons">
          
            <a class="button" href="https://sightsound.org/papers/2022/Huang_Audio-Visual_Object_Localization_in_Egocentric_Videos.pdf" target="_blank">Paper</a>
          

          

          

          

          

          

          
         </div>


      </div>
        </div>
      
      <div >
        <div class="figure">
          <img style="float:left;margin-bottom:20px;margin-right:30px;vertical-align:middle;" class="hidden-xs hidden-sm hidden-md" src="/assets/publications/2022_avqa/teaser.png" width="220" height="110" /> 
        </div>
      <div class="paper">
        <p class="title"><b>Learning to Answer Questions in Dynamic Audio-Visual Scenarios</b></p>
        <p>Guangyao Li<sup>‡</sup>, Yake Wei<sup>‡</sup>, <b>Yapeng Tian<sup>‡</sup></b>, Chenliang Xu, Ji-Rong Wen, and Di Hu</p>
        <p><i>CVPR'22 Oral: IEEE/CVF Conference on Computer Vision and Pattern Recognition. </i></p>
         
         <div class="paper-buttons">
          
            <a class="button" href="https://arxiv.org/pdf/2203.14072.pdf" target="_blank">Paper</a>
          

          

          

          
            <a class="button" href="https://www.youtube.com/watch?v=JH3t5gwe9Xw" target="_blank">Video</a>
          

          
            <a class="button" href="https://github.com/GeWu-Lab/MUSIC-AVQA" target="_blank">Code</a>
          

          

          
            <a class="button" href="https://gewu-lab.github.io/MUSIC-AVQA/" target="_blank">Project</a>
          
         </div>


      </div>
        </div>
      
      <div >
        <div class="figure">
          <img style="float:left;margin-bottom:20px;margin-right:30px;vertical-align:middle;" class="hidden-xs hidden-sm hidden-md" src="/assets/publications/2021_stm/teaser.png" width="220" height="110" /> 
        </div>
      <div class="paper">
        <p class="title"><b>Space-Time Memory Network for Sounding Object Localization in Videos</b></p>
        <p>Sizhe Li<sup>‡</sup>, <b>Yapeng Tian<sup>‡</sup></b>, and Chenliang Xu</p>
        <p><i>BMVC'21: The British Machine Vision Conference. </i></p>
         
         <div class="paper-buttons">
          
            <a class="button" href="https://arxiv.org/pdf/2111.05526.pdf" target="_blank">Paper</a>
          

          

          

          

          
            <a class="button" href="https://github.com/lester0866/Space-Time-Memory-Network-for-Sounding-Object-Localization-in-Videos" target="_blank">Code</a>
          

          

          
            <a class="button" href="https://sites.google.com/view/bmvc2021stm" target="_blank">Project</a>
          
         </div>


      </div>
        </div>
      
      <div >
        <div class="figure">
          <img style="float:left;margin-bottom:20px;margin-right:30px;vertical-align:middle;" class="hidden-xs hidden-sm hidden-md" src="/assets/publications/2021_robustness/teaser.png" width="220" height="110" /> 
        </div>
      <div class="paper">
        <p class="title"><b>Can audio-visual integration strengthen robustness under multimodal attacks?</b></p>
        <p><b>Yapeng Tian</b> and Chenliang Xu</p>
        <p><i>CVPR'21: IEEE/CVF Conference on Computer Vision and Pattern Recognition. </i></p>
         
         <div class="paper-buttons">
          
            <a class="button" href="https://arxiv.org/pdf/2104.02000.pdf" target="_blank">Paper</a>
          

          

          

          

          
            <a class="button" href="https://github.com/YapengTian/AV-Robustness-CVPR21" target="_blank">Code</a>
          

          

          
         </div>


      </div>
        </div>
      
      <div >
        <div class="figure">
          <img style="float:left;margin-bottom:20px;margin-right:30px;vertical-align:middle;" class="hidden-xs hidden-sm hidden-md" src="/assets/publications/2021_ccol/teaser.png" width="220" height="110" /> 
        </div>
      <div class="paper">
        <p class="title"><b>Cyclic Co-Learning of Sounding Object Visual Grounding and Sound Separation</b></p>
        <p><b>Yapeng Tian</b>, Di Hu, and Chenliang Xu</p>
        <p><i>CVPR'21: IEEE/CVF Conference on Computer Vision and Pattern Recognition.</i></p>
         
         <div class="paper-buttons">
          
            <a class="button" href="https://arxiv.org/pdf/2104.02026.pdf" target="_blank">Paper</a>
          

          

          

          

          
            <a class="button" href="https://github.com/YapengTian/CCOL-CVPR21" target="_blank">Code</a>
          

          

          
         </div>


      </div>
        </div>
      
      <div >
        <div class="figure">
          <img style="float:left;margin-bottom:20px;margin-right:30px;vertical-align:middle;" class="hidden-xs hidden-sm hidden-md" src="/assets/publications/2020_avvp/teaser.png" width="220" height="110" /> 
        </div>
      <div class="paper">
        <p class="title"><b>Unified Multisensory Perception: Weakly-Supervised Audio-Visual Video Parsing</b></p>
        <p><b>Yapeng Tian</b>, Dingzeyu Li, and Chenliang Xu</p>
        <p><i>ECCV'20 Spotlight: European Conference on Computer Vision.</i></p>
         
         <div class="paper-buttons">
          
            <a class="button" href="https://arxiv.org/pdf/2007.10558.pdf" target="_blank">Paper</a>
          

          

          

          

          
            <a class="button" href="https://github.com/YapengTian/AVVP-ECCV20" target="_blank">Code</a>
          

          
            <a class="button" href="https://github.com/YapengTian/AVVP-ECCV20" target="_blank">Data</a>
          

          
         </div>


      </div>
        </div>
      
      <div >
        <div class="figure">
          <img style="float:left;margin-bottom:20px;margin-right:30px;vertical-align:middle;" class="hidden-xs hidden-sm hidden-md" src="/assets/publications/2020_dap/teaser.png" width="220" height="110" /> 
        </div>
      <div class="paper">
        <p class="title"><b>Deep Audio Prior</b></p>
        <p><b>Yapeng Tian</b>, Chenliang Xu, and Dingzeyu Li</p>
        <p><i>CVPRW'20: CVPR Workshops.</i></p>
         
         <div class="paper-buttons">
          
            <a class="button" href="https://arxiv.org/pdf/1912.10292v1.pdf" target="_blank">Paper</a>
          

          

          

          

          
            <a class="button" href="https://github.com/adobe/Deep-Audio-Prior" target="_blank">Code</a>
          

          

          
            <a class="button" href="https://opensource.adobe.com/Deep-Audio-Prior/" target="_blank">Project</a>
          
         </div>


      </div>
        </div>
      
      <div >
        <div class="figure">
          <img style="float:left;margin-bottom:20px;margin-right:30px;vertical-align:middle;" class="hidden-xs hidden-sm hidden-md" src="/assets/publications/2019_avc/teaser.png" width="220" height="110" /> 
        </div>
      <div class="paper">
        <p class="title"><b>Interpretable and Controllable Audio-Visual Video Captioning</b></p>
        <p><b>Yapeng Tian</b>, Chenxiao Guan, Goodman Justin, Marc Moore, and Chenliang Xu</p>
        <p><i>CVPRW'19: CVPR Workshops.</i></p>
        
        <p style="color:red">Multisensory interpretability in terms of the audio-visual video captioning task.</p>
       
         <div class="paper-buttons">
          
            <a class="button" href="https://openaccess.thecvf.com/content_CVPRW_2019/papers/Sight%20and%20Sound/Yapeng_Tian_Audio-Visual_Interpretable_and_Controllable_Video_Captioning_CVPRW_2019_paper.pdf" target="_blank">Paper</a>
          

          

          

          

          

          

          
         </div>


      </div>
        </div>
      
      <div >
        <div class="figure">
          <img style="float:left;margin-bottom:20px;margin-right:30px;vertical-align:middle;" class="hidden-xs hidden-sm hidden-md" src="/assets/publications/2018_ave/teaser.png" width="220" height="110" /> 
        </div>
      <div class="paper">
        <p class="title"><b>Audio-Visual Event Localization in Unconstrained Videos</b></p>
        <p><b>Yapeng Tian</b>, Jing Shi, Bochen Li, Zhiyao Duan, Chenliang Xu</p>
        <p><i>ECCV'18: European Conference on Computer Vision.</i></p>
         
         <div class="paper-buttons">
          
            <a class="button" href="https://openaccess.thecvf.com/content_ECCV_2018/papers/Yapeng_Tian_Audio-Visual_Event_Localization_ECCV_2018_paper.pdf" target="_blank">Paper</a>
          

          

          

          
            <a class="button" href="https://www.youtube.com/watch?v=m6r6BbD5MSc" target="_blank">Video</a>
          

          
            <a class="button" href="https://github.com/YapengTian/AVE-ECCV18" target="_blank">Code</a>
          

          
            <a class="button" href="https://drive.google.com/file/d/1FjKwe79e0u96vdjIVwfRQ1V6SoDHe7kK" target="_blank">Data</a>
          

          
            <a class="button" href="https://sites.google.com/view/audiovisualresearch" target="_blank">Project</a>
          
         </div>


      </div>
        </div>
      
    </div>



    <div class="tab-pane" id="papers-videorestoration">
      
      
      <div >
        <div class="figure">
          <img style="float:left;margin-bottom:20px;margin-right:30px;vertical-align:middle;" class="hidden-xs hidden-sm hidden-md" src="/assets/publications/2022_std/teaser.png" width="220" height="110" /> 
        </div>
      <div class="paper">
        <p class="title"><b>Learning Spatio-Temporal Downsampling for Effective Video Upscaling</b></p>
        <p>Xiaoyu Xiang, <b>Yapeng Tian</b>, Vijay Rengarajan, Lucas Young, Bo Zhu, Rakesh Ranjan</p>
        <p><i>ECCV'22: European Conference on Computer Vision. </i></p>
         
         <div class="paper-buttons">
          
            <a class="button" href="https://www.ecva.net/papers/eccv_2022/papers_ECCV/papers/136780159.pdf" target="_blank">Paper</a>
          

          

          

          

          

          

          
         </div>


      </div>
        </div>
      
      <div >
        <div class="figure">
          <img style="float:left;margin-bottom:20px;margin-right:30px;vertical-align:middle;" class="hidden-xs hidden-sm hidden-md" src="/assets/publications/2021_matting/teaser.png" width="220" height="110" /> 
        </div>
      <div class="paper">
        <p class="title"><b>Video Matting via Consistency-Regularized Graph Neural Networks</b></p>
        <p>Tiantian Wang, Sifei Liu, <b>Yapeng Tian</b>, Kai Li, and Ming-Hsuan Yang</p>
        <p><i>ICCV'21: IEEE/CVF International Conference on Computer Vision. </i></p>
         
         <div class="paper-buttons">
          
            <a class="button" href="https://faculty.ucmerced.edu/mhyang/papers/iccv2021_video_matting.pdf" target="_blank">Paper</a>
          

          

          

          

          
            <a class="button" href="https://github.com/TiantianWang/VideoMatting-CRGNN" target="_blank">Code</a>
          

          

          
         </div>


      </div>
        </div>
      
      <div >
        <div class="figure">
          <img style="float:left;margin-bottom:20px;margin-right:30px;vertical-align:middle;" class="hidden-xs hidden-sm hidden-md" src="/assets/publications/2020_zsm/teaser.png" width="220" height="110" /> 
        </div>
      <div class="paper">
        <p class="title"><b>Zooming Slow-Mo: Fast and Accurate One-Stage Space-Time Video Super-Resolution</b></p>
        <p>Xiaoyu Xiang<sup>‡</sup>, <b>Yapeng Tian<sup>‡</sup></b>, Yulun Zhang, Yun Fu, Jan Allebach, and Chenliang Xu</p>
        <p><i>CVPR'20: IEEE/CVF Conference on Computer Vision and Pattern Recognition.</i></p>
         
         <div class="paper-buttons">
          
            <a class="button" href="https://arxiv.org/pdf/2002.11616.pdf" target="_blank">Paper</a>
          

          

          

          
            <a class="button" href="https://www.youtube.com/watch?v=8mgD8JxBOus" target="_blank">Video</a>
          

          
            <a class="button" href="https://github.com/Mukosame/Zooming-Slow-Mo-CVPR-2020" target="_blank">Code</a>
          

          

          
         </div>


      </div>
        </div>
      
      <div >
        <div class="figure">
          <img style="float:left;margin-bottom:20px;margin-right:30px;vertical-align:middle;" class="hidden-xs hidden-sm hidden-md" src="/assets/publications/2020_tdan/teaser.png" width="220" height="110" /> 
        </div>
      <div class="paper">
        <p class="title"><b>TDAN: Temporally Deformable Alignment Network for Video Super-Resolution</b></p>
        <p><b>Yapeng Tian</b>, Yulun Zhang, Yun Fu, and Chenliang Xu</p>
        <p><i>CVPR'20: IEEE/CVF Conference on Computer Vision and Pattern Recognition.</i></p>
        
        <p style="color:red">This is the first work that uses deformable alignment to address video restoration.</p>
       
         <div class="paper-buttons">
          
            <a class="button" href="https://openaccess.thecvf.com/content_CVPR_2020/papers/Tian_TDAN_Temporally-Deformable_Alignment_Network_for_Video_Super-Resolution_CVPR_2020_paper.pdf" target="_blank">Paper</a>
          

          

          

          
            <a class="button" href="https://www.youtube.com/watch?v=eZExENE50I0" target="_blank">Video</a>
          

          
            <a class="button" href="https://github.com/YapengTian/TDAN-VSR-CVPR-2020" target="_blank">Code</a>
          

          

          
         </div>


      </div>
        </div>
      
    </div>



    <div class="tab-pane" id="papers-imagerestoration">
      
      
      <div >
        <div class="figure">
          <img style="float:left;margin-bottom:20px;margin-right:30px;vertical-align:middle;" class="hidden-xs hidden-sm hidden-md" src="/assets/publications/2023_iclrkd/teaser.png" width="220" height="110" /> 
        </div>
      <div class="paper">
        <p class="title"><b>Knowledge Distillation based Degradation Estimation for Blind Super-Resolution</b></p>
        <p>Bin Xia, Yulun Zhang, Yitong Wang, <b>Yapeng Tian</b>, Wenming Yang, Radu Timofte, Luc Van Gool</p>
        <p><i>ICLR'23: International Conference on Learning Representations.</i></p>
         
         <div class="paper-buttons">
          
            <a class="button" href="https://arxiv.org/abs/2211.16928" target="_blank">Paper</a>
          

          

          

          

          

          

          
         </div>


      </div>
        </div>
      
      <div >
        <div class="figure">
          <img style="float:left;margin-bottom:20px;margin-right:30px;vertical-align:middle;" class="hidden-xs hidden-sm hidden-md" src="/assets/publications/2023_iclrbbcu/teaser.png" width="220" height="110" /> 
        </div>
      <div class="paper">
        <p class="title"><b>Basic Binary Convolution Unit for Binarized Image Restoration Network</b></p>
        <p>Bin Xia, Yulun Zhang, Yitong Wang, <b>Yapeng Tian</b>, Wenming Yang, Radu Timofte, Luc Van Gool</p>
        <p><i>ICLR'23: International Conference on Learning Representations.</i></p>
         
         <div class="paper-buttons">
          
            <a class="button" href="https://arxiv.org/pdf/2210.00405.pdf" target="_blank">Paper</a>
          

          

          

          

          

          

          
         </div>


      </div>
        </div>
      
      <div >
        <div class="figure">
          <img style="float:left;margin-bottom:20px;margin-right:30px;vertical-align:middle;" class="hidden-xs hidden-sm hidden-md" src="/assets/publications/2022_dudocaf/teaser.png" width="220" height="110" /> 
        </div>
      <div class="paper">
        <p class="title"><b>DuDoCAF: Dual-Domain Cross-Attention Fusion with Recurrent Transformer for Fast Multi-contrast MR Imaging</b></p>
        <p>Jun Lyu, Bin Sui, Chengyan Wang, <b>Yapeng Tian</b>, Qi Dou, and Jing Qin</p>
        <p><i>MICCAI'22: Medical Image Computing and Computer Assisted Intervention. </i></p>
         
         <div class="paper-buttons">
          
            <a class="button" href="/assets/publications/2022_dudocaf/paper.pdf" target="_blank">Paper</a>
          

          

          

          

          

          

          
         </div>


      </div>
        </div>
      
      <div >
        <div class="figure">
          <img style="float:left;margin-bottom:20px;margin-right:30px;vertical-align:middle;" class="hidden-xs hidden-sm hidden-md" src="/assets/publications/2022_mrisr/teaser.png" width="220" height="110" /> 
        </div>
      <div class="paper">
        <p class="title"><b>Transformer-empowered Multi-contrast MRI Super-Resolution</b></p>
        <p>Guangyuan Li, Jun Lv, <b>Yapeng Tian</b>, Qi Dou, Chengyan Wang, Chenliang Xu, Jing Qin</p>
        <p><i>CVPR'22: IEEE/CVF Conference on Computer Vision and Pattern Recognition.</i></p>
         
         <div class="paper-buttons">
          
            <a class="button" href="https://arxiv.org/pdf/2203.13963.pdf" target="_blank">Paper</a>
          

          

          

          

          
            <a class="button" href="https://github.com/XAIMI-Lab/McMRSR" target="_blank">Code</a>
          

          

          
         </div>


      </div>
        </div>
      
      <div >
        <div class="figure">
          <img style="float:left;margin-bottom:20px;margin-right:30px;vertical-align:middle;" class="hidden-xs hidden-sm hidden-md" src="/assets/publications/2022_amsa/teaser.png" width="220" height="110" /> 
        </div>
      <div class="paper">
        <p class="title"><b>Coarse-to-Fine Embedded PatchMatch and Multi-Scale Dynamic Aggregation for Reference-based Super-Resolution</b></p>
        <p>Bin Xia, <b>Yapeng Tian</b>, Yucheng Hang, Wenming Yang, Qingmin Liao, Jie Zhou</p>
        <p><i>AAAI'22: The AAAI Conference on Artificial Intelligence.</i></p>
         
         <div class="paper-buttons">
          
            <a class="button" href="https://arxiv.org/pdf/2201.04358.pdf" target="_blank">Paper</a>
          

          

          

          

          
            <a class="button" href="https://github.com/Zj-BinXia/AMSA" target="_blank">Code</a>
          

          

          
         </div>


      </div>
        </div>
      
      <div >
        <div class="figure">
          <img style="float:left;margin-bottom:20px;margin-right:30px;vertical-align:middle;" class="hidden-xs hidden-sm hidden-md" src="/assets/publications/2022_enlca/teaser.png" width="220" height="110" /> 
        </div>
      <div class="paper">
        <p class="title"><b>Efficient Non-Local Contrastive Attention for Image Super-Resolution</b></p>
        <p>Bin Xia<sup>‡</sup>, Yucheng Hang<sup>‡</sup>, <b>Yapeng Tian</b>, Wenming Yang, Qingmin Liao, Jie Zhou</p>
        <p><i>AAAI'22: The AAAI Conference on Artificial Intelligence. </i></p>
         
         <div class="paper-buttons">
          
            <a class="button" href="https://arxiv.org/pdf/2201.03794.pdf" target="_blank">Paper</a>
          

          

          

          

          
            <a class="button" href="https://github.com/Zj-BinXia/ENLCA" target="_blank">Code</a>
          

          

          
         </div>


      </div>
        </div>
      
      <div >
        <div class="figure">
          <img style="float:left;margin-bottom:20px;margin-right:30px;vertical-align:middle;" class="hidden-xs hidden-sm hidden-md" src="/assets/publications/2020_rdnpami/teaser.png" width="220" height="110" /> 
        </div>
      <div class="paper">
        <p class="title"><b>Residual Dense Network for Image Super-Resolution</b></p>
        <p>Yulun Zhang, <b>Yapeng Tian</b>, Yu Kong , Bineng Zhong, Yun Fu</p>
        <p><i>TPAMI'20: IEEE Transactions on Pattern Analysis and Machine Intelligence.</i></p>
         
         <div class="paper-buttons">
          
            <a class="button" href="https://arxiv.org/pdf/1812.10477.pdf" target="_blank">Paper</a>
          

          

          

          

          
            <a class="button" href="https://github.com/yulunzhang/RDN" target="_blank">Code</a>
          

          

          
         </div>


      </div>
        </div>
      
      <div >
        <div class="figure">
          <img style="float:left;margin-bottom:20px;margin-right:30px;vertical-align:middle;" class="hidden-xs hidden-sm hidden-md" src="/assets/publications/2019_csf/teaser.png" width="220" height="110" /> 
        </div>
      <div class="paper">
        <p class="title"><b>CFSNet: Toward a Controllable Feature Space for Image Restoration</b></p>
        <p>Wei Wang<sup>‡</sup>, Ruiming Guo<sup>‡</sup>, <b>Yapeng Tian</b>, and Wenming Yang</p>
        <p><i>ICCV'19: IEEE/CVF International Conference on Computer Vision.</i></p>
         
         <div class="paper-buttons">
          
            <a class="button" href="https://arxiv.org/pdf/1904.00634.pdf" target="_blank">Paper</a>
          

          

          

          

          
            <a class="button" href="https://github.com/qibao77/CFSNet" target="_blank">Code</a>
          

          

          
         </div>


      </div>
        </div>
      
      <div >
        <div class="figure">
          <img style="float:left;margin-bottom:20px;margin-right:30px;vertical-align:middle;" class="hidden-xs hidden-sm hidden-md" src="/assets/publications/2019_lcsc/teaser.png" width="220" height="110" /> 
        </div>
      <div class="paper">
        <p class="title"><b>LCSCNet: Linear Compressing Based Skip-Connecting Network for ISR</b></p>
        <p>Wenming Yang, Xuechen Zhang, <b>Yapeng Tian</b>, Wei Wang, Jing-Hao Xue, Qingmin Liao</p>
        <p><i>TIP'19: IEEE Trans. Image Processing.</i></p>
         
         <div class="paper-buttons">
          
            <a class="button" href="https://arxiv.org/abs/1909.03573" target="_blank">Paper</a>
          

          

          

          

          

          

          
         </div>


      </div>
        </div>
      
      <div >
        <div class="figure">
          <img style="float:left;margin-bottom:20px;margin-right:30px;vertical-align:middle;" class="hidden-xs hidden-sm hidden-md" src="/assets/publications/2019_review/teaser.png" width="220" height="110" /> 
        </div>
      <div class="paper">
        <p class="title"><b>Deep Learning for Single Image Super-Resolution: A Brief Review</b></p>
        <p>Wenming Yang, Xuechen Zhang, <b>Yapeng Tian</b>, Wei Wang, JingHao Xue, Qingmin Liao</p>
        <p><i>TMM'19: IEEE Trans. Multimedia.</i></p>
         
         <div class="paper-buttons">
          
            <a class="button" href="https://arxiv.org/pdf/1808.03344.pdf" target="_blank">Paper</a>
          

          

          

          

          

          

          
         </div>


      </div>
        </div>
      
      <div >
        <div class="figure">
          <img style="float:left;margin-bottom:20px;margin-right:30px;vertical-align:middle;" class="hidden-xs hidden-sm hidden-md" src="/assets/publications/2018_rdn/teaser.png" width="220" height="110" /> 
        </div>
      <div class="paper">
        <p class="title"><b>Residual Dense Network for Image Super-Resolution</b></p>
        <p>Yulun Zhang, <b>Yapeng Tian</b>, Yu Kong , Bineng Zhong, Yun Fu</p>
        <p><i>CVPR'18 Spotlight: IEEE/CVF Conf. on Computer Vision and Pattern Recognition.</i></p>
         
         <div class="paper-buttons">
          
            <a class="button" href="https://arxiv.org/pdf/1802.08797.pdf" target="_blank">Paper</a>
          

          

          

          

          
            <a class="button" href="https://github.com/yulunzhang/RDN" target="_blank">Code</a>
          

          

          
         </div>


      </div>
        </div>
      
      <div >
        <div class="figure">
          <img style="float:left;margin-bottom:20px;margin-right:30px;vertical-align:middle;" class="hidden-xs hidden-sm hidden-md" src="/assets/publications/2017_ntire/teaser.png" width="220" height="110" /> 
        </div>
      <div class="paper">
        <p class="title"><b>NTIRE 2017 Challenge on Single Image Super-Resolution: Methods and Results</b></p>
        <p>Timofte et al.</p>
        <p><i>CVPRW'17: CVPR Workshops.</i></p>
         
         <div class="paper-buttons">
          
            <a class="button" href="https://people.ee.ethz.ch/~timofter/publications/Timofte-CVPRW-2017.pdf" target="_blank">Paper</a>
          

          

          

          

          

          

          
         </div>


      </div>
        </div>
      
      <div >
        <div class="figure">
          <img style="float:left;margin-bottom:20px;margin-right:30px;vertical-align:middle;" class="hidden-xs hidden-sm hidden-md" src="/assets/publications/2016_ccs/teaser.png" width="220" height="110" /> 
        </div>
      <div class="paper">
        <p class="title"><b>Consistent Coding Scheme for Single-Image Super-Resolution</b></p>
        <p>Wenming Yang, <b>Yapeng Tian</b>, Fei Zhou, Qingmin Liao, Hai Chen, Chenglin Zheng</p>
        <p><i>TMM'16: EEE Trans. Multimedia. (First student author)</i></p>
         
         <div class="paper-buttons">
          
            <a class="button" href="https://drive.google.com/file/d/1MpEM5qmSJi1GtY9TftNNV0cgSHqMT_KQ/view" target="_blank">Paper</a>
          

          

          

          

          

          

          
         </div>


      </div>
        </div>
      
      <div >
        <div class="figure">
          <img style="float:left;margin-bottom:20px;margin-right:30px;vertical-align:middle;" class="hidden-xs hidden-sm hidden-md" src="/assets/publications/2016_anrse/teaser.png" width="220" height="110" /> 
        </div>
      <div class="paper">
        <p class="title"><b>Anchored Neighborhood Regression based SISR from Self-examples</b></p>
        <p><b>Yapeng Tian</b>, Fei Zhou, Wenming Yang, Xuesen Shang, Qingmin Liao</p>
        <p><i>ICIP'16: IEEE International Conference on Image Processing.</i></p>
         
         <div class="paper-buttons">
          
            <a class="button" href="https://drive.google.com/file/d/1Ts_gYIp57llzK53Wyt7hwu4lZ9GQsbis/view" target="_blank">Paper</a>
          

          

          

          

          
            <a class="button" href="https://github.com/YapengTian/ICIP2016" target="_blank">Code</a>
          

          

          
         </div>


      </div>
        </div>
      
      <div >
        <div class="figure">
          <img style="float:left;margin-bottom:20px;margin-right:30px;vertical-align:middle;" class="hidden-xs hidden-sm hidden-md" src="/assets/publications/2015_pfsr/teaser.png" width="220" height="110" /> 
        </div>
      <div class="paper">
        <p class="title"><b>SISR Using Clustering-Based Global Regression and Propagation Filtering</b></p>
        <p>Wenming Yang, <b>Yapeng Tian</b>, Fei Zhou, ..., Qingmin Liao</p>
        <p><i>ACPR'15 Oral: Asian Conference on Pattern Recognition. (First student author)</i></p>
         
         <div class="paper-buttons">
          
            <a class="button" href="https://drive.google.com/file/d/12tqTHt0aLn7-B1jEgEJBYY64uhwfEezA/view" target="_blank">Paper</a>
          

          

          

          

          

          

          
         </div>


      </div>
        </div>
      
    </div>


    <!-- <div class="tab-pane active" id="papers-all">
      
      
        <div class="paper">
          <p class="title"><b>AV-NeRF: Learning Neural Fields for Real-World Audio-Visual Scene Synthesis</b></p>
          <p>Susan Liang, Chao Huang, <b>Yapeng Tian</b>, Anurag Kumar, Chenliang Xu</p>
          <p><i>Preprint'23. </i></p>
           
           <div class="paper-buttons">
            
              <a class="button" href="https://arxiv.org/pdf/2302.02088.pdf" target="_blank">Paper</a>
            

            

            

            

            

            

            
              <a class="button" href="https://liangsusan-git.github.io/project/avnerf/" target="_blank">Project</a>
            

          </div>
        </div>
      
        <div class="paper">
          <p class="title"><b>Learning in Audio-visual Context: A Review, Analysis, and New Perspective</b></p>
          <p>Yake Wei, Di Hu, <b>Yapeng Tian</b>, Xuelong Li</p>
          <p><i>Preprint'22. </i></p>
           
           <div class="paper-buttons">
            
              <a class="button" href="https://arxiv.org/pdf/2208.09579.pdf" target="_blank">Paper</a>
            

            

            

            

            

            

            
              <a class="button" href="https://gewu-lab.github.io/audio-visual-learning/" target="_blank">Project</a>
            

          </div>
        </div>
      
        <div class="paper">
          <p class="title"><b>Knowledge Distillation based Degradation Estimation for Blind Super-Resolution</b></p>
          <p>Bin Xia, Yulun Zhang, Yitong Wang, <b>Yapeng Tian</b>, Wenming Yang, Radu Timofte, Luc Van Gool</p>
          <p><i>ICLR'23: International Conference on Learning Representations.</i></p>
           
           <div class="paper-buttons">
            
              <a class="button" href="https://arxiv.org/abs/2211.16928" target="_blank">Paper</a>
            

            

            

            

            

            

            

          </div>
        </div>
      
        <div class="paper">
          <p class="title"><b>Basic Binary Convolution Unit for Binarized Image Restoration Network</b></p>
          <p>Bin Xia, Yulun Zhang, Yitong Wang, <b>Yapeng Tian</b>, Wenming Yang, Radu Timofte, Luc Van Gool</p>
          <p><i>ICLR'23: International Conference on Learning Representations.</i></p>
           
           <div class="paper-buttons">
            
              <a class="button" href="https://arxiv.org/pdf/2210.00405.pdf" target="_blank">Paper</a>
            

            

            

            

            

            

            

          </div>
        </div>
      
        <div class="paper">
          <p class="title"><b>Towards Unified, Explainable, and Robust Multisensory Perception</b></p>
          <p>Yapeng Tian</p>
          <p><i>AAAI'23: AAAI Conference on Artificial Intelligence. (NFH program)</i></p>
           
           <div class="paper-buttons">
            
              <a class="button" href="/assets/publications/2023_aaainfh/paper.pdf" target="_blank">Paper</a>
            

            

            

            

            

            

            

          </div>
        </div>
      
        <div class="paper">
          <p class="title"><b>Multi-modal Grouping Network for Weakly-Supervised Audio-Visual Video Parsing</b></p>
          <p>Shentong Mo, <b>Yapeng Tian</b></p>
          <p><i>NeurIPS'22: The Annual Conference on Neural Information Processing Systems. </i></p>
           
           <div class="paper-buttons">
            
              <a class="button" href="https://openreview.net/pdf?id=zfo2LqFEVY" target="_blank">Paper</a>
            

            

            

            

            
              <a class="button" href="https://github.com/stoneMo/MGN" target="_blank">Code</a>
            

            

            

          </div>
        </div>
      
        <div class="paper">
          <p class="title"><b>Learning Spatio-Temporal Downsampling for Effective Video Upscaling</b></p>
          <p>Xiaoyu Xiang, <b>Yapeng Tian</b>, Vijay Rengarajan, Lucas Young, Bo Zhu, Rakesh Ranjan</p>
          <p><i>ECCV'22: European Conference on Computer Vision. </i></p>
           
           <div class="paper-buttons">
            
              <a class="button" href="https://www.ecva.net/papers/eccv_2022/papers_ECCV/papers/136780159.pdf" target="_blank">Paper</a>
            

            

            

            

            

            

            

          </div>
        </div>
      
        <div class="paper">
          <p class="title"><b>Audio-Visual Scene Understanding Towards Unified, Explainable, and Robust Multisensory Perception</b></p>
          <p><b>Yapeng Tian</b></p>
          <p><i>PhD Thesis </i></p>
           
           <div class="paper-buttons">
            
              <a class="button" href="https://www.proquest.com/openview/99bef5e8207df0ebab29e6b1f2afbad8/1.pdf?pq-origsite=gscholar&cbl=18750&diss=y" target="_blank">Paper</a>
            

            

            

            

            

            

            

          </div>
        </div>
      
        <div class="paper">
          <p class="title"><b>DuDoCAF: Dual-Domain Cross-Attention Fusion with Recurrent Transformer for Fast Multi-contrast MR Imaging</b></p>
          <p>Jun Lyu, Bin Sui, Chengyan Wang, <b>Yapeng Tian</b>, Qi Dou, and Jing Qin</p>
          <p><i>MICCAI'22: Medical Image Computing and Computer Assisted Intervention. </i></p>
           
           <div class="paper-buttons">
            
              <a class="button" href="/assets/publications/2022_dudocaf/paper.pdf" target="_blank">Paper</a>
            

            

            

            

            

            

            

          </div>
        </div>
      
        <div class="paper">
          <p class="title"><b>Audio-Visual Object Localization in Egocentric Videos</b></p>
          <p>Chao Huang, <b>Yapeng Tian</b>, Anurag Kumar, and Chenliang Xu</p>
          <p><i>CVPRW'22: CVPR Workshops</i></p>
          
          <p style="color:red">Egocentric audio-visual learning.</p>
         
           <div class="paper-buttons">
            
              <a class="button" href="https://sightsound.org/papers/2022/Huang_Audio-Visual_Object_Localization_in_Egocentric_Videos.pdf" target="_blank">Paper</a>
            

            

            

            

            

            

            

          </div>
        </div>
      
        <div class="paper">
          <p class="title"><b>Learning to Answer Questions in Dynamic Audio-Visual Scenarios</b></p>
          <p>Guangyao Li<sup>‡</sup>, Yake Wei<sup>‡</sup>, <b>Yapeng Tian<sup>‡</sup></b>, Chenliang Xu, Ji-Rong Wen, and Di Hu</p>
          <p><i>CVPR'22 Oral: IEEE/CVF Conference on Computer Vision and Pattern Recognition. </i></p>
           
           <div class="paper-buttons">
            
              <a class="button" href="https://arxiv.org/pdf/2203.14072.pdf" target="_blank">Paper</a>
            

            

            

            
              <a class="button" href="https://www.youtube.com/watch?v=JH3t5gwe9Xw" target="_blank">Video</a>
            

            
              <a class="button" href="https://github.com/GeWu-Lab/MUSIC-AVQA" target="_blank">Code</a>
            

            

            
              <a class="button" href="https://gewu-lab.github.io/MUSIC-AVQA/" target="_blank">Project</a>
            

          </div>
        </div>
      
        <div class="paper">
          <p class="title"><b>Transformer-empowered Multi-contrast MRI Super-Resolution</b></p>
          <p>Guangyuan Li, Jun Lv, <b>Yapeng Tian</b>, Qi Dou, Chengyan Wang, Chenliang Xu, Jing Qin</p>
          <p><i>CVPR'22: IEEE/CVF Conference on Computer Vision and Pattern Recognition.</i></p>
           
           <div class="paper-buttons">
            
              <a class="button" href="https://arxiv.org/pdf/2203.13963.pdf" target="_blank">Paper</a>
            

            

            

            

            
              <a class="button" href="https://github.com/XAIMI-Lab/McMRSR" target="_blank">Code</a>
            

            

            

          </div>
        </div>
      
        <div class="paper">
          <p class="title"><b>Coarse-to-Fine Embedded PatchMatch and Multi-Scale Dynamic Aggregation for Reference-based Super-Resolution</b></p>
          <p>Bin Xia, <b>Yapeng Tian</b>, Yucheng Hang, Wenming Yang, Qingmin Liao, Jie Zhou</p>
          <p><i>AAAI'22: The AAAI Conference on Artificial Intelligence.</i></p>
           
           <div class="paper-buttons">
            
              <a class="button" href="https://arxiv.org/pdf/2201.04358.pdf" target="_blank">Paper</a>
            

            

            

            

            
              <a class="button" href="https://github.com/Zj-BinXia/AMSA" target="_blank">Code</a>
            

            

            

          </div>
        </div>
      
        <div class="paper">
          <p class="title"><b>Efficient Non-Local Contrastive Attention for Image Super-Resolution</b></p>
          <p>Bin Xia<sup>‡</sup>, Yucheng Hang<sup>‡</sup>, <b>Yapeng Tian</b>, Wenming Yang, Qingmin Liao, Jie Zhou</p>
          <p><i>AAAI'22: The AAAI Conference on Artificial Intelligence. </i></p>
           
           <div class="paper-buttons">
            
              <a class="button" href="https://arxiv.org/pdf/2201.03794.pdf" target="_blank">Paper</a>
            

            

            

            

            
              <a class="button" href="https://github.com/Zj-BinXia/ENLCA" target="_blank">Code</a>
            

            

            

          </div>
        </div>
      
        <div class="paper">
          <p class="title"><b>Space-Time Memory Network for Sounding Object Localization in Videos</b></p>
          <p>Sizhe Li<sup>‡</sup>, <b>Yapeng Tian<sup>‡</sup></b>, and Chenliang Xu</p>
          <p><i>BMVC'21: The British Machine Vision Conference. </i></p>
           
           <div class="paper-buttons">
            
              <a class="button" href="https://arxiv.org/pdf/2111.05526.pdf" target="_blank">Paper</a>
            

            

            

            

            
              <a class="button" href="https://github.com/lester0866/Space-Time-Memory-Network-for-Sounding-Object-Localization-in-Videos" target="_blank">Code</a>
            

            

            
              <a class="button" href="https://sites.google.com/view/bmvc2021stm" target="_blank">Project</a>
            

          </div>
        </div>
      
        <div class="paper">
          <p class="title"><b>Video Matting via Consistency-Regularized Graph Neural Networks</b></p>
          <p>Tiantian Wang, Sifei Liu, <b>Yapeng Tian</b>, Kai Li, and Ming-Hsuan Yang</p>
          <p><i>ICCV'21: IEEE/CVF International Conference on Computer Vision. </i></p>
           
           <div class="paper-buttons">
            
              <a class="button" href="https://faculty.ucmerced.edu/mhyang/papers/iccv2021_video_matting.pdf" target="_blank">Paper</a>
            

            

            

            

            
              <a class="button" href="https://github.com/TiantianWang/VideoMatting-CRGNN" target="_blank">Code</a>
            

            

            

          </div>
        </div>
      
        <div class="paper">
          <p class="title"><b>Can audio-visual integration strengthen robustness under multimodal attacks?</b></p>
          <p><b>Yapeng Tian</b> and Chenliang Xu</p>
          <p><i>CVPR'21: IEEE/CVF Conference on Computer Vision and Pattern Recognition. </i></p>
           
           <div class="paper-buttons">
            
              <a class="button" href="https://arxiv.org/pdf/2104.02000.pdf" target="_blank">Paper</a>
            

            

            

            

            
              <a class="button" href="https://github.com/YapengTian/AV-Robustness-CVPR21" target="_blank">Code</a>
            

            

            

          </div>
        </div>
      
        <div class="paper">
          <p class="title"><b>Cyclic Co-Learning of Sounding Object Visual Grounding and Sound Separation</b></p>
          <p><b>Yapeng Tian</b>, Di Hu, and Chenliang Xu</p>
          <p><i>CVPR'21: IEEE/CVF Conference on Computer Vision and Pattern Recognition.</i></p>
           
           <div class="paper-buttons">
            
              <a class="button" href="https://arxiv.org/pdf/2104.02026.pdf" target="_blank">Paper</a>
            

            

            

            

            
              <a class="button" href="https://github.com/YapengTian/CCOL-CVPR21" target="_blank">Code</a>
            

            

            

          </div>
        </div>
      
        <div class="paper">
          <p class="title"><b>Unified Multisensory Perception: Weakly-Supervised Audio-Visual Video Parsing</b></p>
          <p><b>Yapeng Tian</b>, Dingzeyu Li, and Chenliang Xu</p>
          <p><i>ECCV'20 Spotlight: European Conference on Computer Vision.</i></p>
           
           <div class="paper-buttons">
            
              <a class="button" href="https://arxiv.org/pdf/2007.10558.pdf" target="_blank">Paper</a>
            

            

            

            

            
              <a class="button" href="https://github.com/YapengTian/AVVP-ECCV20" target="_blank">Code</a>
            

            
              <a class="button" href="https://github.com/YapengTian/AVVP-ECCV20" target="_blank">Data</a>
            

            

          </div>
        </div>
      
        <div class="paper">
          <p class="title"><b>Zooming Slow-Mo: Fast and Accurate One-Stage Space-Time Video Super-Resolution</b></p>
          <p>Xiaoyu Xiang<sup>‡</sup>, <b>Yapeng Tian<sup>‡</sup></b>, Yulun Zhang, Yun Fu, Jan Allebach, and Chenliang Xu</p>
          <p><i>CVPR'20: IEEE/CVF Conference on Computer Vision and Pattern Recognition.</i></p>
           
           <div class="paper-buttons">
            
              <a class="button" href="https://arxiv.org/pdf/2002.11616.pdf" target="_blank">Paper</a>
            

            

            

            
              <a class="button" href="https://www.youtube.com/watch?v=8mgD8JxBOus" target="_blank">Video</a>
            

            
              <a class="button" href="https://github.com/Mukosame/Zooming-Slow-Mo-CVPR-2020" target="_blank">Code</a>
            

            

            

          </div>
        </div>
      
        <div class="paper">
          <p class="title"><b>TDAN: Temporally Deformable Alignment Network for Video Super-Resolution</b></p>
          <p><b>Yapeng Tian</b>, Yulun Zhang, Yun Fu, and Chenliang Xu</p>
          <p><i>CVPR'20: IEEE/CVF Conference on Computer Vision and Pattern Recognition.</i></p>
          
          <p style="color:red">This is the first work that uses deformable alignment to address video restoration.</p>
         
           <div class="paper-buttons">
            
              <a class="button" href="https://openaccess.thecvf.com/content_CVPR_2020/papers/Tian_TDAN_Temporally-Deformable_Alignment_Network_for_Video_Super-Resolution_CVPR_2020_paper.pdf" target="_blank">Paper</a>
            

            

            

            
              <a class="button" href="https://www.youtube.com/watch?v=eZExENE50I0" target="_blank">Video</a>
            

            
              <a class="button" href="https://github.com/YapengTian/TDAN-VSR-CVPR-2020" target="_blank">Code</a>
            

            

            

          </div>
        </div>
      
        <div class="paper">
          <p class="title"><b>Deep Audio Prior</b></p>
          <p><b>Yapeng Tian</b>, Chenliang Xu, and Dingzeyu Li</p>
          <p><i>CVPRW'20: CVPR Workshops.</i></p>
           
           <div class="paper-buttons">
            
              <a class="button" href="https://arxiv.org/pdf/1912.10292v1.pdf" target="_blank">Paper</a>
            

            

            

            

            
              <a class="button" href="https://github.com/adobe/Deep-Audio-Prior" target="_blank">Code</a>
            

            

            
              <a class="button" href="https://opensource.adobe.com/Deep-Audio-Prior/" target="_blank">Project</a>
            

          </div>
        </div>
      
        <div class="paper">
          <p class="title"><b>Residual Dense Network for Image Super-Resolution</b></p>
          <p>Yulun Zhang, <b>Yapeng Tian</b>, Yu Kong , Bineng Zhong, Yun Fu</p>
          <p><i>TPAMI'20: IEEE Transactions on Pattern Analysis and Machine Intelligence.</i></p>
           
           <div class="paper-buttons">
            
              <a class="button" href="https://arxiv.org/pdf/1812.10477.pdf" target="_blank">Paper</a>
            

            

            

            

            
              <a class="button" href="https://github.com/yulunzhang/RDN" target="_blank">Code</a>
            

            

            

          </div>
        </div>
      
        <div class="paper">
          <p class="title"><b>CFSNet: Toward a Controllable Feature Space for Image Restoration</b></p>
          <p>Wei Wang<sup>‡</sup>, Ruiming Guo<sup>‡</sup>, <b>Yapeng Tian</b>, and Wenming Yang</p>
          <p><i>ICCV'19: IEEE/CVF International Conference on Computer Vision.</i></p>
           
           <div class="paper-buttons">
            
              <a class="button" href="https://arxiv.org/pdf/1904.00634.pdf" target="_blank">Paper</a>
            

            

            

            

            
              <a class="button" href="https://github.com/qibao77/CFSNet" target="_blank">Code</a>
            

            

            

          </div>
        </div>
      
        <div class="paper">
          <p class="title"><b>Interpretable and Controllable Audio-Visual Video Captioning</b></p>
          <p><b>Yapeng Tian</b>, Chenxiao Guan, Goodman Justin, Marc Moore, and Chenliang Xu</p>
          <p><i>CVPRW'19: CVPR Workshops.</i></p>
          
          <p style="color:red">Multisensory interpretability in terms of the audio-visual video captioning task.</p>
         
           <div class="paper-buttons">
            
              <a class="button" href="https://openaccess.thecvf.com/content_CVPRW_2019/papers/Sight%20and%20Sound/Yapeng_Tian_Audio-Visual_Interpretable_and_Controllable_Video_Captioning_CVPRW_2019_paper.pdf" target="_blank">Paper</a>
            

            

            

            

            

            

            

          </div>
        </div>
      
        <div class="paper">
          <p class="title"><b>LCSCNet: Linear Compressing Based Skip-Connecting Network for ISR</b></p>
          <p>Wenming Yang, Xuechen Zhang, <b>Yapeng Tian</b>, Wei Wang, Jing-Hao Xue, Qingmin Liao</p>
          <p><i>TIP'19: IEEE Trans. Image Processing.</i></p>
           
           <div class="paper-buttons">
            
              <a class="button" href="https://arxiv.org/abs/1909.03573" target="_blank">Paper</a>
            

            

            

            

            

            

            

          </div>
        </div>
      
        <div class="paper">
          <p class="title"><b>Deep Learning for Single Image Super-Resolution: A Brief Review</b></p>
          <p>Wenming Yang, Xuechen Zhang, <b>Yapeng Tian</b>, Wei Wang, JingHao Xue, Qingmin Liao</p>
          <p><i>TMM'19: IEEE Trans. Multimedia.</i></p>
           
           <div class="paper-buttons">
            
              <a class="button" href="https://arxiv.org/pdf/1808.03344.pdf" target="_blank">Paper</a>
            

            

            

            

            

            

            

          </div>
        </div>
      
        <div class="paper">
          <p class="title"><b>Audio-Visual Event Localization in Unconstrained Videos</b></p>
          <p><b>Yapeng Tian</b>, Jing Shi, Bochen Li, Zhiyao Duan, Chenliang Xu</p>
          <p><i>ECCV'18: European Conference on Computer Vision.</i></p>
           
           <div class="paper-buttons">
            
              <a class="button" href="https://openaccess.thecvf.com/content_ECCV_2018/papers/Yapeng_Tian_Audio-Visual_Event_Localization_ECCV_2018_paper.pdf" target="_blank">Paper</a>
            

            

            

            
              <a class="button" href="https://www.youtube.com/watch?v=m6r6BbD5MSc" target="_blank">Video</a>
            

            
              <a class="button" href="https://github.com/YapengTian/AVE-ECCV18" target="_blank">Code</a>
            

            
              <a class="button" href="https://drive.google.com/file/d/1FjKwe79e0u96vdjIVwfRQ1V6SoDHe7kK" target="_blank">Data</a>
            

            
              <a class="button" href="https://sites.google.com/view/audiovisualresearch" target="_blank">Project</a>
            

          </div>
        </div>
      
        <div class="paper">
          <p class="title"><b>Residual Dense Network for Image Super-Resolution</b></p>
          <p>Yulun Zhang, <b>Yapeng Tian</b>, Yu Kong , Bineng Zhong, Yun Fu</p>
          <p><i>CVPR'18 Spotlight: IEEE/CVF Conf. on Computer Vision and Pattern Recognition.</i></p>
           
           <div class="paper-buttons">
            
              <a class="button" href="https://arxiv.org/pdf/1802.08797.pdf" target="_blank">Paper</a>
            

            

            

            

            
              <a class="button" href="https://github.com/yulunzhang/RDN" target="_blank">Code</a>
            

            

            

          </div>
        </div>
      
        <div class="paper">
          <p class="title"><b>NTIRE 2017 Challenge on Single Image Super-Resolution: Methods and Results</b></p>
          <p>Timofte et al.</p>
          <p><i>CVPRW'17: CVPR Workshops.</i></p>
           
           <div class="paper-buttons">
            
              <a class="button" href="https://people.ee.ethz.ch/~timofter/publications/Timofte-CVPRW-2017.pdf" target="_blank">Paper</a>
            

            

            

            

            

            

            

          </div>
        </div>
      
        <div class="paper">
          <p class="title"><b>Consistent Coding Scheme for Single-Image Super-Resolution</b></p>
          <p>Wenming Yang, <b>Yapeng Tian</b>, Fei Zhou, Qingmin Liao, Hai Chen, Chenglin Zheng</p>
          <p><i>TMM'16: EEE Trans. Multimedia. (First student author)</i></p>
           
           <div class="paper-buttons">
            
              <a class="button" href="https://drive.google.com/file/d/1MpEM5qmSJi1GtY9TftNNV0cgSHqMT_KQ/view" target="_blank">Paper</a>
            

            

            

            

            

            

            

          </div>
        </div>
      
        <div class="paper">
          <p class="title"><b>Anchored Neighborhood Regression based SISR from Self-examples</b></p>
          <p><b>Yapeng Tian</b>, Fei Zhou, Wenming Yang, Xuesen Shang, Qingmin Liao</p>
          <p><i>ICIP'16: IEEE International Conference on Image Processing.</i></p>
           
           <div class="paper-buttons">
            
              <a class="button" href="https://drive.google.com/file/d/1Ts_gYIp57llzK53Wyt7hwu4lZ9GQsbis/view" target="_blank">Paper</a>
            

            

            

            

            
              <a class="button" href="https://github.com/YapengTian/ICIP2016" target="_blank">Code</a>
            

            

            

          </div>
        </div>
      
        <div class="paper">
          <p class="title"><b>SISR Using Clustering-Based Global Regression and Propagation Filtering</b></p>
          <p>Wenming Yang, <b>Yapeng Tian</b>, Fei Zhou, ..., Qingmin Liao</p>
          <p><i>ACPR'15 Oral: Asian Conference on Pattern Recognition. (First student author)</i></p>
           
           <div class="paper-buttons">
            
              <a class="button" href="https://drive.google.com/file/d/12tqTHt0aLn7-B1jEgEJBYY64uhwfEezA/view" target="_blank">Paper</a>
            

            

            

            

            

            

            

          </div>
        </div>
      
    </div> -->

    <!-- <div class="tab-pane active" id="papers-selected">
      
      
        <div class="paper">
          <p class="title"><b>AV-NeRF: Learning Neural Fields for Real-World Audio-Visual Scene Synthesis</b></p>
          <p>Susan Liang, Chao Huang, <b>Yapeng Tian</b>, Anurag Kumar, Chenliang Xu</p>
          <p><i>Preprint'23. </i></p>
           
           <div class="paper-buttons">
            
              <a class="button" href="https://arxiv.org/pdf/2302.02088.pdf" target="_blank">Paper</a>
            

            

            

            

            

            

            
              <a class="button" href="https://liangsusan-git.github.io/project/avnerf/" target="_blank">Project</a>
            



          </div>
        </div>
      
        <div class="paper">
          <p class="title"><b>Learning in Audio-visual Context: A Review, Analysis, and New Perspective</b></p>
          <p>Yake Wei, Di Hu, <b>Yapeng Tian</b>, Xuelong Li</p>
          <p><i>Preprint'22. </i></p>
           
           <div class="paper-buttons">
            
              <a class="button" href="https://arxiv.org/pdf/2208.09579.pdf" target="_blank">Paper</a>
            

            

            

            

            

            

            
              <a class="button" href="https://gewu-lab.github.io/audio-visual-learning/" target="_blank">Project</a>
            



          </div>
        </div>
      
        <div class="paper">
          <p class="title"><b>Towards Unified, Explainable, and Robust Multisensory Perception</b></p>
          <p>Yapeng Tian</p>
          <p><i>AAAI'23: AAAI Conference on Artificial Intelligence. (NFH program)</i></p>
           
           <div class="paper-buttons">
            
              <a class="button" href="/assets/publications/2023_aaainfh/paper.pdf" target="_blank">Paper</a>
            

            

            

            

            

            

            



          </div>
        </div>
      
        <div class="paper">
          <p class="title"><b>Multi-modal Grouping Network for Weakly-Supervised Audio-Visual Video Parsing</b></p>
          <p>Shentong Mo, <b>Yapeng Tian</b></p>
          <p><i>NeurIPS'22: The Annual Conference on Neural Information Processing Systems. </i></p>
           
           <div class="paper-buttons">
            
              <a class="button" href="https://openreview.net/pdf?id=zfo2LqFEVY" target="_blank">Paper</a>
            

            

            

            

            
              <a class="button" href="https://github.com/stoneMo/MGN" target="_blank">Code</a>
            

            

            



          </div>
        </div>
      
        <div class="paper">
          <p class="title"><b>Learning Spatio-Temporal Downsampling for Effective Video Upscaling</b></p>
          <p>Xiaoyu Xiang, <b>Yapeng Tian</b>, Vijay Rengarajan, Lucas Young, Bo Zhu, Rakesh Ranjan</p>
          <p><i>ECCV'22: European Conference on Computer Vision. </i></p>
           
           <div class="paper-buttons">
            
              <a class="button" href="https://www.ecva.net/papers/eccv_2022/papers_ECCV/papers/136780159.pdf" target="_blank">Paper</a>
            

            

            

            

            

            

            



          </div>
        </div>
      
        <div class="paper">
          <p class="title"><b>Audio-Visual Scene Understanding Towards Unified, Explainable, and Robust Multisensory Perception</b></p>
          <p><b>Yapeng Tian</b></p>
          <p><i>PhD Thesis </i></p>
           
           <div class="paper-buttons">
            
              <a class="button" href="https://www.proquest.com/openview/99bef5e8207df0ebab29e6b1f2afbad8/1.pdf?pq-origsite=gscholar&cbl=18750&diss=y" target="_blank">Paper</a>
            

            

            

            

            

            

            



          </div>
        </div>
      
        <div class="paper">
          <p class="title"><b>Audio-Visual Object Localization in Egocentric Videos</b></p>
          <p>Chao Huang, <b>Yapeng Tian</b>, Anurag Kumar, and Chenliang Xu</p>
          <p><i>CVPRW'22: CVPR Workshops</i></p>
          
          <p style="color:red">Egocentric audio-visual learning.</p>
         
           <div class="paper-buttons">
            
              <a class="button" href="https://sightsound.org/papers/2022/Huang_Audio-Visual_Object_Localization_in_Egocentric_Videos.pdf" target="_blank">Paper</a>
            

            

            

            

            

            

            



          </div>
        </div>
      
        <div class="paper">
          <p class="title"><b>Learning to Answer Questions in Dynamic Audio-Visual Scenarios</b></p>
          <p>Guangyao Li<sup>‡</sup>, Yake Wei<sup>‡</sup>, <b>Yapeng Tian<sup>‡</sup></b>, Chenliang Xu, Ji-Rong Wen, and Di Hu</p>
          <p><i>CVPR'22 Oral: IEEE/CVF Conference on Computer Vision and Pattern Recognition. </i></p>
           
           <div class="paper-buttons">
            
              <a class="button" href="https://arxiv.org/pdf/2203.14072.pdf" target="_blank">Paper</a>
            

            

            

            
              <a class="button" href="https://www.youtube.com/watch?v=JH3t5gwe9Xw" target="_blank">Video</a>
            

            
              <a class="button" href="https://github.com/GeWu-Lab/MUSIC-AVQA" target="_blank">Code</a>
            

            

            
              <a class="button" href="https://gewu-lab.github.io/MUSIC-AVQA/" target="_blank">Project</a>
            



          </div>
        </div>
      
        <div class="paper">
          <p class="title"><b>Can audio-visual integration strengthen robustness under multimodal attacks?</b></p>
          <p><b>Yapeng Tian</b> and Chenliang Xu</p>
          <p><i>CVPR'21: IEEE/CVF Conference on Computer Vision and Pattern Recognition. </i></p>
           
           <div class="paper-buttons">
            
              <a class="button" href="https://arxiv.org/pdf/2104.02000.pdf" target="_blank">Paper</a>
            

            

            

            

            
              <a class="button" href="https://github.com/YapengTian/AV-Robustness-CVPR21" target="_blank">Code</a>
            

            

            



          </div>
        </div>
      
        <div class="paper">
          <p class="title"><b>Cyclic Co-Learning of Sounding Object Visual Grounding and Sound Separation</b></p>
          <p><b>Yapeng Tian</b>, Di Hu, and Chenliang Xu</p>
          <p><i>CVPR'21: IEEE/CVF Conference on Computer Vision and Pattern Recognition.</i></p>
           
           <div class="paper-buttons">
            
              <a class="button" href="https://arxiv.org/pdf/2104.02026.pdf" target="_blank">Paper</a>
            

            

            

            

            
              <a class="button" href="https://github.com/YapengTian/CCOL-CVPR21" target="_blank">Code</a>
            

            

            



          </div>
        </div>
      
        <div class="paper">
          <p class="title"><b>Unified Multisensory Perception: Weakly-Supervised Audio-Visual Video Parsing</b></p>
          <p><b>Yapeng Tian</b>, Dingzeyu Li, and Chenliang Xu</p>
          <p><i>ECCV'20 Spotlight: European Conference on Computer Vision.</i></p>
           
           <div class="paper-buttons">
            
              <a class="button" href="https://arxiv.org/pdf/2007.10558.pdf" target="_blank">Paper</a>
            

            

            

            

            
              <a class="button" href="https://github.com/YapengTian/AVVP-ECCV20" target="_blank">Code</a>
            

            
              <a class="button" href="https://github.com/YapengTian/AVVP-ECCV20" target="_blank">Data</a>
            

            



          </div>
        </div>
      
        <div class="paper">
          <p class="title"><b>Zooming Slow-Mo: Fast and Accurate One-Stage Space-Time Video Super-Resolution</b></p>
          <p>Xiaoyu Xiang<sup>‡</sup>, <b>Yapeng Tian<sup>‡</sup></b>, Yulun Zhang, Yun Fu, Jan Allebach, and Chenliang Xu</p>
          <p><i>CVPR'20: IEEE/CVF Conference on Computer Vision and Pattern Recognition.</i></p>
           
           <div class="paper-buttons">
            
              <a class="button" href="https://arxiv.org/pdf/2002.11616.pdf" target="_blank">Paper</a>
            

            

            

            
              <a class="button" href="https://www.youtube.com/watch?v=8mgD8JxBOus" target="_blank">Video</a>
            

            
              <a class="button" href="https://github.com/Mukosame/Zooming-Slow-Mo-CVPR-2020" target="_blank">Code</a>
            

            

            



          </div>
        </div>
      
        <div class="paper">
          <p class="title"><b>TDAN: Temporally Deformable Alignment Network for Video Super-Resolution</b></p>
          <p><b>Yapeng Tian</b>, Yulun Zhang, Yun Fu, and Chenliang Xu</p>
          <p><i>CVPR'20: IEEE/CVF Conference on Computer Vision and Pattern Recognition.</i></p>
          
          <p style="color:red">This is the first work that uses deformable alignment to address video restoration.</p>
         
           <div class="paper-buttons">
            
              <a class="button" href="https://openaccess.thecvf.com/content_CVPR_2020/papers/Tian_TDAN_Temporally-Deformable_Alignment_Network_for_Video_Super-Resolution_CVPR_2020_paper.pdf" target="_blank">Paper</a>
            

            

            

            
              <a class="button" href="https://www.youtube.com/watch?v=eZExENE50I0" target="_blank">Video</a>
            

            
              <a class="button" href="https://github.com/YapengTian/TDAN-VSR-CVPR-2020" target="_blank">Code</a>
            

            

            



          </div>
        </div>
      
        <div class="paper">
          <p class="title"><b>Deep Audio Prior</b></p>
          <p><b>Yapeng Tian</b>, Chenliang Xu, and Dingzeyu Li</p>
          <p><i>CVPRW'20: CVPR Workshops.</i></p>
           
           <div class="paper-buttons">
            
              <a class="button" href="https://arxiv.org/pdf/1912.10292v1.pdf" target="_blank">Paper</a>
            

            

            

            

            
              <a class="button" href="https://github.com/adobe/Deep-Audio-Prior" target="_blank">Code</a>
            

            

            
              <a class="button" href="https://opensource.adobe.com/Deep-Audio-Prior/" target="_blank">Project</a>
            



          </div>
        </div>
      
        <div class="paper">
          <p class="title"><b>Interpretable and Controllable Audio-Visual Video Captioning</b></p>
          <p><b>Yapeng Tian</b>, Chenxiao Guan, Goodman Justin, Marc Moore, and Chenliang Xu</p>
          <p><i>CVPRW'19: CVPR Workshops.</i></p>
          
          <p style="color:red">Multisensory interpretability in terms of the audio-visual video captioning task.</p>
         
           <div class="paper-buttons">
            
              <a class="button" href="https://openaccess.thecvf.com/content_CVPRW_2019/papers/Sight%20and%20Sound/Yapeng_Tian_Audio-Visual_Interpretable_and_Controllable_Video_Captioning_CVPRW_2019_paper.pdf" target="_blank">Paper</a>
            

            

            

            

            

            

            



          </div>
        </div>
      
        <div class="paper">
          <p class="title"><b>Audio-Visual Event Localization in Unconstrained Videos</b></p>
          <p><b>Yapeng Tian</b>, Jing Shi, Bochen Li, Zhiyao Duan, Chenliang Xu</p>
          <p><i>ECCV'18: European Conference on Computer Vision.</i></p>
           
           <div class="paper-buttons">
            
              <a class="button" href="https://openaccess.thecvf.com/content_ECCV_2018/papers/Yapeng_Tian_Audio-Visual_Event_Localization_ECCV_2018_paper.pdf" target="_blank">Paper</a>
            

            

            

            
              <a class="button" href="https://www.youtube.com/watch?v=m6r6BbD5MSc" target="_blank">Video</a>
            

            
              <a class="button" href="https://github.com/YapengTian/AVE-ECCV18" target="_blank">Code</a>
            

            
              <a class="button" href="https://drive.google.com/file/d/1FjKwe79e0u96vdjIVwfRQ1V6SoDHe7kK" target="_blank">Data</a>
            

            
              <a class="button" href="https://sites.google.com/view/audiovisualresearch" target="_blank">Project</a>
            



          </div>
        </div>
      
    </div> -->
  
        

    <!-- <div class="tab-pane active" id="papers-audiovisual">
      
      
        <div class="paper">
          <p class="title"><b>AV-NeRF: Learning Neural Fields for Real-World Audio-Visual Scene Synthesis</b></p>
          <p>Susan Liang, Chao Huang, <b>Yapeng Tian</b>, Anurag Kumar, Chenliang Xu</p>
          <p><i>Preprint'23. </i></p>
           <div class="paper-buttons">
            
              <a class="button" href="https://arxiv.org/pdf/2302.02088.pdf" target="_blank">Paper</a>
            

            

            

            

            

            

            
              <a class="button" href="https://liangsusan-git.github.io/project/avnerf/" target="_blank">Project</a>
            

          </div>
        </div>
      
        <div class="paper">
          <p class="title"><b>Learning in Audio-visual Context: A Review, Analysis, and New Perspective</b></p>
          <p>Yake Wei, Di Hu, <b>Yapeng Tian</b>, Xuelong Li</p>
          <p><i>Preprint'22. </i></p>
           <div class="paper-buttons">
            
              <a class="button" href="https://arxiv.org/pdf/2208.09579.pdf" target="_blank">Paper</a>
            

            

            

            

            

            

            
              <a class="button" href="https://gewu-lab.github.io/audio-visual-learning/" target="_blank">Project</a>
            

          </div>
        </div>
      
        <div class="paper">
          <p class="title"><b>Towards Unified, Explainable, and Robust Multisensory Perception</b></p>
          <p>Yapeng Tian</p>
          <p><i>AAAI'23: AAAI Conference on Artificial Intelligence. (NFH program)</i></p>
           <div class="paper-buttons">
            
              <a class="button" href="/assets/publications/2023_aaainfh/paper.pdf" target="_blank">Paper</a>
            

            

            

            

            

            

            

          </div>
        </div>
      
        <div class="paper">
          <p class="title"><b>Multi-modal Grouping Network for Weakly-Supervised Audio-Visual Video Parsing</b></p>
          <p>Shentong Mo, <b>Yapeng Tian</b></p>
          <p><i>NeurIPS'22: The Annual Conference on Neural Information Processing Systems. </i></p>
           <div class="paper-buttons">
            
              <a class="button" href="https://openreview.net/pdf?id=zfo2LqFEVY" target="_blank">Paper</a>
            

            

            

            

            
              <a class="button" href="https://github.com/stoneMo/MGN" target="_blank">Code</a>
            

            

            

          </div>
        </div>
      
        <div class="paper">
          <p class="title"><b>Audio-Visual Scene Understanding Towards Unified, Explainable, and Robust Multisensory Perception</b></p>
          <p><b>Yapeng Tian</b></p>
          <p><i>PhD Thesis </i></p>
           <div class="paper-buttons">
            
              <a class="button" href="https://www.proquest.com/openview/99bef5e8207df0ebab29e6b1f2afbad8/1.pdf?pq-origsite=gscholar&cbl=18750&diss=y" target="_blank">Paper</a>
            

            

            

            

            

            

            

          </div>
        </div>
      
        <div class="paper">
          <p class="title"><b>Audio-Visual Object Localization in Egocentric Videos</b></p>
          <p>Chao Huang, <b>Yapeng Tian</b>, Anurag Kumar, and Chenliang Xu</p>
          <p><i>CVPRW'22: CVPR Workshops</i></p>
           <div class="paper-buttons">
            
              <a class="button" href="https://sightsound.org/papers/2022/Huang_Audio-Visual_Object_Localization_in_Egocentric_Videos.pdf" target="_blank">Paper</a>
            

            

            

            

            

            

            

          </div>
        </div>
      
        <div class="paper">
          <p class="title"><b>Learning to Answer Questions in Dynamic Audio-Visual Scenarios</b></p>
          <p>Guangyao Li<sup>‡</sup>, Yake Wei<sup>‡</sup>, <b>Yapeng Tian<sup>‡</sup></b>, Chenliang Xu, Ji-Rong Wen, and Di Hu</p>
          <p><i>CVPR'22 Oral: IEEE/CVF Conference on Computer Vision and Pattern Recognition. </i></p>
           <div class="paper-buttons">
            
              <a class="button" href="https://arxiv.org/pdf/2203.14072.pdf" target="_blank">Paper</a>
            

            

            

            
              <a class="button" href="https://www.youtube.com/watch?v=JH3t5gwe9Xw" target="_blank">Video</a>
            

            
              <a class="button" href="https://github.com/GeWu-Lab/MUSIC-AVQA" target="_blank">Code</a>
            

            

            
              <a class="button" href="https://gewu-lab.github.io/MUSIC-AVQA/" target="_blank">Project</a>
            

          </div>
        </div>
      
        <div class="paper">
          <p class="title"><b>Space-Time Memory Network for Sounding Object Localization in Videos</b></p>
          <p>Sizhe Li<sup>‡</sup>, <b>Yapeng Tian<sup>‡</sup></b>, and Chenliang Xu</p>
          <p><i>BMVC'21: The British Machine Vision Conference. </i></p>
           <div class="paper-buttons">
            
              <a class="button" href="https://arxiv.org/pdf/2111.05526.pdf" target="_blank">Paper</a>
            

            

            

            

            
              <a class="button" href="https://github.com/lester0866/Space-Time-Memory-Network-for-Sounding-Object-Localization-in-Videos" target="_blank">Code</a>
            

            

            
              <a class="button" href="https://sites.google.com/view/bmvc2021stm" target="_blank">Project</a>
            

          </div>
        </div>
      
        <div class="paper">
          <p class="title"><b>Can audio-visual integration strengthen robustness under multimodal attacks?</b></p>
          <p><b>Yapeng Tian</b> and Chenliang Xu</p>
          <p><i>CVPR'21: IEEE/CVF Conference on Computer Vision and Pattern Recognition. </i></p>
           <div class="paper-buttons">
            
              <a class="button" href="https://arxiv.org/pdf/2104.02000.pdf" target="_blank">Paper</a>
            

            

            

            

            
              <a class="button" href="https://github.com/YapengTian/AV-Robustness-CVPR21" target="_blank">Code</a>
            

            

            

          </div>
        </div>
      
        <div class="paper">
          <p class="title"><b>Cyclic Co-Learning of Sounding Object Visual Grounding and Sound Separation</b></p>
          <p><b>Yapeng Tian</b>, Di Hu, and Chenliang Xu</p>
          <p><i>CVPR'21: IEEE/CVF Conference on Computer Vision and Pattern Recognition.</i></p>
           <div class="paper-buttons">
            
              <a class="button" href="https://arxiv.org/pdf/2104.02026.pdf" target="_blank">Paper</a>
            

            

            

            

            
              <a class="button" href="https://github.com/YapengTian/CCOL-CVPR21" target="_blank">Code</a>
            

            

            

          </div>
        </div>
      
        <div class="paper">
          <p class="title"><b>Unified Multisensory Perception: Weakly-Supervised Audio-Visual Video Parsing</b></p>
          <p><b>Yapeng Tian</b>, Dingzeyu Li, and Chenliang Xu</p>
          <p><i>ECCV'20 Spotlight: European Conference on Computer Vision.</i></p>
           <div class="paper-buttons">
            
              <a class="button" href="https://arxiv.org/pdf/2007.10558.pdf" target="_blank">Paper</a>
            

            

            

            

            
              <a class="button" href="https://github.com/YapengTian/AVVP-ECCV20" target="_blank">Code</a>
            

            
              <a class="button" href="https://github.com/YapengTian/AVVP-ECCV20" target="_blank">Data</a>
            

            

          </div>
        </div>
      
        <div class="paper">
          <p class="title"><b>Deep Audio Prior</b></p>
          <p><b>Yapeng Tian</b>, Chenliang Xu, and Dingzeyu Li</p>
          <p><i>CVPRW'20: CVPR Workshops.</i></p>
           <div class="paper-buttons">
            
              <a class="button" href="https://arxiv.org/pdf/1912.10292v1.pdf" target="_blank">Paper</a>
            

            

            

            

            
              <a class="button" href="https://github.com/adobe/Deep-Audio-Prior" target="_blank">Code</a>
            

            

            
              <a class="button" href="https://opensource.adobe.com/Deep-Audio-Prior/" target="_blank">Project</a>
            

          </div>
        </div>
      
        <div class="paper">
          <p class="title"><b>Interpretable and Controllable Audio-Visual Video Captioning</b></p>
          <p><b>Yapeng Tian</b>, Chenxiao Guan, Goodman Justin, Marc Moore, and Chenliang Xu</p>
          <p><i>CVPRW'19: CVPR Workshops.</i></p>
           <div class="paper-buttons">
            
              <a class="button" href="https://openaccess.thecvf.com/content_CVPRW_2019/papers/Sight%20and%20Sound/Yapeng_Tian_Audio-Visual_Interpretable_and_Controllable_Video_Captioning_CVPRW_2019_paper.pdf" target="_blank">Paper</a>
            

            

            

            

            

            

            

          </div>
        </div>
      
        <div class="paper">
          <p class="title"><b>Audio-Visual Event Localization in Unconstrained Videos</b></p>
          <p><b>Yapeng Tian</b>, Jing Shi, Bochen Li, Zhiyao Duan, Chenliang Xu</p>
          <p><i>ECCV'18: European Conference on Computer Vision.</i></p>
           <div class="paper-buttons">
            
              <a class="button" href="https://openaccess.thecvf.com/content_ECCV_2018/papers/Yapeng_Tian_Audio-Visual_Event_Localization_ECCV_2018_paper.pdf" target="_blank">Paper</a>
            

            

            

            
              <a class="button" href="https://www.youtube.com/watch?v=m6r6BbD5MSc" target="_blank">Video</a>
            

            
              <a class="button" href="https://github.com/YapengTian/AVE-ECCV18" target="_blank">Code</a>
            

            
              <a class="button" href="https://drive.google.com/file/d/1FjKwe79e0u96vdjIVwfRQ1V6SoDHe7kK" target="_blank">Data</a>
            

            
              <a class="button" href="https://sites.google.com/view/audiovisualresearch" target="_blank">Project</a>
            

          </div>
        </div>
      
    </div> -->
<!-- 
    <div class="tab-pane active" id="papers-videorestoration">
      
      
        <div class="paper">
          <p class="title"><b>Learning Spatio-Temporal Downsampling for Effective Video Upscaling</b></p>
          <p>Xiaoyu Xiang, <b>Yapeng Tian</b>, Vijay Rengarajan, Lucas Young, Bo Zhu, Rakesh Ranjan</p>
          <p><i>ECCV'22: European Conference on Computer Vision. </i></p>
           <div class="paper-buttons">
            
              <a class="button" href="https://www.ecva.net/papers/eccv_2022/papers_ECCV/papers/136780159.pdf" target="_blank">Paper</a>
            

            

            

            

            

            

            

          </div>
        </div>
      
        <div class="paper">
          <p class="title"><b>Video Matting via Consistency-Regularized Graph Neural Networks</b></p>
          <p>Tiantian Wang, Sifei Liu, <b>Yapeng Tian</b>, Kai Li, and Ming-Hsuan Yang</p>
          <p><i>ICCV'21: IEEE/CVF International Conference on Computer Vision. </i></p>
           <div class="paper-buttons">
            
              <a class="button" href="https://faculty.ucmerced.edu/mhyang/papers/iccv2021_video_matting.pdf" target="_blank">Paper</a>
            

            

            

            

            
              <a class="button" href="https://github.com/TiantianWang/VideoMatting-CRGNN" target="_blank">Code</a>
            

            

            

          </div>
        </div>
      
        <div class="paper">
          <p class="title"><b>Zooming Slow-Mo: Fast and Accurate One-Stage Space-Time Video Super-Resolution</b></p>
          <p>Xiaoyu Xiang<sup>‡</sup>, <b>Yapeng Tian<sup>‡</sup></b>, Yulun Zhang, Yun Fu, Jan Allebach, and Chenliang Xu</p>
          <p><i>CVPR'20: IEEE/CVF Conference on Computer Vision and Pattern Recognition.</i></p>
           <div class="paper-buttons">
            
              <a class="button" href="https://arxiv.org/pdf/2002.11616.pdf" target="_blank">Paper</a>
            

            

            

            
              <a class="button" href="https://www.youtube.com/watch?v=8mgD8JxBOus" target="_blank">Video</a>
            

            
              <a class="button" href="https://github.com/Mukosame/Zooming-Slow-Mo-CVPR-2020" target="_blank">Code</a>
            

            

            

          </div>
        </div>
      
        <div class="paper">
          <p class="title"><b>TDAN: Temporally Deformable Alignment Network for Video Super-Resolution</b></p>
          <p><b>Yapeng Tian</b>, Yulun Zhang, Yun Fu, and Chenliang Xu</p>
          <p><i>CVPR'20: IEEE/CVF Conference on Computer Vision and Pattern Recognition.</i></p>
           <div class="paper-buttons">
            
              <a class="button" href="https://openaccess.thecvf.com/content_CVPR_2020/papers/Tian_TDAN_Temporally-Deformable_Alignment_Network_for_Video_Super-Resolution_CVPR_2020_paper.pdf" target="_blank">Paper</a>
            

            

            

            
              <a class="button" href="https://www.youtube.com/watch?v=eZExENE50I0" target="_blank">Video</a>
            

            
              <a class="button" href="https://github.com/YapengTian/TDAN-VSR-CVPR-2020" target="_blank">Code</a>
            

            

            

          </div>
        </div>
      
    </div> -->
<!-- 
    <div class="tab-pane active" id="papers-imagerestoration">
      
      
        <div class="paper">
          <p class="title"><b>Knowledge Distillation based Degradation Estimation for Blind Super-Resolution</b></p>
          <p>Bin Xia, Yulun Zhang, Yitong Wang, <b>Yapeng Tian</b>, Wenming Yang, Radu Timofte, Luc Van Gool</p>
          <p><i>ICLR'23: International Conference on Learning Representations.</i></p>
           <div class="paper-buttons">
            
              <a class="button" href="https://arxiv.org/abs/2211.16928" target="_blank">Paper</a>
            

            

            

            

            

            

            

          </div>
        </div>
      
        <div class="paper">
          <p class="title"><b>Basic Binary Convolution Unit for Binarized Image Restoration Network</b></p>
          <p>Bin Xia, Yulun Zhang, Yitong Wang, <b>Yapeng Tian</b>, Wenming Yang, Radu Timofte, Luc Van Gool</p>
          <p><i>ICLR'23: International Conference on Learning Representations.</i></p>
           <div class="paper-buttons">
            
              <a class="button" href="https://arxiv.org/pdf/2210.00405.pdf" target="_blank">Paper</a>
            

            

            

            

            

            

            

          </div>
        </div>
      
        <div class="paper">
          <p class="title"><b>DuDoCAF: Dual-Domain Cross-Attention Fusion with Recurrent Transformer for Fast Multi-contrast MR Imaging</b></p>
          <p>Jun Lyu, Bin Sui, Chengyan Wang, <b>Yapeng Tian</b>, Qi Dou, and Jing Qin</p>
          <p><i>MICCAI'22: Medical Image Computing and Computer Assisted Intervention. </i></p>
           <div class="paper-buttons">
            
              <a class="button" href="/assets/publications/2022_dudocaf/paper.pdf" target="_blank">Paper</a>
            

            

            

            

            

            

            

          </div>
        </div>
      
        <div class="paper">
          <p class="title"><b>Transformer-empowered Multi-contrast MRI Super-Resolution</b></p>
          <p>Guangyuan Li, Jun Lv, <b>Yapeng Tian</b>, Qi Dou, Chengyan Wang, Chenliang Xu, Jing Qin</p>
          <p><i>CVPR'22: IEEE/CVF Conference on Computer Vision and Pattern Recognition.</i></p>
           <div class="paper-buttons">
            
              <a class="button" href="https://arxiv.org/pdf/2203.13963.pdf" target="_blank">Paper</a>
            

            

            

            

            
              <a class="button" href="https://github.com/XAIMI-Lab/McMRSR" target="_blank">Code</a>
            

            

            

          </div>
        </div>
      
        <div class="paper">
          <p class="title"><b>Coarse-to-Fine Embedded PatchMatch and Multi-Scale Dynamic Aggregation for Reference-based Super-Resolution</b></p>
          <p>Bin Xia, <b>Yapeng Tian</b>, Yucheng Hang, Wenming Yang, Qingmin Liao, Jie Zhou</p>
          <p><i>AAAI'22: The AAAI Conference on Artificial Intelligence.</i></p>
           <div class="paper-buttons">
            
              <a class="button" href="https://arxiv.org/pdf/2201.04358.pdf" target="_blank">Paper</a>
            

            

            

            

            
              <a class="button" href="https://github.com/Zj-BinXia/AMSA" target="_blank">Code</a>
            

            

            

          </div>
        </div>
      
        <div class="paper">
          <p class="title"><b>Efficient Non-Local Contrastive Attention for Image Super-Resolution</b></p>
          <p>Bin Xia<sup>‡</sup>, Yucheng Hang<sup>‡</sup>, <b>Yapeng Tian</b>, Wenming Yang, Qingmin Liao, Jie Zhou</p>
          <p><i>AAAI'22: The AAAI Conference on Artificial Intelligence. </i></p>
           <div class="paper-buttons">
            
              <a class="button" href="https://arxiv.org/pdf/2201.03794.pdf" target="_blank">Paper</a>
            

            

            

            

            
              <a class="button" href="https://github.com/Zj-BinXia/ENLCA" target="_blank">Code</a>
            

            

            

          </div>
        </div>
      
        <div class="paper">
          <p class="title"><b>Residual Dense Network for Image Super-Resolution</b></p>
          <p>Yulun Zhang, <b>Yapeng Tian</b>, Yu Kong , Bineng Zhong, Yun Fu</p>
          <p><i>TPAMI'20: IEEE Transactions on Pattern Analysis and Machine Intelligence.</i></p>
           <div class="paper-buttons">
            
              <a class="button" href="https://arxiv.org/pdf/1812.10477.pdf" target="_blank">Paper</a>
            

            

            

            

            
              <a class="button" href="https://github.com/yulunzhang/RDN" target="_blank">Code</a>
            

            

            

          </div>
        </div>
      
        <div class="paper">
          <p class="title"><b>CFSNet: Toward a Controllable Feature Space for Image Restoration</b></p>
          <p>Wei Wang<sup>‡</sup>, Ruiming Guo<sup>‡</sup>, <b>Yapeng Tian</b>, and Wenming Yang</p>
          <p><i>ICCV'19: IEEE/CVF International Conference on Computer Vision.</i></p>
           <div class="paper-buttons">
            
              <a class="button" href="https://arxiv.org/pdf/1904.00634.pdf" target="_blank">Paper</a>
            

            

            

            

            
              <a class="button" href="https://github.com/qibao77/CFSNet" target="_blank">Code</a>
            

            

            

          </div>
        </div>
      
        <div class="paper">
          <p class="title"><b>LCSCNet: Linear Compressing Based Skip-Connecting Network for ISR</b></p>
          <p>Wenming Yang, Xuechen Zhang, <b>Yapeng Tian</b>, Wei Wang, Jing-Hao Xue, Qingmin Liao</p>
          <p><i>TIP'19: IEEE Trans. Image Processing.</i></p>
           <div class="paper-buttons">
            
              <a class="button" href="https://arxiv.org/abs/1909.03573" target="_blank">Paper</a>
            

            

            

            

            

            

            

          </div>
        </div>
      
        <div class="paper">
          <p class="title"><b>Deep Learning for Single Image Super-Resolution: A Brief Review</b></p>
          <p>Wenming Yang, Xuechen Zhang, <b>Yapeng Tian</b>, Wei Wang, JingHao Xue, Qingmin Liao</p>
          <p><i>TMM'19: IEEE Trans. Multimedia.</i></p>
           <div class="paper-buttons">
            
              <a class="button" href="https://arxiv.org/pdf/1808.03344.pdf" target="_blank">Paper</a>
            

            

            

            

            

            

            

          </div>
        </div>
      
        <div class="paper">
          <p class="title"><b>Residual Dense Network for Image Super-Resolution</b></p>
          <p>Yulun Zhang, <b>Yapeng Tian</b>, Yu Kong , Bineng Zhong, Yun Fu</p>
          <p><i>CVPR'18 Spotlight: IEEE/CVF Conf. on Computer Vision and Pattern Recognition.</i></p>
           <div class="paper-buttons">
            
              <a class="button" href="https://arxiv.org/pdf/1802.08797.pdf" target="_blank">Paper</a>
            

            

            

            

            
              <a class="button" href="https://github.com/yulunzhang/RDN" target="_blank">Code</a>
            

            

            

          </div>
        </div>
      
        <div class="paper">
          <p class="title"><b>NTIRE 2017 Challenge on Single Image Super-Resolution: Methods and Results</b></p>
          <p>Timofte et al.</p>
          <p><i>CVPRW'17: CVPR Workshops.</i></p>
           <div class="paper-buttons">
            
              <a class="button" href="https://people.ee.ethz.ch/~timofter/publications/Timofte-CVPRW-2017.pdf" target="_blank">Paper</a>
            

            

            

            

            

            

            

          </div>
        </div>
      
        <div class="paper">
          <p class="title"><b>Consistent Coding Scheme for Single-Image Super-Resolution</b></p>
          <p>Wenming Yang, <b>Yapeng Tian</b>, Fei Zhou, Qingmin Liao, Hai Chen, Chenglin Zheng</p>
          <p><i>TMM'16: EEE Trans. Multimedia. (First student author)</i></p>
           <div class="paper-buttons">
            
              <a class="button" href="https://drive.google.com/file/d/1MpEM5qmSJi1GtY9TftNNV0cgSHqMT_KQ/view" target="_blank">Paper</a>
            

            

            

            

            

            

            

          </div>
        </div>
      
        <div class="paper">
          <p class="title"><b>Anchored Neighborhood Regression based SISR from Self-examples</b></p>
          <p><b>Yapeng Tian</b>, Fei Zhou, Wenming Yang, Xuesen Shang, Qingmin Liao</p>
          <p><i>ICIP'16: IEEE International Conference on Image Processing.</i></p>
           <div class="paper-buttons">
            
              <a class="button" href="https://drive.google.com/file/d/1Ts_gYIp57llzK53Wyt7hwu4lZ9GQsbis/view" target="_blank">Paper</a>
            

            

            

            

            
              <a class="button" href="https://github.com/YapengTian/ICIP2016" target="_blank">Code</a>
            

            

            

          </div>
        </div>
      
        <div class="paper">
          <p class="title"><b>SISR Using Clustering-Based Global Regression and Propagation Filtering</b></p>
          <p>Wenming Yang, <b>Yapeng Tian</b>, Fei Zhou, ..., Qingmin Liao</p>
          <p><i>ACPR'15 Oral: Asian Conference on Pattern Recognition. (First student author)</i></p>
           <div class="paper-buttons">
            
              <a class="button" href="https://drive.google.com/file/d/12tqTHt0aLn7-B1jEgEJBYY64uhwfEezA/view" target="_blank">Paper</a>
            

            

            

            

            

            

            

          </div>
        </div>
      
    </div> -->

    

    

    


   

  </div>
</div>
</div>

<!-- ========== PROJECTS ========== 
<div class="docs-section" id="projects">
  <h4>Projects</h4>

  <ul class="tab-nav">
    <li><div class="button active" data-ref="#projects-selected">Selected</div></li>
    <li><div class="button" data-ref="#projects-all">All</div></li>
  </ul>

  <div class="tab-content">
    <div class="tab-pane active" id="projects-selected">
      
      
        
        
          <div class="row">
        

          <div class="four columns">
            <div class="project-container">

                <div class="project-image-container">
                  <a href="projects/2016_network-ab-testing.html">
                    <img src="assets/projects/2016_network-ab/thumbnail.jpg" class="u-max-full-width" />
                  </a>
                </div>

                <div class="project-caption">
                  <b>Detecting Network Effects</b> <br/>
                  Randomizing Over Randomized Experiments
                </div>

            </div>
          </div>

        
      
        
        

          <div class="four columns">
            <div class="project-container">

                <div class="project-image-container">
                  <a href="projects/2016_human-atlas.html">
                    <img src="assets/projects/2016_human-atlas/thumbnail.png" class="u-max-full-width" />
                  </a>
                </div>

                <div class="project-caption">
                  <b>Human Atlas</b> <br/>
                  Tool for Mapping Social Networks
                </div>

            </div>
          </div>

        
      
        
        

          <div class="four columns">
            <div class="project-container">

                <div class="project-image-container">
                  <a href="projects/2015_jun.html">
                    <img src="assets/projects/2015_jun/thumbnail.png" class="u-max-full-width" />
                  </a>
                </div>

                <div class="project-caption">
                  <b>Responsive Communities</b> <br/>
                  Pilot project in Jun, Spain
                </div>

            </div>
          </div>

        
          </div>
        
      
    </div>

    <div class="tab-pane" id="projects-all">
      
        
        
          <div class="row">
        

          <div class="four columns">
            <div class="project-container">

                <div class="project-image-container">
                  <a href="projects/2016_network-ab-testing.html">
                    <img src="assets/projects/2016_network-ab/thumbnail.jpg" class="u-max-full-width" />
                  </a>
                </div>

                <div class="project-caption">
                  <b>Detecting Network Effects</b> <br/>
                  Randomizing Over Randomized Experiments
                </div>

            </div>
          </div>

        
      
        
        

          <div class="four columns">
            <div class="project-container">

                <div class="project-image-container">
                  <a href="projects/2016_human-atlas.html">
                    <img src="assets/projects/2016_human-atlas/thumbnail.png" class="u-max-full-width" />
                  </a>
                </div>

                <div class="project-caption">
                  <b>Human Atlas</b> <br/>
                  Tool for Mapping Social Networks
                </div>

            </div>
          </div>

        
      
        
        

          <div class="four columns">
            <div class="project-container">

                <div class="project-image-container">
                  <a href="projects/2015_jun.html">
                    <img src="assets/projects/2015_jun/thumbnail.png" class="u-max-full-width" />
                  </a>
                </div>

                <div class="project-caption">
                  <b>Responsive Communities</b> <br/>
                  Pilot project in Jun, Spain
                </div>

            </div>
          </div>

        
          </div>
        
      
        
        
          <div class="row">
        

          <div class="four columns">
            <div class="project-container">

                <div class="project-image-container">
                  <a href="projects/2014_item-cold-start.html">
                    <img src="assets/projects/2014_item-cold-start/thumbnail.jpg" class="u-max-full-width" />
                  </a>
                </div>

                <div class="project-caption">
                  <b>Cold-Start Recommendations</b> <br/>
                  Learning Local Collective Embeddings
                </div>

            </div>
          </div>

        
      
        
        

          <div class="four columns">
            <div class="project-container">

                <div class="project-image-container">
                  <a href="projects/2013_iterative-hybrid-algorithm.html">
                    <img src="assets/projects/2013_iterative-hybrid-algorithm/thumbnail.jpg" class="u-max-full-width" />
                  </a>
                </div>

                <div class="project-caption">
                  <b>Semi-supervised Learning</b> <br/>
                  Iterative Hybrid Algorithm
                </div>

            </div>
          </div>

        
      
        
        

          <div class="four columns">
            <div class="project-container">

                <div class="project-image-container">
                  <a href="projects/2011_twitter-sentiment-analysis.html">
                    <img src="assets/projects/2011_twitter-sentiment-analysis/thumbnail.png" class="u-max-full-width" />
                  </a>
                </div>

                <div class="project-caption">
                  <b>Twitter Sentiment Analysis</b> <br/>
                  Analyzing Financial Tweets
                </div>

            </div>
          </div>

        
          </div>
        
      
        
        
          <div class="row">
        

          <div class="four columns">
            <div class="project-container">

                <div class="project-image-container">
                  <a href="projects/2010_wordnet-contruction.html">
                    <img src="assets/projects/2010_wordnet-construction/thumbnail.jpg" class="u-max-full-width" />
                  </a>
                </div>

                <div class="project-caption">
                  <b>Wordnet Construction</b> <br/>
                  Automatic Wordnet Construction using Language Models
                </div>

            </div>
          </div>

        
      
        
        

          <div class="four columns">
            <div class="project-container">

                <div class="project-image-container">
                  <a href="projects/2010_fingerprint-verification.html">
                    <img src="assets/projects/2010_fingerprint-verification/thumbnail.png" class="u-max-full-width" />
                  </a>
                </div>

                <div class="project-caption">
                  <b>Fingerprint Verification</b> <br/>
                  Image processing class project
                </div>

            </div>
          </div>

        
      
        
        

          <div class="four columns">
            <div class="project-container">

                <div class="project-image-container">
                  <a href="projects/2009_connect-four.html">
                    <img src="assets/projects/2009_connect-four/thumbnail.png" class="u-max-full-width" />
                  </a>
                </div>

                <div class="project-caption">
                  <b>Connect Four AI Agent</b> <br/>
                  Iterative deepening and alpha-beta pruning
                </div>

            </div>
          </div>

        
          </div>
        
      
    </div>
  </div>

</div>
-->

<!-- ========== PUBLICATIONS ========== -->
<span class="anchor" id="teaching"></span>
<div class="docs-section">
<div class="docs-section">
  <h4>Teaching</h4>

  <ul class="STYLE238">
    <li> Spring 2023 - CS 6384.001: <a href=/t/6384S23/ target="_blank">Computer Vision</a> (UT Dallas) </li>
    <li> Fall 2022 - CS 6334: <a href=/t/6334F22/ target="_blank">Virtual Reality</a> (UT Dallas) </li>
    
  </ul>

  <!-- <ul class="STYLE238">
    <li> Spring 2019 - <a href="https://www.cs.rochester.edu/~cxu22/t/249S19/">CSC 249/449: Machine Vision</a> (University of Rochester) </li>
    <li> Fall 2018 - <a href="https://www.cs.rochester.edu/~cxu22/t/577F18/">CSC 577: Advanced Topics in Computer Vision,</a> (University of Rochester) </li>
    <li> Spring 2018 - <a href="https://www.cs.rochester.edu/~cxu22/t/249S18/">CSC 249/449: Machine Vision</a> (University of Rochester) </li>
    <li> Fall 2016 - Advanced Image Processing and Its Applications (Tsinghua University) </li>
    <li> Spring 2016 - Digital Image Processing (Tsinghua University) </li>

  </ul>

    <p style="text-align:left"><b>Guest Lecturer:</b></p>
    <ul class="STYLE238">
      <li> Spring 2021 - <a href="https://www.cs.rochester.edu/~cxu22/t/577S21/">CSC 577: Advanced Topics in Computer Vision,</a> (University of Rochester) </li>
      <li> Fall 2020 - <a href="https://www.cs.rochester.edu/~cxu22/t/249F20/">CSC 249/449: Machine Vision</a> (University of Rochester) </li>
    </ul> -->





</div>
</div>

<!-- ========== Professional Activities ========== -->
<span class="anchor" id="activity"></span>
<div class="docs-section">
<div class="docs-section">
  <h4>Service</h4>

  <p>
    <b>Organizer:</b>
    </p>
    <ul class="STYLE238">
      <li>Tutorial on <a href="https://audio-visual-scene-understanding.github.io/">Audio-Visual Scene Understanding</a>, CVPR 2021 </li>
      <li>Tutorial on <a href="https://echo0409.github.io/Audio-Visual-Scene-Understanding/">Audio-Visual Scene Understanding</a>, WACV 2021 </li>
    </ul>

  
  <p style="text-align:left"><b>Senior Program Committee or Area Chair:</b></p>
  <ul class="STYLE238">
    <li>AAAI: AAAI Conference on Artificial Intelligence, 2023</li>
  </ul>

    
  <p style="text-align:left"><b>Session Chair:</b></p>
  <ul class="STYLE238">
    <li>AAAI 2023 (Multimodal Learning, Low-Level & Physics-based Vision)</li>
  </ul>

  <p style="text-align:left"><b>Conference Program Committee/Reviewer:</b></p>
  <ul class="STYLE238">
    <li>CVPR: IEEE/CVF Conference on Computer Vision and Pattern Recognition </li>
    <li>ICCV: IEEE/CVF International Conference on Computer Vision</li>
    <li>ECCV: European Conference on Computer Vision </li>
    <li>NeurIPS: Conference on Neural Information Processing Systems  </li>
    <li>ICLR: International Conference on Learning Representations </li>
    <li>AAAI: AAAI Conference on Artificial Intelligence</li>
    <li>ICML: International Conference on Machine Learning </li>
    <li>WACV: Winter Conference on Applications of Computer Vision</li>
    <li>ACCV: Asian Conference on Computer Vision</li>
  </ul>

  <p style="text-align:left"><b>Journal Reviewer:</b></p>
  <ul class="STYLE238">
    <li>TPAMI: IEEE Transactions on Pattern Analysis and Machine Intelligence  </li>
    <li> TMLR: The Transactions on Machine Learning Research  </li>
    <li>TIP: IEEE Transactions on Image Processing  </li>
    <li>TNNLS: IEEE Transactions on Neural Networks and Learning Systems  </li>
    <li> TMM: IEEE Transactions on Multimedia </li>
    <li>TCSVT: IEEE Transcations on Circuits and Systems for Video Technology  </li>
    <li>TASLP: IEEE/ACM Transactions on Audio, Speech and Language Processing </li>
    <li>Scientific Reports–Nature  </li>
    <li>CGF: Computer Graphics Forum </li>
    <li>CVIU: Computer Vision and Image Understanding </li>
    <li>SPIC: Signal Processing: Image Communication </li>
    <li> IEEE Access</li>

  </ul>

  <p style="text-align:left"><b>Talks and Seminars:</b></p>
  <ul class="STYLE238">
    <li> Audio-Visual Scene Understanding Towards Unified, Explainable, and Robust Multisensory Perception 
      <p style = "text-indent:0.5cm;"> KTH Dive-Deep Seminar, Dec. 2021<br>
        &nbsp;&nbsp;&nbsp;&nbsp; RIT PhD Colloquium Series, Oct. 2021</p>
    </li>
    <li>Audio-Visual Video Understanding, IIAI Seminar, Sep. 2021 </li>
    <li>The Future of Audio-Visual Research Panel Discussion, VALSE Webinar, Nov. 2021 </li>
    <li>Human-Multisensory AI Collaboration: Opportunities and Challenges, <a href="https://av4d.org/">AV4D Workshop</a> @ ECCV, Oct. 2022 </li>
    
  </ul>
  

</div>
</div>

<!-- ========== Awards ========== -->
<span class="anchor" id="award"></span>
<div class="docs-section">
<div class="docs-section">
  <h4>Awards</h4>
    <p>
      AAAI New Faculty Highlights, 2023<br>
      CVPR Doctoral Consortium, 2022<br>
      Top 10% of High-Scoring Reviewers for NeurIPS, 2020<br>
      Outstanding Graduate of Tsinghua University, 2017  <br>
      Outstanding Master Thesis Award, Tsinghua University, 2017  <br>
      National Scholarship, Tsinghua University, 2016 <br>
    </p>


</div>
</div>


<!-- ========== RESUME ========== -->
<span class="anchor" id="resume"></span>
<div class="docs-section">
<div class="docs-section">
  <h4>Vitæ</h4>

  <p>Full CV in <a href=/assets/cv/cv_web.pdf target="_blank">PDF</a>.</p>

  <!-- The Timeline -->
  <ul class="timeline">
    
    <li>
      
      <div class="direction-r">
      
        <div class="flag-wrapper">
          <span class="flag">University of Texas at Dallas</span>
          <span class="time-wrapper"><span class="time">2022 - now</span></span>
        </div>
        <div class="desc"><b>Assistant Professor</b> <br/> Department of Computer Science</div>
      </div>
    </li>
    
    <li>
      
      <div class="direction-r">
      
        <div class="flag-wrapper">
          <span class="flag">University of Rochester</span>
          <span class="time-wrapper"><span class="time">2017 - 2022</span></span>
        </div>
        <div class="desc"><b>Ph.D. Student</b> <br/> Department of Computer Science</div>
      </div>
    </li>
    
    <li>
      
      <div class="direction-l">
      
        <div class="flag-wrapper">
          <span class="flag">Meta</span>
          <span class="time-wrapper"><span class="time">Sep. 2021 - Jan. 2022</span></span>
        </div>
        <div class="desc"><b>Research Intern</b> <br/> Reality Labs</div>
      </div>
    </li>
    
    <li>
      
      <div class="direction-l">
      
        <div class="flag-wrapper">
          <span class="flag">Adobe</span>
          <span class="time-wrapper"><span class="time">Summer 2021</span></span>
        </div>
        <div class="desc"><b>Research Intern</b> <br/> Creative Intelligence Lab</div>
      </div>
    </li>
    
    <li>
      
      <div class="direction-l">
      
        <div class="flag-wrapper">
          <span class="flag">Adobe</span>
          <span class="time-wrapper"><span class="time">Summer 2019</span></span>
        </div>
        <div class="desc"><b>Research Intern</b> <br/> Creative Intelligence Lab</div>
      </div>
    </li>
    
    <li>
      
      <div class="direction-r">
      
        <div class="flag-wrapper">
          <span class="flag">Tsinghua University</span>
          <span class="time-wrapper"><span class="time">2014-2017</span></span>
        </div>
        <div class="desc"><b>M.E. Student</b> <br/> Department of Electronic Engineering</div>
      </div>
    </li>
    
    <li>
      
      <div class="direction-l">
      
        <div class="flag-wrapper">
          <span class="flag">Chinese Academy of Sciences</span>
          <span class="time-wrapper"><span class="time">Nov. 2016- May 2017</span></span>
        </div>
        <div class="desc"><b>Visiting Student</b> <br/> Shenzhen Institutes of Advanced Technology</div>
      </div>
    </li>
    
    <li>
      
      <div class="direction-r">
      
        <div class="flag-wrapper">
          <span class="flag">Xidian University</span>
          <span class="time-wrapper"><span class="time">2009 - 2013</span></span>
        </div>
        <div class="desc"><b>B.E. Student</b> <br/> School of Electronic Engineering</div>
      </div>
    </li>
    
  </ul>
</div>
</div>

<p> This website was built with <a href="https://jekyllrb.com">jekyll</a> based on a template from <a href="http://web.media.mit.edu/~msaveski/">Martin Saveski</a>.
</p>
<!-- <a href="https://clustrmaps.com/site/19nf5" title="Visit tracker"><img src="//www.clustrmaps.com/map_v2.png?d=NHvsgfF3ADBf-LMNCTgzvH2p8lgbFk4ZF2bRwOuJgH0&cl=ffffff"></a> -->



    <div class="footer">
      <div class="row">
        <div class="four columns">
          Yapeng Tian
        </div>
        <div class="four columns">
          yapeng.tian@utdallas.edu
        </div>
        <div class="four columns">
          <span onclick="window.open('https://twitter.com/YapengTian')" style="cursor: pointer">
            <i class="fa fa-twitter" aria-hidden="true"></i>
          </span>
          <span onclick="window.open('https://www.linkedin.com/in/yapeng-tian-780795141/')" style="cursor: pointer">
            <i class="fa fa-linkedin-square" aria-hidden="true"></i>
          </span>
          <span onclick="window.open('https://github.com/YapengTian')" style="cursor: pointer">
            <i class="fa fa-github" aria-hidden="true"></i>
          </span>
          <span onclick="window.open('https://scholar.google.com/citations?user=lxCqdpoAAAAJ&hl=en')" style="cursor: pointer">
            <i class="ai ai-google-scholar ai-lg" aria-hidden="true"></i>
          </span>
          <span onclick="window.open('https://dblp.dagstuhl.de/pid/176/4020.html')" style="cursor: pointer">
            <i class="ai ai-dblp ai-lg" aria-hidden="true"></i>
          </span>
        </div>
      </div>
    </div>

  </div>

  <!-- Google Analytics -->
  <script>
  (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
  (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
  m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
  })(window,document,'script','https://www.google-analytics.com/analytics.js','ga');

  ga('create', 'G-7BR8HB30JT', 'auto');
  ga('send', 'pageview');

</script>

  <!-- do not remove -->
  <span id="62cd7b7da1aff3196fdc26b60e396df9"></span>

<!-- End Document
  –––––––––––––––––––––––––––––––––––––––––––––––––– -->
</body>
</html>
