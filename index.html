<!DOCTYPE html>
<html lang="en">
<head>

  <!-- Basic Page Needs
  –––––––––––––––––––––––––––––––––––––––––––––––––– -->
  <meta charset="utf-8">
  <title>Yapeng Tian | Home</title>
  <meta name="description" content="Yapeng Tian">
  <meta name="author" content="Yapeng Tian">


  <!-- <meta property="og:title" content="Martin Saveski" />
  <meta property="og:type" content="website" />
  <meta property="og:url" content="http://yapengtian.org/" />
  <meta property="og:site_name" content="Yapeng Tian" />
  <link rel="canonical" href="https://yapengtian.org/" /> -->

  <!-- Mobile Specific Metas
  –––––––––––––––––––––––––––––––––––––––––––––––––– -->
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">

  <!-- FONT
  –––––––––––––––––––––––––––––––––––––––––––––––––– -->
  <link href='https://fonts.googleapis.com/css?family=Raleway:400,300,600' rel='stylesheet' type='text/css'>

  <!-- CSS
  –––––––––––––––––––––––––––––––––––––––––––––––––– -->
  <link rel="stylesheet" href=/libs/external/skeleton/normalize.css>
  <link rel="stylesheet" href=/libs/external/skeleton/skeleton.css>
  <link rel="stylesheet" href=/libs/custom/my_css.css>

  <!-- JQuery
  –––––––––––––––––––––––––––––––––––––––––––––––––– -->
  <script src=/libs/external/jquery-3.1.1.min.js></script>

  <!-- Font-Awesome
  –––––––––––––––––––––––––––––––––––––––––––––––––– -->
  <link rel="stylesheet" href=/libs/external/font-awesome-4.7.0/css/font-awesome.min.css>

  <!-- Academicons
  –––––––––––––––––––––––––––––––––––––––––––––––––– -->
  <link rel="stylesheet" href=/libs/external/academicons-1.8.6/css/academicons.min.css>

  <!-- Skeleton tabs
  –––––––––––––––––––––––––––––––––––––––––––––––––– -->
  <link rel="stylesheet" href=/libs/external/skeleton_tabs/skeleton-tabs.css>
  <script src=/libs/external/skeleton_tabs/skeleton-tabs.js></script>

  <!-- Timeline
  –––––––––––––––––––––––––––––––––––––––––––––––––– -->
  <link rel="stylesheet" href=/libs/external/timeline.css>

  <!-- Scripts
  –––––––––––––––––––––––––––––––––––––––––––––––––– -->
  <!--<link rel="stylesheet" href=/libs/external/github-prettify-theme.css>-->
  <script src=/libs/custom/my_js.js></script>

  <!-- Favicon
  –––––––––––––––––––––––––––––––––––––––––––––––––– -->
  <link rel="icon" type="image/png" href=/libs/icon.png>
  <link rel="shortcut icon" type="image/png" href=/libs/icon.png>

</head>
<body>

  <!-- Primary Page Layout
  –––––––––––––––––––––––––––––––––––––––––––––––––– -->
  <div class="container">

    <section class="header">
      <div class="row">
        <div class="three columns">
          <a href="/"><img class="u-max-full-width" src='/assets/profile-pics/ytian_pic.png'></a>
        </div>
        <div class="nine columns main-description">
            <h1>Yapeng Tian</h1>
            <p>PhD student, University of Rochester</p>
            <p>yapengtian [AT] rochester.edu</p>
            <p>
              <span onclick="window.open('https://twitter.com/YapengTian')" style="cursor: pointer">
                <i class="fa fa-twitter" aria-hidden="true"></i>
              </span>

              <span onclick="window.open('https://www.linkedin.com/in/yapeng-tian-780795141/')" style="cursor: pointer">
                <i class="fa fa-linkedin-square" aria-hidden="true"></i>
              </span>

              <span onclick="window.open('https://github.com/YapengTian')" style="cursor: pointer">
                <i class="fa fa-github" aria-hidden="true"></i>
              </span>

              <span onclick="window.open('https://scholar.google.com/citations?user=lxCqdpoAAAAJ&hl=en')" style="cursor: pointer">
                <i class="ai ai-google-scholar ai-lg" aria-hidden="true"></i>
              </span>

              <span onclick="window.open('https://dblp.dagstuhl.de/pid/176/4020.html')" style="cursor: pointer">
                <i class="ai ai-dblp ai-lg" aria-hidden="true"></i>
              </span>
            </p>
        </div>
      </div>
    </section>

    <div class="navbar-spacer"></div>
    <nav class="navbar">
      <div class="container">
        <ul class="navbar-list">
          <li class="navbar-item"><a class="navbar-link" href=/index.html#bio>Bio</a></li>
          <li class="navbar-item"><a class="navbar-link" href=/index.html#news>News</a></li>
          <li class="navbar-item"><a class="navbar-link" href=/index.html#publications>Publications</a></li>
          <!-- <li class="navbar-item"><a class="navbar-link" href=/index.html#projects>Projects</a></li> -->
          <li class="navbar-item"><a class="navbar-link" href=/index.html#teaching>Teaching</a></li>
          <li class="navbar-item"><a class="navbar-link" href=/index.html#activity>Professional Activities</a></li>
          <li class="navbar-item"><a class="navbar-link" href=/index.html#award>Awards</a></li>
          <li class="navbar-item"><a class="navbar-link" href=/index.html#resume>CV</a></li>
        </ul>
      </div>
    </nav>

    <!-- ========== BIO ========== -->
<span class="anchor" id="bio"></span>
<div class="docs-section">
<div class="docs-section">
  <h4>Bio</h4>
  <p>
    I am currently a final-year PhD student in the Department of Computer Science at the University of Rochester, advised by Prof. <a href="https://www.cs.rochester.edu/u/cxu22/" target="_blank">Chenliang Xu</a>.
    </p> 

  <p>
  My research interests center around solving core <b>computer vision</b> and <b>computer audition</b> problems and applying the developed learning approaches to broad AI applications 
  in <b>multisensory perception</b>, <b>computational photography</b>, <b>robotics</b>, <b>AR/VR</b>, and <b>HCI</b>.

  My recent work has focused on designing unified, explainable, and robust multisensory perception systems 
  [<a href="https://openaccess.thecvf.com/content_ECCV_2018/papers/Yapeng_Tian_Audio-Visual_Event_Localization_ECCV_2018_paper.pdf" target="_blank">ECCV'18</a>,
  <a href="https://openaccess.thecvf.com/content_CVPRW_2019/papers/Sight%20and%20Sound/Yapeng_Tian_Audio-Visual_Interpretable_and_Controllable_Video_Captioning_CVPRW_2019_paper.pdf" target="_blank">CVPRW'19</a>,
  <a href="https://arxiv.org/pdf/2007.10558.pdf" target="_blank">ECCV'20</a>,
  <a href="https://arxiv.org/pdf/2104.02026.pdf" target="_blank">CVPR'21a</a>,
  <a href="https://arxiv.org/pdf/2104.02000.pdf" target="_blank">CVPR'21b</a>,
  <a href="https://arxiv.org/pdf/2203.14072.pdf" target="_blank">CVPR'22a</a>,
  mitigating video motions in computational photograhy
  [<a href="https://openaccess.thecvf.com/content_CVPR_2020/papers/Tian_TDAN_Temporally-Deformable_Alignment_Network_for_Video_Super-Resolution_CVPR_2020_paper.pdf" target="_blank">CVPR'20a</a>, 
  <a href="https://arxiv.org/pdf/2002.11616.pdf" target="_blank">CVPR'20b</a>], 
  and improving image quality
  [<a href="https://arxiv.org/pdf/1802.08797.pdf" target="_blank">CVPR'18</a>
  <a href="https://arxiv.org/pdf/2203.13963.pdf" target="_blank">CVPR'22b</a>]. 
  <!-- My research often falls at the intersections of Social Networks, Machine Learning, and Causal Inference. -->
  </p>

  <p>
    Previously, I received my master degree in the Department of Electronic Engineering, Tsinghua University, China, in 2017 under the supervision of Prof. <a href="http://www.fiesta.tsinghua.edu.cn/pi/2/10" target="_blank">Wenming Yang</a>, and B.E degree from School of Electronic Engineering, Xidian University in 2013.
    I was a visiting student at Shenzhen Institutes of Advanced Technology, Chinese Academy of Sciences, advised by Prof. <a href="https://scholar.google.com/citations?user=gFtI-8QAAAAJ&hl=en" target="_blank">Yu Qiao</a> in 2016-2017. I did three internships at Adobe Research and Meta Reality Labs.

  </p>

 

  <p align="justify">
    <a style="color:red;">
      I'm on the job market this year. Please reach out if you think I’d be a good fit for your academic department. 
    </a>
  </p>

  <!--
  I am a Postdoc at the department of Management Science and Engineering at Stanford University, working with <a href="https://web.stanford.edu/~jugander/" target="_blank">Johan Ugander</a>. 
  My research develops tools for analyzing large-scale social data, aiming to provide a better understanding of social structure and behaviors online while also impacting the design of digital social systems.
  My work often falls at the intersections of Social Networks, Machine Learning, and Causal Inference.
  </p>

  <p>
  I completed my Ph.D. from MIT in 2020 under the supervision of Deb Roy. 
  Before coming to MIT, I spent one year in Paris and one year in Barcelona doing a M.Sc. in Data mining and Knowledge Management. 
  I got my B.Sc. from Staffordshire University with First Class honors in Computer Science. 
  Throughout my graduate studies, I spent several summers doing internships in industry, including Yahoo! Labs, Amazon, LinkedIn, and Facebook.
  </p>
  -->
</div>
</div>

<span class="anchor" id="news"></span>
<div class="docs-section">
<div class="docs-section">
  <h4>News</h4>
  <div  style="overflow-y: scroll; height:364px;">
<table border="1" style="border-width: 0px;" width="1050">
<tbody>
<tr>
<td style="border-style: none; border-width: medium;">

<ul class="STYLE238">
  <li> 03/2022: Two works: audio-visual question answering and MRI SR are accepted by CVPR 2022. </li>
  <li> 12/2021: Two papers are accepted by AAAI 2022.</li>
<li> 10/2021: One paper on sounding object localization is accepted by BMVC 2021! </li>
<li> 07/2021: One paper on video matting is accepted by ICCV 2021! </li>
<li> 03/2021: Our two works: co-learn sounding object visual grounding and sound separation and audio-visual robustness are accepted by CVPR 2021!</li>
<li>02/2021: We will co-organize a CVPR 2021 Tutorial on Audio-visual Scene Understanding!</li>

<li>01/2021: Co-organized the WACV 2021 Tutorial on Audio-visual Scene Understanding. More details can be found in our <a href="https://echo0409.github.io/Audio-Visual-Scene-Understanding/">website</a>.</a></li>

<li>10/2020: I was in the top 10% of high-scoring reviewers for NeurIPS 2020! </li>

<li>07/2020: Our audio-visual video parsing work got accepted by ECCV 2020 as a Spotlight</a>.  </li>

<li>05/2020: Our three papers will be presented in the <a href="http://sightsound.org/">CVPR 2020 Sight and Sound workshop</a>.</li>

<li>02/2020: Two papers on video restoration got accepted by CVPR 2020! Congratulations to all co-authors! </li>

<li>01/2020: RDN is accepted by IEEE TPAMI! Congratulations to Yulun!</li>

<li>12/2019: Please check our deep audio prior paper. </li>

<li>08/2019: One paper is accepted by IEEE TIP. Congratulations to Xuechen!</li>

<li>07/2019: One paper is accepted by ICCV 2019. Congratulations to Wei! </li>

<li>05/2019: Our two works: audio-visual event localization and audio-visual video captioning will be presented in the CVPR 2019 Sight and Sound workshop.</li>

<li>02/2019: I will serve as an ICCV 2019 reviewer. </li>

<li>12/2018: Two papers are posted on ArXiv. Please watch the corresponding demos.  </li>

<li>07/2018: One paper is accepted by ECCV 2018! AVE dataset and codes have been released. </li>

<li> 02/2018: One paper is accepted by CVPR 2018. Congratulations to Yulun! </li>

<li>07/2017: I recieve '<strong>Outstanding Graduate of Tsinghua university</strong>' and '<strong>Outstanding Master Thesis Award</strong>'. </li>

<li>03/2017: I will join Prof. <a href="http://www.cs.rochester.edu/u/cxu22/">Chenliang Xu</a>'s lab to pursue a PhD degree at University of Rochester! </li>


</font>
</ul>
</td>
</tr>
</tbody>
</table>
</div>
</div>
</div>



<!-- ========== PUBLICATIONS ========== -->
<span class="anchor"  id="publications"></span>
<div class="docs-section">
<div class="docs-section">
  <h4>Publications</h4>

  <p>Most recent publications on <a href="https://scholar.google.com/citations?user=lxCqdpoAAAAJ&hl=en" target="_blank">Google Scholar</a>.<br/>
  <sup>‡</sup> indicates equal contribution.
  </p>

  <ul class="tab-nav">
    <li><div class="button active" data-ref="#papers-all" font-size: 10px style="width:40px;padding:0 0;">All</div></li>
    <li><div  class="button" data-ref="#papers-selected" font-size: 10px style="width:90px;padding:0 0;">Selected</div></li>
    <li><div class="button" data-ref="#papers-audiovisual" font-size: 10px  style="width:120px;padding:0 0;">Vision+Sound</div></li>
    <li><div class="button" data-ref="#papers-videorestoration" font-size: 10px  style="width:160px;padding:0 0;">Video Restoration</div></li>
    <li><div class="button" data-ref="#papers-imagerestoration" font-size: 10px  style="width:160px;padding:0 0;">Image Restoration</div></li>
  </ul>

  <div class="tab-content">
    <div class="tab-pane active" id="papers-all">
      
      
      <table style="table-layout: fixed;">
        <tr>
          <td><img src="/assets/publications/2022_avqa/teaser.png" width="200" height="100" /></td>
          
          <td> 
          <div dir="ltr">
        <div class="paper">
          <p class="title"><b>Learning to Answer Questions in Dynamic Audio-Visual Scenarios</b></p>
          <p>Guangyao Li<sup>‡</sup>, Yake Wei<sup>‡</sup>, <b>Yapeng Tian<sup>‡</sup></b>, Chenliang Xu, Ji-Rong Wen, and Di Hu</p>
          <p><i>CVPR'22 Oral: IEEE/CVF Conference on Computer Vision and Pattern Recognition. </i></p>
           
           <div class="paper-buttons">
            
              <a class="button" href="https://arxiv.org/pdf/2203.14072.pdf" target="_blank">Paper</a>
            

            

            

            
              <a class="button" href="https://www.youtube.com/watch?v=JH3t5gwe9Xw" target="_blank">Video</a>
            

            
              <a class="button" href="https://github.com/GeWu-Lab/MUSIC-AVQA" target="_blank">Code</a>
            

            

            
              <a class="button" href="https://gewu-lab.github.io/MUSIC-AVQA/" target="_blank">Project</a>
            

          </div>
        </div>

          </div></td>
        </tr>
      </table>
      
      <table style="table-layout: fixed;">
        <tr>
          <td><img src="/assets/publications/2022_mrisr/teaser.png" width="200" height="100" /></td>
          
          <td> 
          <div dir="ltr">
        <div class="paper">
          <p class="title"><b>Transformer-empowered Multi-scale Contextual Matching and Aggregation for Multi-contrast MRI Super-Resolution</b></p>
          <p>Guangyuan Li, Jun Lv, <b>Yapeng Tian</b>, Qi Dou, ChengyanWang, Chenliang Xu, and Jing Qin</p>
          <p><i>CVPR'22: IEEE/CVF Conference on Computer Vision and Pattern Recognition.</i></p>
           
           <div class="paper-buttons">
            
              <a class="button" href="https://arxiv.org/pdf/2203.13963.pdf" target="_blank">Paper</a>
            

            

            

            

            
              <a class="button" href="https://github.com/XAIMI-Lab/McMRSR" target="_blank">Code</a>
            

            

            

          </div>
        </div>

          </div></td>
        </tr>
      </table>
      
      <table style="table-layout: fixed;">
        <tr>
          <td><img src="/assets/publications/2022_amsa/teaser.png" width="200" height="100" /></td>
          
          <td> 
          <div dir="ltr">
        <div class="paper">
          <p class="title"><b>Coarse-to-Fine Embedded PatchMatch and Multi-Scale Dynamic Aggregation for Reference-based Super-Resolution</b></p>
          <p>Bin Xia, <b>Yapeng Tian</b>, Yucheng Hang, Wenming Yang, Qingmin Liao, Jie Zhou</p>
          <p><i>AAAI'22: The AAAI Conference on Artificial Intelligence.</i></p>
           
           <div class="paper-buttons">
            
              <a class="button" href="https://arxiv.org/pdf/2201.04358.pdf" target="_blank">Paper</a>
            

            

            

            

            
              <a class="button" href="https://github.com/Zj-BinXia/AMSA" target="_blank">Code</a>
            

            

            

          </div>
        </div>

          </div></td>
        </tr>
      </table>
      
      <table style="table-layout: fixed;">
        <tr>
          <td><img src="/assets/publications/2022_enlca/teaser.png" width="200" height="100" /></td>
          
          <td> 
          <div dir="ltr">
        <div class="paper">
          <p class="title"><b>Efficient Non-Local Contrastive Attention for Image Super-Resolution</b></p>
          <p>Bin Xia<sup>‡</sup>, Yucheng Hang<sup>‡</sup>, <b>Yapeng Tian</b>, Wenming Yang, Qingmin Liao, Jie Zhou</p>
          <p><i>AAAI'22: The AAAI Conference on Artificial Intelligence. </i></p>
           
           <div class="paper-buttons">
            
              <a class="button" href="https://arxiv.org/pdf/2201.03794.pdf" target="_blank">Paper</a>
            

            

            

            

            
              <a class="button" href="https://github.com/Zj-BinXia/ENLCA" target="_blank">Code</a>
            

            

            

          </div>
        </div>

          </div></td>
        </tr>
      </table>
      
      <table style="table-layout: fixed;">
        <tr>
          <td><img src="/assets/publications/2021_stm/teaser.png" width="200" height="100" /></td>
          
          <td> 
          <div dir="ltr">
        <div class="paper">
          <p class="title"><b>Space-Time Memory Network for Sounding Object Localization in Videos</b></p>
          <p>Sizhe Li<sup>‡</sup>, <b>Yapeng Tian<sup>‡</sup></b>, and Chenliang Xu</p>
          <p><i>BMVC'21: The British Machine Vision Conference. </i></p>
           
           <div class="paper-buttons">
            
              <a class="button" href="https://arxiv.org/pdf/2111.05526.pdf" target="_blank">Paper</a>
            

            

            

            

            
              <a class="button" href="https://github.com/lester0866/Space-Time-Memory-Network-for-Sounding-Object-Localization-in-Videos" target="_blank">Code</a>
            

            

            
              <a class="button" href="https://sites.google.com/view/bmvc2021stm" target="_blank">Project</a>
            

          </div>
        </div>

          </div></td>
        </tr>
      </table>
      
      <table style="table-layout: fixed;">
        <tr>
          <td><img src="/assets/publications/2021_matting/teaser.png" width="200" height="100" /></td>
          
          <td> 
          <div dir="ltr">
        <div class="paper">
          <p class="title"><b>Video Matting via Consistency-Regularized Graph Neural Networks</b></p>
          <p>Tiantian Wang, Sifei Liu, <b>Yapeng Tian</b>, Kai Li, and Ming-Hsuan Yang</p>
          <p><i>ICCV'21: IEEE/CVF International Conference on Computer Vision. </i></p>
           
           <div class="paper-buttons">
            
              <a class="button" href="https://faculty.ucmerced.edu/mhyang/papers/iccv2021_video_matting.pdf" target="_blank">Paper</a>
            

            

            

            

            
              <a class="button" href="https://github.com/TiantianWang/VideoMatting-CRGNN" target="_blank">Code</a>
            

            

            

          </div>
        </div>

          </div></td>
        </tr>
      </table>
      
      <table style="table-layout: fixed;">
        <tr>
          <td><img src="/assets/publications/2021_robustness/teaser.png" width="200" height="100" /></td>
          
          <td> 
          <div dir="ltr">
        <div class="paper">
          <p class="title"><b>Can audio-visual integration strengthen robustness under multimodal attacks?</b></p>
          <p><b>Yapeng Tian</b> and Chenliang Xu</p>
          <p><i>CVPR'21: IEEE/CVF Conference on Computer Vision and Pattern Recognition. </i></p>
           
           <div class="paper-buttons">
            
              <a class="button" href="https://arxiv.org/pdf/2104.02000.pdf" target="_blank">Paper</a>
            

            

            

            

            
              <a class="button" href="https://github.com/YapengTian/AV-Robustness-CVPR21" target="_blank">Code</a>
            

            

            

          </div>
        </div>

          </div></td>
        </tr>
      </table>
      
      <table style="table-layout: fixed;">
        <tr>
          <td><img src="/assets/publications/2021_ccol/teaser.png" width="200" height="100" /></td>
          
          <td> 
          <div dir="ltr">
        <div class="paper">
          <p class="title"><b>Cyclic Co-Learning of Sounding Object Visual Grounding and Sound Separation</b></p>
          <p><b>Yapeng Tian</b>, Di Hu, and Chenliang Xu</p>
          <p><i>CVPR'21: IEEE/CVF Conference on Computer Vision and Pattern Recognition.</i></p>
           
           <div class="paper-buttons">
            
              <a class="button" href="https://arxiv.org/pdf/2104.02026.pdf" target="_blank">Paper</a>
            

            

            

            

            
              <a class="button" href="https://github.com/YapengTian/CCOL-CVPR21" target="_blank">Code</a>
            

            

            

          </div>
        </div>

          </div></td>
        </tr>
      </table>
      
      <table style="table-layout: fixed;">
        <tr>
          <td><img src="/assets/publications/2020_avvp/teaser.png" width="200" height="100" /></td>
          
          <td> 
          <div dir="ltr">
        <div class="paper">
          <p class="title"><b>Unified Multisensory Perception: Weakly-Supervised Audio-Visual Video Parsing</b></p>
          <p><b>Yapeng Tian</b>, Dingzeyu Li, and Chenliang Xu</p>
          <p><i>ECCV'20 Spotlight: European Conference on Computer Vision.</i></p>
           
           <div class="paper-buttons">
            
              <a class="button" href="/assets/publications/2019_biometrika/paper.pdf" target="_blank">Paper</a>
            

            

            

            

            
              <a class="button" href="https://github.com/YapengTian/AVVP-ECCV20" target="_blank">Code</a>
            

            
              <a class="button" href="https://github.com/YapengTian/AVVP-ECCV20" target="_blank">Data</a>
            

            

          </div>
        </div>

          </div></td>
        </tr>
      </table>
      
      <table style="table-layout: fixed;">
        <tr>
          <td><img src="/assets/publications/2020_zsm/teaser.png" width="200" height="100" /></td>
          
          <td> 
          <div dir="ltr">
        <div class="paper">
          <p class="title"><b>Zooming Slow-Mo: Fast and Accurate One-Stage Space-Time Video Super-Resolution</b></p>
          <p>Xiaoyu Xiang<sup>‡</sup>, <b>Yapeng Tian<sup>‡</sup></b>, Yulun Zhang, Yun Fu, Jan Allebach, and Chenliang Xu</p>
          <p><i>CVPR'20: IEEE/CVF Conference on Computer Vision and Pattern Recognition.</i></p>
           
           <div class="paper-buttons">
            
              <a class="button" href="https://arxiv.org/pdf/2002.11616.pdf" target="_blank">Paper</a>
            

            

            

            
              <a class="button" href="https://www.youtube.com/watch?v=8mgD8JxBOus" target="_blank">Video</a>
            

            
              <a class="button" href="https://github.com/Mukosame/Zooming-Slow-Mo-CVPR-2020" target="_blank">Code</a>
            

            

            

          </div>
        </div>

          </div></td>
        </tr>
      </table>
      
      <table style="table-layout: fixed;">
        <tr>
          <td><img src="/assets/publications/2020_tdan/teaser.png" width="200" height="100" /></td>
          
          <td> 
          <div dir="ltr">
        <div class="paper">
          <p class="title"><b>TDAN: Temporally Deformable Alignment Network for Video Super-Resolution</b></p>
          <p><b>Yapeng Tian</b>, Yulun Zhang, Yun Fu, and Chenliang Xu</p>
          <p><i>CVPR'20: IEEE/CVF Conference on Computer Vision and Pattern Recognition.</i></p>
          
          <p style="color:red">This is the first work that uses deformable alignment to address video restoration.</p>
         
           <div class="paper-buttons">
            
              <a class="button" href="https://openaccess.thecvf.com/content_CVPR_2020/papers/Tian_TDAN_Temporally-Deformable_Alignment_Network_for_Video_Super-Resolution_CVPR_2020_paper.pdf" target="_blank">Paper</a>
            

            

            

            
              <a class="button" href="https://www.youtube.com/watch?v=eZExENE50I0" target="_blank">Video</a>
            

            
              <a class="button" href="https://github.com/YapengTian/TDAN-VSR-CVPR-2020" target="_blank">Code</a>
            

            

            

          </div>
        </div>

          </div></td>
        </tr>
      </table>
      
      <table style="table-layout: fixed;">
        <tr>
          <td><img src="/assets/publications/2020_dap/teaser.png" width="200" height="100" /></td>
          
          <td> 
          <div dir="ltr">
        <div class="paper">
          <p class="title"><b>Deep Audio Prior</b></p>
          <p><b>Yapeng Tian</b>, Chenliang Xu, and Dingzeyu Li</p>
          <p><i>CVPRW'20: CVPR Workshops.</i></p>
           
           <div class="paper-buttons">
            
              <a class="button" href="https://arxiv.org/pdf/1912.10292v1.pdf" target="_blank">Paper</a>
            

            

            

            

            
              <a class="button" href="https://github.com/adobe/Deep-Audio-Prior" target="_blank">Code</a>
            

            

            
              <a class="button" href="https://opensource.adobe.com/Deep-Audio-Prior/" target="_blank">Project</a>
            

          </div>
        </div>

          </div></td>
        </tr>
      </table>
      
      <table style="table-layout: fixed;">
        <tr>
          <td><img src="/assets/publications/2020_rdnpami/teaser.png" width="200" height="100" /></td>
          
          <td> 
          <div dir="ltr">
        <div class="paper">
          <p class="title"><b>Residual Dense Network for Image Super-Resolution</b></p>
          <p>Yulun Zhang, <b>Yapeng Tian</b>, Yu Kong , Bineng Zhong, Yun Fu</p>
          <p><i>TPAMI'20: IEEE Transactions on Pattern Analysis and Machine Intelligence.</i></p>
           
           <div class="paper-buttons">
            
              <a class="button" href="https://arxiv.org/pdf/1812.10477.pdf" target="_blank">Paper</a>
            

            

            

            

            
              <a class="button" href="https://github.com/yulunzhang/RDN" target="_blank">Code</a>
            

            

            

          </div>
        </div>

          </div></td>
        </tr>
      </table>
      
      <table style="table-layout: fixed;">
        <tr>
          <td><img src="/assets/publications/2019_csf/teaser.png" width="200" height="100" /></td>
          
          <td> 
          <div dir="ltr">
        <div class="paper">
          <p class="title"><b>CFSNet: Toward a Controllable Feature Space for Image Restoration</b></p>
          <p>Wei Wang<sup>‡</sup>, Ruiming Guo<sup>‡</sup>, <b>Yapeng Tian</b>, and Wenming Yang</p>
          <p><i>ICCV'19: IEEE/CVF International Conference on Computer Vision.</i></p>
           
           <div class="paper-buttons">
            
              <a class="button" href="https://arxiv.org/pdf/1904.00634.pdf" target="_blank">Paper</a>
            

            

            

            

            
              <a class="button" href="https://github.com/qibao77/CFSNet" target="_blank">Code</a>
            

            

            

          </div>
        </div>

          </div></td>
        </tr>
      </table>
      
      <table style="table-layout: fixed;">
        <tr>
          <td><img src="/assets/publications/2019_avc/teaser.png" width="200" height="100" /></td>
          
          <td> 
          <div dir="ltr">
        <div class="paper">
          <p class="title"><b>Interpretable and Controllable Audio-Visual Video Captioning</b></p>
          <p><b>Yapeng Tian</b>, Chenxiao Guan, Goodman Justin, Marc Moore, and Chenliang Xu</p>
          <p><i>CVPRW'19: CVPR Workshops.</i></p>
          
          <p style="color:red">Multisensory interpretability in terms of the audio-visual video captioning task.</p>
         
           <div class="paper-buttons">
            
              <a class="button" href="https://openaccess.thecvf.com/content_CVPRW_2019/papers/Sight%20and%20Sound/Yapeng_Tian_Audio-Visual_Interpretable_and_Controllable_Video_Captioning_CVPRW_2019_paper.pdf" target="_blank">Paper</a>
            

            

            

            

            

            

            

          </div>
        </div>

          </div></td>
        </tr>
      </table>
      
      <table style="table-layout: fixed;">
        <tr>
          <td><img src="/assets/publications/2019_lcsc/teaser.png" width="200" height="100" /></td>
          
          <td> 
          <div dir="ltr">
        <div class="paper">
          <p class="title"><b>LCSCNet: Linear Compressing Based Skip-Connecting Network for Image Super-Resolution</b></p>
          <p>Wenming Yang, Xuechen Zhang, <b>Yapeng Tian</b>, Wei Wang, Jing-Hao Xue, Qingmin Liao</p>
          <p><i>TIP'19: IEEE Trans. Image Processing.</i></p>
           
           <div class="paper-buttons">
            
              <a class="button" href="https://arxiv.org/abs/1909.03573" target="_blank">Paper</a>
            

            

            

            

            

            

            

          </div>
        </div>

          </div></td>
        </tr>
      </table>
      
      <table style="table-layout: fixed;">
        <tr>
          <td><img src="/assets/publications/2019_review/teaser.png" width="200" height="100" /></td>
          
          <td> 
          <div dir="ltr">
        <div class="paper">
          <p class="title"><b>Deep Learning for Single Image Super-Resolution: A Brief Review</b></p>
          <p>Wenming Yang, Xuechen Zhang, <b>Yapeng Tian</b>, Wei Wang, JingHao Xue, and Qingmin Liao</p>
          <p><i>TMM'19: IEEE Trans. Multimedia.</i></p>
           
           <div class="paper-buttons">
            
              <a class="button" href="https://arxiv.org/pdf/1808.03344.pdf" target="_blank">Paper</a>
            

            

            

            

            

            

            

          </div>
        </div>

          </div></td>
        </tr>
      </table>
      
      <table style="table-layout: fixed;">
        <tr>
          <td><img src="/assets/publications/2018_ave/teaser.png" width="200" height="100" /></td>
          
          <td> 
          <div dir="ltr">
        <div class="paper">
          <p class="title"><b>Audio-Visual Event Localization in Unconstrained Videos</b></p>
          <p><b>Yapeng Tian</b>, Jing Shi, Bochen Li, Zhiyao Duan, and Chenliang Xu</p>
          <p><i>ECCV'18: European Conference on Computer Vision.</i></p>
           
           <div class="paper-buttons">
            
              <a class="button" href="https://openaccess.thecvf.com/content_ECCV_2018/papers/Yapeng_Tian_Audio-Visual_Event_Localization_ECCV_2018_paper.pdf" target="_blank">Paper</a>
            

            

            

            
              <a class="button" href="https://www.youtube.com/watch?v=m6r6BbD5MSc" target="_blank">Video</a>
            

            
              <a class="button" href="https://github.com/YapengTian/AVE-ECCV18" target="_blank">Code</a>
            

            
              <a class="button" href="https://drive.google.com/file/d/1FjKwe79e0u96vdjIVwfRQ1V6SoDHe7kK" target="_blank">Data</a>
            

            
              <a class="button" href="https://sites.google.com/view/audiovisualresearch" target="_blank">Project</a>
            

          </div>
        </div>

          </div></td>
        </tr>
      </table>
      
      <table style="table-layout: fixed;">
        <tr>
          <td><img src="/assets/publications/2018_rdn/teaser.png" width="200" height="100" /></td>
          
          <td> 
          <div dir="ltr">
        <div class="paper">
          <p class="title"><b>Residual Dense Network for Image Super-Resolution</b></p>
          <p>Yulun Zhang, <b>Yapeng Tian</b>, Yu Kong , Bineng Zhong, Yun Fu</p>
          <p><i>CVPR'18 Spotlight: IEEE/CVF Conf. on Computer Vision and Pattern Recognition.</i></p>
           
           <div class="paper-buttons">
            
              <a class="button" href="https://arxiv.org/pdf/1802.08797.pdf" target="_blank">Paper</a>
            

            

            

            

            
              <a class="button" href="https://github.com/yulunzhang/RDN" target="_blank">Code</a>
            

            

            

          </div>
        </div>

          </div></td>
        </tr>
      </table>
      
      <table style="table-layout: fixed;">
        <tr>
          <td><img src="/assets/publications/2017_ntire/teaser.png" width="200" height="100" /></td>
          
          <td> 
          <div dir="ltr">
        <div class="paper">
          <p class="title"><b>NTIRE 2017 Challenge on Single Image Super-Resolution: Methods and Results</b></p>
          <p>Radu Timofte, Eirikur Agustsson, Luc Van Gool, ..., Xintao Wang, <b>Yapeng Tian</b>, Ke Yu, Yulun Zhang, Shixiang Wu, Chao Dong, Liang Lin, Yu Qiao, ...</p>
          <p><i>CVPRW'17: CVPR Workshops.</i></p>
           
           <div class="paper-buttons">
            
              <a class="button" href="https://people.ee.ethz.ch/~timofter/publications/Timofte-CVPRW-2017.pdf" target="_blank">Paper</a>
            

            

            

            

            

            

            

          </div>
        </div>

          </div></td>
        </tr>
      </table>
      
      <table style="table-layout: fixed;">
        <tr>
          <td><img src="/assets/publications/2016_ccs/teaser.png" width="200" height="100" /></td>
          
          <td> 
          <div dir="ltr">
        <div class="paper">
          <p class="title"><b>Consistent Coding Scheme for Single-Image Super-Resolution Via Independent Dictionaries</b></p>
          <p>Wenming Yang, <b>Yapeng Tian</b>, Fei Zhou*, Qingmin Liao, Hai Chen and Chenglin Zheng</p>
          <p><i>TMM'16: EEE Trans. Multimedia.</i></p>
           
           <div class="paper-buttons">
            
              <a class="button" href="https://drive.google.com/file/d/1MpEM5qmSJi1GtY9TftNNV0cgSHqMT_KQ/view" target="_blank">Paper</a>
            

            

            

            

            

            

            

          </div>
        </div>

          </div></td>
        </tr>
      </table>
      
      <table style="table-layout: fixed;">
        <tr>
          <td><img src="/assets/publications/2016_anrse/teaser.png" width="200" height="100" /></td>
          
          <td> 
          <div dir="ltr">
        <div class="paper">
          <p class="title"><b>Anchored Neighborhood Regression based Single Image Super-Resolution from Self-examples</b></p>
          <p><b>Yapeng Tian</b>, Fei Zhou, Wenming Yang*, Xuesen Shang and Qingmin Liao</p>
          <p><i>ICIP'16: IEEE International Conference on Image Processing.</i></p>
           
           <div class="paper-buttons">
            
              <a class="button" href="https://drive.google.com/file/d/1Ts_gYIp57llzK53Wyt7hwu4lZ9GQsbis/view" target="_blank">Paper</a>
            

            

            

            

            
              <a class="button" href="https://github.com/YapengTian/ICIP2016" target="_blank">Code</a>
            

            

            

          </div>
        </div>

          </div></td>
        </tr>
      </table>
      
      <table style="table-layout: fixed;">
        <tr>
          <td><img src="/assets/publications/2015_pfsr/teaser.png" width="200" height="100" /></td>
          
          <td> 
          <div dir="ltr">
        <div class="paper">
          <p class="title"><b>Single-Image Super-Resolution Using Clustering-Based Global Regression and Propagation Filtering</b></p>
          <p>Wenming Yang, <b>Yapeng Tian</b>, Fei Zhou, Tingrong Yuan, Xuesen Shang and QingminLiao</p>
          <p><i>ACPR'15 Oral: Asian Conference on Pattern Recognition.</i></p>
           
           <div class="paper-buttons">
            
              <a class="button" href="https://drive.google.com/file/d/12tqTHt0aLn7-B1jEgEJBYY64uhwfEezA/view" target="_blank">Paper</a>
            

            

            

            

            

            

            

          </div>
        </div>

          </div></td>
        </tr>
      </table>
      
    </div>


    <div class="tab-pane active" id="papers-selected">
      
      
      <table border="0">
        <tr>
          <td><img src="/assets/publications/2022_avqa/teaser.png" width="200" height="100" /></td>
          
          <td> 
          <div dir="ltr">
        <div class="paper">
          <p class="title"><b>Learning to Answer Questions in Dynamic Audio-Visual Scenarios</b></p>
          <p>Guangyao Li<sup>‡</sup>, Yake Wei<sup>‡</sup>, <b>Yapeng Tian<sup>‡</sup></b>, Chenliang Xu, Ji-Rong Wen, and Di Hu</p>
          <p><i>CVPR'22 Oral: IEEE/CVF Conference on Computer Vision and Pattern Recognition. </i></p>
           
           <div class="paper-buttons">
            
              <a class="button" href="https://arxiv.org/pdf/2203.14072.pdf" target="_blank">Paper</a>
            

            

            

            
              <a class="button" href="https://www.youtube.com/watch?v=JH3t5gwe9Xw" target="_blank">Video</a>
            

            
              <a class="button" href="https://github.com/GeWu-Lab/MUSIC-AVQA" target="_blank">Code</a>
            

            

            
              <a class="button" href="https://gewu-lab.github.io/MUSIC-AVQA/" target="_blank">Project</a>
            

          </div>
        </div>

          </div></td>
        </tr>
      </table>
      
      <table border="0">
        <tr>
          <td><img src="/assets/publications/2021_stm/teaser.png" width="200" height="100" /></td>
          
          <td> 
          <div dir="ltr">
        <div class="paper">
          <p class="title"><b>Space-Time Memory Network for Sounding Object Localization in Videos</b></p>
          <p>Sizhe Li<sup>‡</sup>, <b>Yapeng Tian<sup>‡</sup></b>, and Chenliang Xu</p>
          <p><i>BMVC'21: The British Machine Vision Conference. </i></p>
           
           <div class="paper-buttons">
            
              <a class="button" href="https://arxiv.org/pdf/2111.05526.pdf" target="_blank">Paper</a>
            

            

            

            

            
              <a class="button" href="https://github.com/lester0866/Space-Time-Memory-Network-for-Sounding-Object-Localization-in-Videos" target="_blank">Code</a>
            

            

            
              <a class="button" href="https://sites.google.com/view/bmvc2021stm" target="_blank">Project</a>
            

          </div>
        </div>

          </div></td>
        </tr>
      </table>
      
      <table border="0">
        <tr>
          <td><img src="/assets/publications/2021_robustness/teaser.png" width="200" height="100" /></td>
          
          <td> 
          <div dir="ltr">
        <div class="paper">
          <p class="title"><b>Can audio-visual integration strengthen robustness under multimodal attacks?</b></p>
          <p><b>Yapeng Tian</b> and Chenliang Xu</p>
          <p><i>CVPR'21: IEEE/CVF Conference on Computer Vision and Pattern Recognition. </i></p>
           
           <div class="paper-buttons">
            
              <a class="button" href="https://arxiv.org/pdf/2104.02000.pdf" target="_blank">Paper</a>
            

            

            

            

            
              <a class="button" href="https://github.com/YapengTian/AV-Robustness-CVPR21" target="_blank">Code</a>
            

            

            

          </div>
        </div>

          </div></td>
        </tr>
      </table>
      
      <table border="0">
        <tr>
          <td><img src="/assets/publications/2021_ccol/teaser.png" width="200" height="100" /></td>
          
          <td> 
          <div dir="ltr">
        <div class="paper">
          <p class="title"><b>Cyclic Co-Learning of Sounding Object Visual Grounding and Sound Separation</b></p>
          <p><b>Yapeng Tian</b>, Di Hu, and Chenliang Xu</p>
          <p><i>CVPR'21: IEEE/CVF Conference on Computer Vision and Pattern Recognition.</i></p>
           
           <div class="paper-buttons">
            
              <a class="button" href="https://arxiv.org/pdf/2104.02026.pdf" target="_blank">Paper</a>
            

            

            

            

            
              <a class="button" href="https://github.com/YapengTian/CCOL-CVPR21" target="_blank">Code</a>
            

            

            

          </div>
        </div>

          </div></td>
        </tr>
      </table>
      
      <table border="0">
        <tr>
          <td><img src="/assets/publications/2020_avvp/teaser.png" width="200" height="100" /></td>
          
          <td> 
          <div dir="ltr">
        <div class="paper">
          <p class="title"><b>Unified Multisensory Perception: Weakly-Supervised Audio-Visual Video Parsing</b></p>
          <p><b>Yapeng Tian</b>, Dingzeyu Li, and Chenliang Xu</p>
          <p><i>ECCV'20 Spotlight: European Conference on Computer Vision.</i></p>
           
           <div class="paper-buttons">
            
              <a class="button" href="/assets/publications/2019_biometrika/paper.pdf" target="_blank">Paper</a>
            

            

            

            

            
              <a class="button" href="https://github.com/YapengTian/AVVP-ECCV20" target="_blank">Code</a>
            

            
              <a class="button" href="https://github.com/YapengTian/AVVP-ECCV20" target="_blank">Data</a>
            

            

          </div>
        </div>

          </div></td>
        </tr>
      </table>
      
      <table border="0">
        <tr>
          <td><img src="/assets/publications/2020_zsm/teaser.png" width="200" height="100" /></td>
          
          <td> 
          <div dir="ltr">
        <div class="paper">
          <p class="title"><b>Zooming Slow-Mo: Fast and Accurate One-Stage Space-Time Video Super-Resolution</b></p>
          <p>Xiaoyu Xiang<sup>‡</sup>, <b>Yapeng Tian<sup>‡</sup></b>, Yulun Zhang, Yun Fu, Jan Allebach, and Chenliang Xu</p>
          <p><i>CVPR'20: IEEE/CVF Conference on Computer Vision and Pattern Recognition.</i></p>
           
           <div class="paper-buttons">
            
              <a class="button" href="https://arxiv.org/pdf/2002.11616.pdf" target="_blank">Paper</a>
            

            

            

            
              <a class="button" href="https://www.youtube.com/watch?v=8mgD8JxBOus" target="_blank">Video</a>
            

            
              <a class="button" href="https://github.com/Mukosame/Zooming-Slow-Mo-CVPR-2020" target="_blank">Code</a>
            

            

            

          </div>
        </div>

          </div></td>
        </tr>
      </table>
      
      <table border="0">
        <tr>
          <td><img src="/assets/publications/2020_tdan/teaser.png" width="200" height="100" /></td>
          
          <td> 
          <div dir="ltr">
        <div class="paper">
          <p class="title"><b>TDAN: Temporally Deformable Alignment Network for Video Super-Resolution</b></p>
          <p><b>Yapeng Tian</b>, Yulun Zhang, Yun Fu, and Chenliang Xu</p>
          <p><i>CVPR'20: IEEE/CVF Conference on Computer Vision and Pattern Recognition.</i></p>
          
          <p style="color:red">This is the first work that uses deformable alignment to address video restoration.</p>
         
           <div class="paper-buttons">
            
              <a class="button" href="https://openaccess.thecvf.com/content_CVPR_2020/papers/Tian_TDAN_Temporally-Deformable_Alignment_Network_for_Video_Super-Resolution_CVPR_2020_paper.pdf" target="_blank">Paper</a>
            

            

            

            
              <a class="button" href="https://www.youtube.com/watch?v=eZExENE50I0" target="_blank">Video</a>
            

            
              <a class="button" href="https://github.com/YapengTian/TDAN-VSR-CVPR-2020" target="_blank">Code</a>
            

            

            

          </div>
        </div>

          </div></td>
        </tr>
      </table>
      
      <table border="0">
        <tr>
          <td><img src="/assets/publications/2019_avc/teaser.png" width="200" height="100" /></td>
          
          <td> 
          <div dir="ltr">
        <div class="paper">
          <p class="title"><b>Interpretable and Controllable Audio-Visual Video Captioning</b></p>
          <p><b>Yapeng Tian</b>, Chenxiao Guan, Goodman Justin, Marc Moore, and Chenliang Xu</p>
          <p><i>CVPRW'19: CVPR Workshops.</i></p>
          
          <p style="color:red">Multisensory interpretability in terms of the audio-visual video captioning task.</p>
         
           <div class="paper-buttons">
            
              <a class="button" href="https://openaccess.thecvf.com/content_CVPRW_2019/papers/Sight%20and%20Sound/Yapeng_Tian_Audio-Visual_Interpretable_and_Controllable_Video_Captioning_CVPRW_2019_paper.pdf" target="_blank">Paper</a>
            

            

            

            

            

            

            

          </div>
        </div>

          </div></td>
        </tr>
      </table>
      
      <table border="0">
        <tr>
          <td><img src="/assets/publications/2018_ave/teaser.png" width="200" height="100" /></td>
          
          <td> 
          <div dir="ltr">
        <div class="paper">
          <p class="title"><b>Audio-Visual Event Localization in Unconstrained Videos</b></p>
          <p><b>Yapeng Tian</b>, Jing Shi, Bochen Li, Zhiyao Duan, and Chenliang Xu</p>
          <p><i>ECCV'18: European Conference on Computer Vision.</i></p>
           
           <div class="paper-buttons">
            
              <a class="button" href="https://openaccess.thecvf.com/content_ECCV_2018/papers/Yapeng_Tian_Audio-Visual_Event_Localization_ECCV_2018_paper.pdf" target="_blank">Paper</a>
            

            

            

            
              <a class="button" href="https://www.youtube.com/watch?v=m6r6BbD5MSc" target="_blank">Video</a>
            

            
              <a class="button" href="https://github.com/YapengTian/AVE-ECCV18" target="_blank">Code</a>
            

            
              <a class="button" href="https://drive.google.com/file/d/1FjKwe79e0u96vdjIVwfRQ1V6SoDHe7kK" target="_blank">Data</a>
            

            
              <a class="button" href="https://sites.google.com/view/audiovisualresearch" target="_blank">Project</a>
            

          </div>
        </div>

          </div></td>
        </tr>
      </table>
      
      <table border="0">
        <tr>
          <td><img src="/assets/publications/2018_rdn/teaser.png" width="200" height="100" /></td>
          
          <td> 
          <div dir="ltr">
        <div class="paper">
          <p class="title"><b>Residual Dense Network for Image Super-Resolution</b></p>
          <p>Yulun Zhang, <b>Yapeng Tian</b>, Yu Kong , Bineng Zhong, Yun Fu</p>
          <p><i>CVPR'18 Spotlight: IEEE/CVF Conf. on Computer Vision and Pattern Recognition.</i></p>
           
           <div class="paper-buttons">
            
              <a class="button" href="https://arxiv.org/pdf/1802.08797.pdf" target="_blank">Paper</a>
            

            

            

            

            
              <a class="button" href="https://github.com/yulunzhang/RDN" target="_blank">Code</a>
            

            

            

          </div>
        </div>

          </div></td>
        </tr>
      </table>
      
    </div>


    <div class="tab-pane active" id="papers-audiovisual">
      
      
      <table border="0">
        <tr>
          <td><img src="/assets/publications/2022_avqa/teaser.png" width="200" height="100" /></td>
          
          <td> 
          <div dir="ltr">
        <div class="paper">
          <p class="title"><b>Learning to Answer Questions in Dynamic Audio-Visual Scenarios</b></p>
          <p>Guangyao Li<sup>‡</sup>, Yake Wei<sup>‡</sup>, <b>Yapeng Tian<sup>‡</sup></b>, Chenliang Xu, Ji-Rong Wen, and Di Hu</p>
          <p><i>CVPR'22 Oral: IEEE/CVF Conference on Computer Vision and Pattern Recognition. </i></p>
           
           <div class="paper-buttons">
            
              <a class="button" href="https://arxiv.org/pdf/2203.14072.pdf" target="_blank">Paper</a>
            

            

            

            
              <a class="button" href="https://www.youtube.com/watch?v=JH3t5gwe9Xw" target="_blank">Video</a>
            

            
              <a class="button" href="https://github.com/GeWu-Lab/MUSIC-AVQA" target="_blank">Code</a>
            

            

            
              <a class="button" href="https://gewu-lab.github.io/MUSIC-AVQA/" target="_blank">Project</a>
            

          </div>
        </div>

          </div></td>
        </tr>
      </table>
      
      <table border="0">
        <tr>
          <td><img src="/assets/publications/2021_stm/teaser.png" width="200" height="100" /></td>
          
          <td> 
          <div dir="ltr">
        <div class="paper">
          <p class="title"><b>Space-Time Memory Network for Sounding Object Localization in Videos</b></p>
          <p>Sizhe Li<sup>‡</sup>, <b>Yapeng Tian<sup>‡</sup></b>, and Chenliang Xu</p>
          <p><i>BMVC'21: The British Machine Vision Conference. </i></p>
           
           <div class="paper-buttons">
            
              <a class="button" href="https://arxiv.org/pdf/2111.05526.pdf" target="_blank">Paper</a>
            

            

            

            

            
              <a class="button" href="https://github.com/lester0866/Space-Time-Memory-Network-for-Sounding-Object-Localization-in-Videos" target="_blank">Code</a>
            

            

            
              <a class="button" href="https://sites.google.com/view/bmvc2021stm" target="_blank">Project</a>
            

          </div>
        </div>

          </div></td>
        </tr>
      </table>
      
      <table border="0">
        <tr>
          <td><img src="/assets/publications/2021_robustness/teaser.png" width="200" height="100" /></td>
          
          <td> 
          <div dir="ltr">
        <div class="paper">
          <p class="title"><b>Can audio-visual integration strengthen robustness under multimodal attacks?</b></p>
          <p><b>Yapeng Tian</b> and Chenliang Xu</p>
          <p><i>CVPR'21: IEEE/CVF Conference on Computer Vision and Pattern Recognition. </i></p>
           
           <div class="paper-buttons">
            
              <a class="button" href="https://arxiv.org/pdf/2104.02000.pdf" target="_blank">Paper</a>
            

            

            

            

            
              <a class="button" href="https://github.com/YapengTian/AV-Robustness-CVPR21" target="_blank">Code</a>
            

            

            

          </div>
        </div>

          </div></td>
        </tr>
      </table>
      
      <table border="0">
        <tr>
          <td><img src="/assets/publications/2021_ccol/teaser.png" width="200" height="100" /></td>
          
          <td> 
          <div dir="ltr">
        <div class="paper">
          <p class="title"><b>Cyclic Co-Learning of Sounding Object Visual Grounding and Sound Separation</b></p>
          <p><b>Yapeng Tian</b>, Di Hu, and Chenliang Xu</p>
          <p><i>CVPR'21: IEEE/CVF Conference on Computer Vision and Pattern Recognition.</i></p>
           
           <div class="paper-buttons">
            
              <a class="button" href="https://arxiv.org/pdf/2104.02026.pdf" target="_blank">Paper</a>
            

            

            

            

            
              <a class="button" href="https://github.com/YapengTian/CCOL-CVPR21" target="_blank">Code</a>
            

            

            

          </div>
        </div>

          </div></td>
        </tr>
      </table>
      
      <table border="0">
        <tr>
          <td><img src="/assets/publications/2020_avvp/teaser.png" width="200" height="100" /></td>
          
          <td> 
          <div dir="ltr">
        <div class="paper">
          <p class="title"><b>Unified Multisensory Perception: Weakly-Supervised Audio-Visual Video Parsing</b></p>
          <p><b>Yapeng Tian</b>, Dingzeyu Li, and Chenliang Xu</p>
          <p><i>ECCV'20 Spotlight: European Conference on Computer Vision.</i></p>
           
           <div class="paper-buttons">
            
              <a class="button" href="/assets/publications/2019_biometrika/paper.pdf" target="_blank">Paper</a>
            

            

            

            

            
              <a class="button" href="https://github.com/YapengTian/AVVP-ECCV20" target="_blank">Code</a>
            

            
              <a class="button" href="https://github.com/YapengTian/AVVP-ECCV20" target="_blank">Data</a>
            

            

          </div>
        </div>

          </div></td>
        </tr>
      </table>
      
      <table border="0">
        <tr>
          <td><img src="/assets/publications/2020_dap/teaser.png" width="200" height="100" /></td>
          
          <td> 
          <div dir="ltr">
        <div class="paper">
          <p class="title"><b>Deep Audio Prior</b></p>
          <p><b>Yapeng Tian</b>, Chenliang Xu, and Dingzeyu Li</p>
          <p><i>CVPRW'20: CVPR Workshops.</i></p>
           
           <div class="paper-buttons">
            
              <a class="button" href="https://arxiv.org/pdf/1912.10292v1.pdf" target="_blank">Paper</a>
            

            

            

            

            
              <a class="button" href="https://github.com/adobe/Deep-Audio-Prior" target="_blank">Code</a>
            

            

            
              <a class="button" href="https://opensource.adobe.com/Deep-Audio-Prior/" target="_blank">Project</a>
            

          </div>
        </div>

          </div></td>
        </tr>
      </table>
      
      <table border="0">
        <tr>
          <td><img src="/assets/publications/2019_avc/teaser.png" width="200" height="100" /></td>
          
          <td> 
          <div dir="ltr">
        <div class="paper">
          <p class="title"><b>Interpretable and Controllable Audio-Visual Video Captioning</b></p>
          <p><b>Yapeng Tian</b>, Chenxiao Guan, Goodman Justin, Marc Moore, and Chenliang Xu</p>
          <p><i>CVPRW'19: CVPR Workshops.</i></p>
          
          <p style="color:red">Multisensory interpretability in terms of the audio-visual video captioning task.</p>
         
           <div class="paper-buttons">
            
              <a class="button" href="https://openaccess.thecvf.com/content_CVPRW_2019/papers/Sight%20and%20Sound/Yapeng_Tian_Audio-Visual_Interpretable_and_Controllable_Video_Captioning_CVPRW_2019_paper.pdf" target="_blank">Paper</a>
            

            

            

            

            

            

            

          </div>
        </div>

          </div></td>
        </tr>
      </table>
      
      <table border="0">
        <tr>
          <td><img src="/assets/publications/2018_ave/teaser.png" width="200" height="100" /></td>
          
          <td> 
          <div dir="ltr">
        <div class="paper">
          <p class="title"><b>Audio-Visual Event Localization in Unconstrained Videos</b></p>
          <p><b>Yapeng Tian</b>, Jing Shi, Bochen Li, Zhiyao Duan, and Chenliang Xu</p>
          <p><i>ECCV'18: European Conference on Computer Vision.</i></p>
           
           <div class="paper-buttons">
            
              <a class="button" href="https://openaccess.thecvf.com/content_ECCV_2018/papers/Yapeng_Tian_Audio-Visual_Event_Localization_ECCV_2018_paper.pdf" target="_blank">Paper</a>
            

            

            

            
              <a class="button" href="https://www.youtube.com/watch?v=m6r6BbD5MSc" target="_blank">Video</a>
            

            
              <a class="button" href="https://github.com/YapengTian/AVE-ECCV18" target="_blank">Code</a>
            

            
              <a class="button" href="https://drive.google.com/file/d/1FjKwe79e0u96vdjIVwfRQ1V6SoDHe7kK" target="_blank">Data</a>
            

            
              <a class="button" href="https://sites.google.com/view/audiovisualresearch" target="_blank">Project</a>
            

          </div>
        </div>

          </div></td>
        </tr>
      </table>
      
    </div>



    <div class="tab-pane active" id="papers-videorestoration">
      
      
      <table border="0">
        <tr>
          <td><img src="/assets/publications/2021_matting/teaser.png" width="200" height="100" /></td>
          
          <td> 
          <div dir="ltr">
        <div class="paper">
          <p class="title"><b>Video Matting via Consistency-Regularized Graph Neural Networks</b></p>
          <p>Tiantian Wang, Sifei Liu, <b>Yapeng Tian</b>, Kai Li, and Ming-Hsuan Yang</p>
          <p><i>ICCV'21: IEEE/CVF International Conference on Computer Vision. </i></p>
           
           <div class="paper-buttons">
            
              <a class="button" href="https://faculty.ucmerced.edu/mhyang/papers/iccv2021_video_matting.pdf" target="_blank">Paper</a>
            

            

            

            

            
              <a class="button" href="https://github.com/TiantianWang/VideoMatting-CRGNN" target="_blank">Code</a>
            

            

            

          </div>
        </div>

          </div></td>
        </tr>
      </table>
      
      <table border="0">
        <tr>
          <td><img src="/assets/publications/2020_zsm/teaser.png" width="200" height="100" /></td>
          
          <td> 
          <div dir="ltr">
        <div class="paper">
          <p class="title"><b>Zooming Slow-Mo: Fast and Accurate One-Stage Space-Time Video Super-Resolution</b></p>
          <p>Xiaoyu Xiang<sup>‡</sup>, <b>Yapeng Tian<sup>‡</sup></b>, Yulun Zhang, Yun Fu, Jan Allebach, and Chenliang Xu</p>
          <p><i>CVPR'20: IEEE/CVF Conference on Computer Vision and Pattern Recognition.</i></p>
           
           <div class="paper-buttons">
            
              <a class="button" href="https://arxiv.org/pdf/2002.11616.pdf" target="_blank">Paper</a>
            

            

            

            
              <a class="button" href="https://www.youtube.com/watch?v=8mgD8JxBOus" target="_blank">Video</a>
            

            
              <a class="button" href="https://github.com/Mukosame/Zooming-Slow-Mo-CVPR-2020" target="_blank">Code</a>
            

            

            

          </div>
        </div>

          </div></td>
        </tr>
      </table>
      
      <table border="0">
        <tr>
          <td><img src="/assets/publications/2020_tdan/teaser.png" width="200" height="100" /></td>
          
          <td> 
          <div dir="ltr">
        <div class="paper">
          <p class="title"><b>TDAN: Temporally Deformable Alignment Network for Video Super-Resolution</b></p>
          <p><b>Yapeng Tian</b>, Yulun Zhang, Yun Fu, and Chenliang Xu</p>
          <p><i>CVPR'20: IEEE/CVF Conference on Computer Vision and Pattern Recognition.</i></p>
          
          <p style="color:red">This is the first work that uses deformable alignment to address video restoration.</p>
         
           <div class="paper-buttons">
            
              <a class="button" href="https://openaccess.thecvf.com/content_CVPR_2020/papers/Tian_TDAN_Temporally-Deformable_Alignment_Network_for_Video_Super-Resolution_CVPR_2020_paper.pdf" target="_blank">Paper</a>
            

            

            

            
              <a class="button" href="https://www.youtube.com/watch?v=eZExENE50I0" target="_blank">Video</a>
            

            
              <a class="button" href="https://github.com/YapengTian/TDAN-VSR-CVPR-2020" target="_blank">Code</a>
            

            

            

          </div>
        </div>

          </div></td>
        </tr>
      </table>
      
    </div>



    <div class="tab-pane active" id="papers-imagerestoration">
      
      
      <table border="0">
        <tr>
          <td><img src="/assets/publications/2022_mrisr/teaser.png" width="200" height="100" /></td>
          
          <td> 
          <div dir="ltr">
        <div class="paper">
          <p class="title"><b>Transformer-empowered Multi-scale Contextual Matching and Aggregation for Multi-contrast MRI Super-Resolution</b></p>
          <p>Guangyuan Li, Jun Lv, <b>Yapeng Tian</b>, Qi Dou, ChengyanWang, Chenliang Xu, and Jing Qin</p>
          <p><i>CVPR'22: IEEE/CVF Conference on Computer Vision and Pattern Recognition.</i></p>
           
           <div class="paper-buttons">
            
              <a class="button" href="https://arxiv.org/pdf/2203.13963.pdf" target="_blank">Paper</a>
            

            

            

            

            
              <a class="button" href="https://github.com/XAIMI-Lab/McMRSR" target="_blank">Code</a>
            

            

            

          </div>
        </div>

          </div></td>
        </tr>
      </table>
      
      <table border="0">
        <tr>
          <td><img src="/assets/publications/2022_amsa/teaser.png" width="200" height="100" /></td>
          
          <td> 
          <div dir="ltr">
        <div class="paper">
          <p class="title"><b>Coarse-to-Fine Embedded PatchMatch and Multi-Scale Dynamic Aggregation for Reference-based Super-Resolution</b></p>
          <p>Bin Xia, <b>Yapeng Tian</b>, Yucheng Hang, Wenming Yang, Qingmin Liao, Jie Zhou</p>
          <p><i>AAAI'22: The AAAI Conference on Artificial Intelligence.</i></p>
           
           <div class="paper-buttons">
            
              <a class="button" href="https://arxiv.org/pdf/2201.04358.pdf" target="_blank">Paper</a>
            

            

            

            

            
              <a class="button" href="https://github.com/Zj-BinXia/AMSA" target="_blank">Code</a>
            

            

            

          </div>
        </div>

          </div></td>
        </tr>
      </table>
      
      <table border="0">
        <tr>
          <td><img src="/assets/publications/2022_enlca/teaser.png" width="200" height="100" /></td>
          
          <td> 
          <div dir="ltr">
        <div class="paper">
          <p class="title"><b>Efficient Non-Local Contrastive Attention for Image Super-Resolution</b></p>
          <p>Bin Xia<sup>‡</sup>, Yucheng Hang<sup>‡</sup>, <b>Yapeng Tian</b>, Wenming Yang, Qingmin Liao, Jie Zhou</p>
          <p><i>AAAI'22: The AAAI Conference on Artificial Intelligence. </i></p>
           
           <div class="paper-buttons">
            
              <a class="button" href="https://arxiv.org/pdf/2201.03794.pdf" target="_blank">Paper</a>
            

            

            

            

            
              <a class="button" href="https://github.com/Zj-BinXia/ENLCA" target="_blank">Code</a>
            

            

            

          </div>
        </div>

          </div></td>
        </tr>
      </table>
      
      <table border="0">
        <tr>
          <td><img src="/assets/publications/2020_rdnpami/teaser.png" width="200" height="100" /></td>
          
          <td> 
          <div dir="ltr">
        <div class="paper">
          <p class="title"><b>Residual Dense Network for Image Super-Resolution</b></p>
          <p>Yulun Zhang, <b>Yapeng Tian</b>, Yu Kong , Bineng Zhong, Yun Fu</p>
          <p><i>TPAMI'20: IEEE Transactions on Pattern Analysis and Machine Intelligence.</i></p>
           
           <div class="paper-buttons">
            
              <a class="button" href="https://arxiv.org/pdf/1812.10477.pdf" target="_blank">Paper</a>
            

            

            

            

            
              <a class="button" href="https://github.com/yulunzhang/RDN" target="_blank">Code</a>
            

            

            

          </div>
        </div>

          </div></td>
        </tr>
      </table>
      
      <table border="0">
        <tr>
          <td><img src="/assets/publications/2019_csf/teaser.png" width="200" height="100" /></td>
          
          <td> 
          <div dir="ltr">
        <div class="paper">
          <p class="title"><b>CFSNet: Toward a Controllable Feature Space for Image Restoration</b></p>
          <p>Wei Wang<sup>‡</sup>, Ruiming Guo<sup>‡</sup>, <b>Yapeng Tian</b>, and Wenming Yang</p>
          <p><i>ICCV'19: IEEE/CVF International Conference on Computer Vision.</i></p>
           
           <div class="paper-buttons">
            
              <a class="button" href="https://arxiv.org/pdf/1904.00634.pdf" target="_blank">Paper</a>
            

            

            

            

            
              <a class="button" href="https://github.com/qibao77/CFSNet" target="_blank">Code</a>
            

            

            

          </div>
        </div>

          </div></td>
        </tr>
      </table>
      
      <table border="0">
        <tr>
          <td><img src="/assets/publications/2019_lcsc/teaser.png" width="200" height="100" /></td>
          
          <td> 
          <div dir="ltr">
        <div class="paper">
          <p class="title"><b>LCSCNet: Linear Compressing Based Skip-Connecting Network for Image Super-Resolution</b></p>
          <p>Wenming Yang, Xuechen Zhang, <b>Yapeng Tian</b>, Wei Wang, Jing-Hao Xue, Qingmin Liao</p>
          <p><i>TIP'19: IEEE Trans. Image Processing.</i></p>
           
           <div class="paper-buttons">
            
              <a class="button" href="https://arxiv.org/abs/1909.03573" target="_blank">Paper</a>
            

            

            

            

            

            

            

          </div>
        </div>

          </div></td>
        </tr>
      </table>
      
      <table border="0">
        <tr>
          <td><img src="/assets/publications/2019_review/teaser.png" width="200" height="100" /></td>
          
          <td> 
          <div dir="ltr">
        <div class="paper">
          <p class="title"><b>Deep Learning for Single Image Super-Resolution: A Brief Review</b></p>
          <p>Wenming Yang, Xuechen Zhang, <b>Yapeng Tian</b>, Wei Wang, JingHao Xue, and Qingmin Liao</p>
          <p><i>TMM'19: IEEE Trans. Multimedia.</i></p>
           
           <div class="paper-buttons">
            
              <a class="button" href="https://arxiv.org/pdf/1808.03344.pdf" target="_blank">Paper</a>
            

            

            

            

            

            

            

          </div>
        </div>

          </div></td>
        </tr>
      </table>
      
      <table border="0">
        <tr>
          <td><img src="/assets/publications/2018_rdn/teaser.png" width="200" height="100" /></td>
          
          <td> 
          <div dir="ltr">
        <div class="paper">
          <p class="title"><b>Residual Dense Network for Image Super-Resolution</b></p>
          <p>Yulun Zhang, <b>Yapeng Tian</b>, Yu Kong , Bineng Zhong, Yun Fu</p>
          <p><i>CVPR'18 Spotlight: IEEE/CVF Conf. on Computer Vision and Pattern Recognition.</i></p>
           
           <div class="paper-buttons">
            
              <a class="button" href="https://arxiv.org/pdf/1802.08797.pdf" target="_blank">Paper</a>
            

            

            

            

            
              <a class="button" href="https://github.com/yulunzhang/RDN" target="_blank">Code</a>
            

            

            

          </div>
        </div>

          </div></td>
        </tr>
      </table>
      
      <table border="0">
        <tr>
          <td><img src="/assets/publications/2017_ntire/teaser.png" width="200" height="100" /></td>
          
          <td> 
          <div dir="ltr">
        <div class="paper">
          <p class="title"><b>NTIRE 2017 Challenge on Single Image Super-Resolution: Methods and Results</b></p>
          <p>Radu Timofte, Eirikur Agustsson, Luc Van Gool, ..., Xintao Wang, <b>Yapeng Tian</b>, Ke Yu, Yulun Zhang, Shixiang Wu, Chao Dong, Liang Lin, Yu Qiao, ...</p>
          <p><i>CVPRW'17: CVPR Workshops.</i></p>
           
           <div class="paper-buttons">
            
              <a class="button" href="https://people.ee.ethz.ch/~timofter/publications/Timofte-CVPRW-2017.pdf" target="_blank">Paper</a>
            

            

            

            

            

            

            

          </div>
        </div>

          </div></td>
        </tr>
      </table>
      
      <table border="0">
        <tr>
          <td><img src="/assets/publications/2016_ccs/teaser.png" width="200" height="100" /></td>
          
          <td> 
          <div dir="ltr">
        <div class="paper">
          <p class="title"><b>Consistent Coding Scheme for Single-Image Super-Resolution Via Independent Dictionaries</b></p>
          <p>Wenming Yang, <b>Yapeng Tian</b>, Fei Zhou*, Qingmin Liao, Hai Chen and Chenglin Zheng</p>
          <p><i>TMM'16: EEE Trans. Multimedia.</i></p>
           
           <div class="paper-buttons">
            
              <a class="button" href="https://drive.google.com/file/d/1MpEM5qmSJi1GtY9TftNNV0cgSHqMT_KQ/view" target="_blank">Paper</a>
            

            

            

            

            

            

            

          </div>
        </div>

          </div></td>
        </tr>
      </table>
      
      <table border="0">
        <tr>
          <td><img src="/assets/publications/2016_anrse/teaser.png" width="200" height="100" /></td>
          
          <td> 
          <div dir="ltr">
        <div class="paper">
          <p class="title"><b>Anchored Neighborhood Regression based Single Image Super-Resolution from Self-examples</b></p>
          <p><b>Yapeng Tian</b>, Fei Zhou, Wenming Yang*, Xuesen Shang and Qingmin Liao</p>
          <p><i>ICIP'16: IEEE International Conference on Image Processing.</i></p>
           
           <div class="paper-buttons">
            
              <a class="button" href="https://drive.google.com/file/d/1Ts_gYIp57llzK53Wyt7hwu4lZ9GQsbis/view" target="_blank">Paper</a>
            

            

            

            

            
              <a class="button" href="https://github.com/YapengTian/ICIP2016" target="_blank">Code</a>
            

            

            

          </div>
        </div>

          </div></td>
        </tr>
      </table>
      
      <table border="0">
        <tr>
          <td><img src="/assets/publications/2015_pfsr/teaser.png" width="200" height="100" /></td>
          
          <td> 
          <div dir="ltr">
        <div class="paper">
          <p class="title"><b>Single-Image Super-Resolution Using Clustering-Based Global Regression and Propagation Filtering</b></p>
          <p>Wenming Yang, <b>Yapeng Tian</b>, Fei Zhou, Tingrong Yuan, Xuesen Shang and QingminLiao</p>
          <p><i>ACPR'15 Oral: Asian Conference on Pattern Recognition.</i></p>
           
           <div class="paper-buttons">
            
              <a class="button" href="https://drive.google.com/file/d/12tqTHt0aLn7-B1jEgEJBYY64uhwfEezA/view" target="_blank">Paper</a>
            

            

            

            

            

            

            

          </div>
        </div>

          </div></td>
        </tr>
      </table>
      
    </div>


    <!-- <div class="tab-pane active" id="papers-all">
      
      
        <div class="paper">
          <p class="title"><b>Learning to Answer Questions in Dynamic Audio-Visual Scenarios</b></p>
          <p>Guangyao Li<sup>‡</sup>, Yake Wei<sup>‡</sup>, <b>Yapeng Tian<sup>‡</sup></b>, Chenliang Xu, Ji-Rong Wen, and Di Hu</p>
          <p><i>CVPR'22 Oral: IEEE/CVF Conference on Computer Vision and Pattern Recognition. </i></p>
           
           <div class="paper-buttons">
            
              <a class="button" href="https://arxiv.org/pdf/2203.14072.pdf" target="_blank">Paper</a>
            

            

            

            
              <a class="button" href="https://www.youtube.com/watch?v=JH3t5gwe9Xw" target="_blank">Video</a>
            

            
              <a class="button" href="https://github.com/GeWu-Lab/MUSIC-AVQA" target="_blank">Code</a>
            

            

            
              <a class="button" href="https://gewu-lab.github.io/MUSIC-AVQA/" target="_blank">Project</a>
            

          </div>
        </div>
      
        <div class="paper">
          <p class="title"><b>Transformer-empowered Multi-scale Contextual Matching and Aggregation for Multi-contrast MRI Super-Resolution</b></p>
          <p>Guangyuan Li, Jun Lv, <b>Yapeng Tian</b>, Qi Dou, ChengyanWang, Chenliang Xu, and Jing Qin</p>
          <p><i>CVPR'22: IEEE/CVF Conference on Computer Vision and Pattern Recognition.</i></p>
           
           <div class="paper-buttons">
            
              <a class="button" href="https://arxiv.org/pdf/2203.13963.pdf" target="_blank">Paper</a>
            

            

            

            

            
              <a class="button" href="https://github.com/XAIMI-Lab/McMRSR" target="_blank">Code</a>
            

            

            

          </div>
        </div>
      
        <div class="paper">
          <p class="title"><b>Coarse-to-Fine Embedded PatchMatch and Multi-Scale Dynamic Aggregation for Reference-based Super-Resolution</b></p>
          <p>Bin Xia, <b>Yapeng Tian</b>, Yucheng Hang, Wenming Yang, Qingmin Liao, Jie Zhou</p>
          <p><i>AAAI'22: The AAAI Conference on Artificial Intelligence.</i></p>
           
           <div class="paper-buttons">
            
              <a class="button" href="https://arxiv.org/pdf/2201.04358.pdf" target="_blank">Paper</a>
            

            

            

            

            
              <a class="button" href="https://github.com/Zj-BinXia/AMSA" target="_blank">Code</a>
            

            

            

          </div>
        </div>
      
        <div class="paper">
          <p class="title"><b>Efficient Non-Local Contrastive Attention for Image Super-Resolution</b></p>
          <p>Bin Xia<sup>‡</sup>, Yucheng Hang<sup>‡</sup>, <b>Yapeng Tian</b>, Wenming Yang, Qingmin Liao, Jie Zhou</p>
          <p><i>AAAI'22: The AAAI Conference on Artificial Intelligence. </i></p>
           
           <div class="paper-buttons">
            
              <a class="button" href="https://arxiv.org/pdf/2201.03794.pdf" target="_blank">Paper</a>
            

            

            

            

            
              <a class="button" href="https://github.com/Zj-BinXia/ENLCA" target="_blank">Code</a>
            

            

            

          </div>
        </div>
      
        <div class="paper">
          <p class="title"><b>Space-Time Memory Network for Sounding Object Localization in Videos</b></p>
          <p>Sizhe Li<sup>‡</sup>, <b>Yapeng Tian<sup>‡</sup></b>, and Chenliang Xu</p>
          <p><i>BMVC'21: The British Machine Vision Conference. </i></p>
           
           <div class="paper-buttons">
            
              <a class="button" href="https://arxiv.org/pdf/2111.05526.pdf" target="_blank">Paper</a>
            

            

            

            

            
              <a class="button" href="https://github.com/lester0866/Space-Time-Memory-Network-for-Sounding-Object-Localization-in-Videos" target="_blank">Code</a>
            

            

            
              <a class="button" href="https://sites.google.com/view/bmvc2021stm" target="_blank">Project</a>
            

          </div>
        </div>
      
        <div class="paper">
          <p class="title"><b>Video Matting via Consistency-Regularized Graph Neural Networks</b></p>
          <p>Tiantian Wang, Sifei Liu, <b>Yapeng Tian</b>, Kai Li, and Ming-Hsuan Yang</p>
          <p><i>ICCV'21: IEEE/CVF International Conference on Computer Vision. </i></p>
           
           <div class="paper-buttons">
            
              <a class="button" href="https://faculty.ucmerced.edu/mhyang/papers/iccv2021_video_matting.pdf" target="_blank">Paper</a>
            

            

            

            

            
              <a class="button" href="https://github.com/TiantianWang/VideoMatting-CRGNN" target="_blank">Code</a>
            

            

            

          </div>
        </div>
      
        <div class="paper">
          <p class="title"><b>Can audio-visual integration strengthen robustness under multimodal attacks?</b></p>
          <p><b>Yapeng Tian</b> and Chenliang Xu</p>
          <p><i>CVPR'21: IEEE/CVF Conference on Computer Vision and Pattern Recognition. </i></p>
           
           <div class="paper-buttons">
            
              <a class="button" href="https://arxiv.org/pdf/2104.02000.pdf" target="_blank">Paper</a>
            

            

            

            

            
              <a class="button" href="https://github.com/YapengTian/AV-Robustness-CVPR21" target="_blank">Code</a>
            

            

            

          </div>
        </div>
      
        <div class="paper">
          <p class="title"><b>Cyclic Co-Learning of Sounding Object Visual Grounding and Sound Separation</b></p>
          <p><b>Yapeng Tian</b>, Di Hu, and Chenliang Xu</p>
          <p><i>CVPR'21: IEEE/CVF Conference on Computer Vision and Pattern Recognition.</i></p>
           
           <div class="paper-buttons">
            
              <a class="button" href="https://arxiv.org/pdf/2104.02026.pdf" target="_blank">Paper</a>
            

            

            

            

            
              <a class="button" href="https://github.com/YapengTian/CCOL-CVPR21" target="_blank">Code</a>
            

            

            

          </div>
        </div>
      
        <div class="paper">
          <p class="title"><b>Unified Multisensory Perception: Weakly-Supervised Audio-Visual Video Parsing</b></p>
          <p><b>Yapeng Tian</b>, Dingzeyu Li, and Chenliang Xu</p>
          <p><i>ECCV'20 Spotlight: European Conference on Computer Vision.</i></p>
           
           <div class="paper-buttons">
            
              <a class="button" href="/assets/publications/2019_biometrika/paper.pdf" target="_blank">Paper</a>
            

            

            

            

            
              <a class="button" href="https://github.com/YapengTian/AVVP-ECCV20" target="_blank">Code</a>
            

            
              <a class="button" href="https://github.com/YapengTian/AVVP-ECCV20" target="_blank">Data</a>
            

            

          </div>
        </div>
      
        <div class="paper">
          <p class="title"><b>Zooming Slow-Mo: Fast and Accurate One-Stage Space-Time Video Super-Resolution</b></p>
          <p>Xiaoyu Xiang<sup>‡</sup>, <b>Yapeng Tian<sup>‡</sup></b>, Yulun Zhang, Yun Fu, Jan Allebach, and Chenliang Xu</p>
          <p><i>CVPR'20: IEEE/CVF Conference on Computer Vision and Pattern Recognition.</i></p>
           
           <div class="paper-buttons">
            
              <a class="button" href="https://arxiv.org/pdf/2002.11616.pdf" target="_blank">Paper</a>
            

            

            

            
              <a class="button" href="https://www.youtube.com/watch?v=8mgD8JxBOus" target="_blank">Video</a>
            

            
              <a class="button" href="https://github.com/Mukosame/Zooming-Slow-Mo-CVPR-2020" target="_blank">Code</a>
            

            

            

          </div>
        </div>
      
        <div class="paper">
          <p class="title"><b>TDAN: Temporally Deformable Alignment Network for Video Super-Resolution</b></p>
          <p><b>Yapeng Tian</b>, Yulun Zhang, Yun Fu, and Chenliang Xu</p>
          <p><i>CVPR'20: IEEE/CVF Conference on Computer Vision and Pattern Recognition.</i></p>
          
          <p style="color:red">This is the first work that uses deformable alignment to address video restoration.</p>
         
           <div class="paper-buttons">
            
              <a class="button" href="https://openaccess.thecvf.com/content_CVPR_2020/papers/Tian_TDAN_Temporally-Deformable_Alignment_Network_for_Video_Super-Resolution_CVPR_2020_paper.pdf" target="_blank">Paper</a>
            

            

            

            
              <a class="button" href="https://www.youtube.com/watch?v=eZExENE50I0" target="_blank">Video</a>
            

            
              <a class="button" href="https://github.com/YapengTian/TDAN-VSR-CVPR-2020" target="_blank">Code</a>
            

            

            

          </div>
        </div>
      
        <div class="paper">
          <p class="title"><b>Deep Audio Prior</b></p>
          <p><b>Yapeng Tian</b>, Chenliang Xu, and Dingzeyu Li</p>
          <p><i>CVPRW'20: CVPR Workshops.</i></p>
           
           <div class="paper-buttons">
            
              <a class="button" href="https://arxiv.org/pdf/1912.10292v1.pdf" target="_blank">Paper</a>
            

            

            

            

            
              <a class="button" href="https://github.com/adobe/Deep-Audio-Prior" target="_blank">Code</a>
            

            

            
              <a class="button" href="https://opensource.adobe.com/Deep-Audio-Prior/" target="_blank">Project</a>
            

          </div>
        </div>
      
        <div class="paper">
          <p class="title"><b>Residual Dense Network for Image Super-Resolution</b></p>
          <p>Yulun Zhang, <b>Yapeng Tian</b>, Yu Kong , Bineng Zhong, Yun Fu</p>
          <p><i>TPAMI'20: IEEE Transactions on Pattern Analysis and Machine Intelligence.</i></p>
           
           <div class="paper-buttons">
            
              <a class="button" href="https://arxiv.org/pdf/1812.10477.pdf" target="_blank">Paper</a>
            

            

            

            

            
              <a class="button" href="https://github.com/yulunzhang/RDN" target="_blank">Code</a>
            

            

            

          </div>
        </div>
      
        <div class="paper">
          <p class="title"><b>CFSNet: Toward a Controllable Feature Space for Image Restoration</b></p>
          <p>Wei Wang<sup>‡</sup>, Ruiming Guo<sup>‡</sup>, <b>Yapeng Tian</b>, and Wenming Yang</p>
          <p><i>ICCV'19: IEEE/CVF International Conference on Computer Vision.</i></p>
           
           <div class="paper-buttons">
            
              <a class="button" href="https://arxiv.org/pdf/1904.00634.pdf" target="_blank">Paper</a>
            

            

            

            

            
              <a class="button" href="https://github.com/qibao77/CFSNet" target="_blank">Code</a>
            

            

            

          </div>
        </div>
      
        <div class="paper">
          <p class="title"><b>Interpretable and Controllable Audio-Visual Video Captioning</b></p>
          <p><b>Yapeng Tian</b>, Chenxiao Guan, Goodman Justin, Marc Moore, and Chenliang Xu</p>
          <p><i>CVPRW'19: CVPR Workshops.</i></p>
          
          <p style="color:red">Multisensory interpretability in terms of the audio-visual video captioning task.</p>
         
           <div class="paper-buttons">
            
              <a class="button" href="https://openaccess.thecvf.com/content_CVPRW_2019/papers/Sight%20and%20Sound/Yapeng_Tian_Audio-Visual_Interpretable_and_Controllable_Video_Captioning_CVPRW_2019_paper.pdf" target="_blank">Paper</a>
            

            

            

            

            

            

            

          </div>
        </div>
      
        <div class="paper">
          <p class="title"><b>LCSCNet: Linear Compressing Based Skip-Connecting Network for Image Super-Resolution</b></p>
          <p>Wenming Yang, Xuechen Zhang, <b>Yapeng Tian</b>, Wei Wang, Jing-Hao Xue, Qingmin Liao</p>
          <p><i>TIP'19: IEEE Trans. Image Processing.</i></p>
           
           <div class="paper-buttons">
            
              <a class="button" href="https://arxiv.org/abs/1909.03573" target="_blank">Paper</a>
            

            

            

            

            

            

            

          </div>
        </div>
      
        <div class="paper">
          <p class="title"><b>Deep Learning for Single Image Super-Resolution: A Brief Review</b></p>
          <p>Wenming Yang, Xuechen Zhang, <b>Yapeng Tian</b>, Wei Wang, JingHao Xue, and Qingmin Liao</p>
          <p><i>TMM'19: IEEE Trans. Multimedia.</i></p>
           
           <div class="paper-buttons">
            
              <a class="button" href="https://arxiv.org/pdf/1808.03344.pdf" target="_blank">Paper</a>
            

            

            

            

            

            

            

          </div>
        </div>
      
        <div class="paper">
          <p class="title"><b>Audio-Visual Event Localization in Unconstrained Videos</b></p>
          <p><b>Yapeng Tian</b>, Jing Shi, Bochen Li, Zhiyao Duan, and Chenliang Xu</p>
          <p><i>ECCV'18: European Conference on Computer Vision.</i></p>
           
           <div class="paper-buttons">
            
              <a class="button" href="https://openaccess.thecvf.com/content_ECCV_2018/papers/Yapeng_Tian_Audio-Visual_Event_Localization_ECCV_2018_paper.pdf" target="_blank">Paper</a>
            

            

            

            
              <a class="button" href="https://www.youtube.com/watch?v=m6r6BbD5MSc" target="_blank">Video</a>
            

            
              <a class="button" href="https://github.com/YapengTian/AVE-ECCV18" target="_blank">Code</a>
            

            
              <a class="button" href="https://drive.google.com/file/d/1FjKwe79e0u96vdjIVwfRQ1V6SoDHe7kK" target="_blank">Data</a>
            

            
              <a class="button" href="https://sites.google.com/view/audiovisualresearch" target="_blank">Project</a>
            

          </div>
        </div>
      
        <div class="paper">
          <p class="title"><b>Residual Dense Network for Image Super-Resolution</b></p>
          <p>Yulun Zhang, <b>Yapeng Tian</b>, Yu Kong , Bineng Zhong, Yun Fu</p>
          <p><i>CVPR'18 Spotlight: IEEE/CVF Conf. on Computer Vision and Pattern Recognition.</i></p>
           
           <div class="paper-buttons">
            
              <a class="button" href="https://arxiv.org/pdf/1802.08797.pdf" target="_blank">Paper</a>
            

            

            

            

            
              <a class="button" href="https://github.com/yulunzhang/RDN" target="_blank">Code</a>
            

            

            

          </div>
        </div>
      
        <div class="paper">
          <p class="title"><b>NTIRE 2017 Challenge on Single Image Super-Resolution: Methods and Results</b></p>
          <p>Radu Timofte, Eirikur Agustsson, Luc Van Gool, ..., Xintao Wang, <b>Yapeng Tian</b>, Ke Yu, Yulun Zhang, Shixiang Wu, Chao Dong, Liang Lin, Yu Qiao, ...</p>
          <p><i>CVPRW'17: CVPR Workshops.</i></p>
           
           <div class="paper-buttons">
            
              <a class="button" href="https://people.ee.ethz.ch/~timofter/publications/Timofte-CVPRW-2017.pdf" target="_blank">Paper</a>
            

            

            

            

            

            

            

          </div>
        </div>
      
        <div class="paper">
          <p class="title"><b>Consistent Coding Scheme for Single-Image Super-Resolution Via Independent Dictionaries</b></p>
          <p>Wenming Yang, <b>Yapeng Tian</b>, Fei Zhou*, Qingmin Liao, Hai Chen and Chenglin Zheng</p>
          <p><i>TMM'16: EEE Trans. Multimedia.</i></p>
           
           <div class="paper-buttons">
            
              <a class="button" href="https://drive.google.com/file/d/1MpEM5qmSJi1GtY9TftNNV0cgSHqMT_KQ/view" target="_blank">Paper</a>
            

            

            

            

            

            

            

          </div>
        </div>
      
        <div class="paper">
          <p class="title"><b>Anchored Neighborhood Regression based Single Image Super-Resolution from Self-examples</b></p>
          <p><b>Yapeng Tian</b>, Fei Zhou, Wenming Yang*, Xuesen Shang and Qingmin Liao</p>
          <p><i>ICIP'16: IEEE International Conference on Image Processing.</i></p>
           
           <div class="paper-buttons">
            
              <a class="button" href="https://drive.google.com/file/d/1Ts_gYIp57llzK53Wyt7hwu4lZ9GQsbis/view" target="_blank">Paper</a>
            

            

            

            

            
              <a class="button" href="https://github.com/YapengTian/ICIP2016" target="_blank">Code</a>
            

            

            

          </div>
        </div>
      
        <div class="paper">
          <p class="title"><b>Single-Image Super-Resolution Using Clustering-Based Global Regression and Propagation Filtering</b></p>
          <p>Wenming Yang, <b>Yapeng Tian</b>, Fei Zhou, Tingrong Yuan, Xuesen Shang and QingminLiao</p>
          <p><i>ACPR'15 Oral: Asian Conference on Pattern Recognition.</i></p>
           
           <div class="paper-buttons">
            
              <a class="button" href="https://drive.google.com/file/d/12tqTHt0aLn7-B1jEgEJBYY64uhwfEezA/view" target="_blank">Paper</a>
            

            

            

            

            

            

            

          </div>
        </div>
      
    </div> -->

    <!-- <div class="tab-pane active" id="papers-selected">
      
      
        <div class="paper">
          <p class="title"><b>Learning to Answer Questions in Dynamic Audio-Visual Scenarios</b></p>
          <p>Guangyao Li<sup>‡</sup>, Yake Wei<sup>‡</sup>, <b>Yapeng Tian<sup>‡</sup></b>, Chenliang Xu, Ji-Rong Wen, and Di Hu</p>
          <p><i>CVPR'22 Oral: IEEE/CVF Conference on Computer Vision and Pattern Recognition. </i></p>
           
           <div class="paper-buttons">
            
              <a class="button" href="https://arxiv.org/pdf/2203.14072.pdf" target="_blank">Paper</a>
            

            

            

            
              <a class="button" href="https://www.youtube.com/watch?v=JH3t5gwe9Xw" target="_blank">Video</a>
            

            
              <a class="button" href="https://github.com/GeWu-Lab/MUSIC-AVQA" target="_blank">Code</a>
            

            

            
              <a class="button" href="https://gewu-lab.github.io/MUSIC-AVQA/" target="_blank">Project</a>
            



          </div>
        </div>
      
        <div class="paper">
          <p class="title"><b>Space-Time Memory Network for Sounding Object Localization in Videos</b></p>
          <p>Sizhe Li<sup>‡</sup>, <b>Yapeng Tian<sup>‡</sup></b>, and Chenliang Xu</p>
          <p><i>BMVC'21: The British Machine Vision Conference. </i></p>
           
           <div class="paper-buttons">
            
              <a class="button" href="https://arxiv.org/pdf/2111.05526.pdf" target="_blank">Paper</a>
            

            

            

            

            
              <a class="button" href="https://github.com/lester0866/Space-Time-Memory-Network-for-Sounding-Object-Localization-in-Videos" target="_blank">Code</a>
            

            

            
              <a class="button" href="https://sites.google.com/view/bmvc2021stm" target="_blank">Project</a>
            



          </div>
        </div>
      
        <div class="paper">
          <p class="title"><b>Can audio-visual integration strengthen robustness under multimodal attacks?</b></p>
          <p><b>Yapeng Tian</b> and Chenliang Xu</p>
          <p><i>CVPR'21: IEEE/CVF Conference on Computer Vision and Pattern Recognition. </i></p>
           
           <div class="paper-buttons">
            
              <a class="button" href="https://arxiv.org/pdf/2104.02000.pdf" target="_blank">Paper</a>
            

            

            

            

            
              <a class="button" href="https://github.com/YapengTian/AV-Robustness-CVPR21" target="_blank">Code</a>
            

            

            



          </div>
        </div>
      
        <div class="paper">
          <p class="title"><b>Cyclic Co-Learning of Sounding Object Visual Grounding and Sound Separation</b></p>
          <p><b>Yapeng Tian</b>, Di Hu, and Chenliang Xu</p>
          <p><i>CVPR'21: IEEE/CVF Conference on Computer Vision and Pattern Recognition.</i></p>
           
           <div class="paper-buttons">
            
              <a class="button" href="https://arxiv.org/pdf/2104.02026.pdf" target="_blank">Paper</a>
            

            

            

            

            
              <a class="button" href="https://github.com/YapengTian/CCOL-CVPR21" target="_blank">Code</a>
            

            

            



          </div>
        </div>
      
        <div class="paper">
          <p class="title"><b>Unified Multisensory Perception: Weakly-Supervised Audio-Visual Video Parsing</b></p>
          <p><b>Yapeng Tian</b>, Dingzeyu Li, and Chenliang Xu</p>
          <p><i>ECCV'20 Spotlight: European Conference on Computer Vision.</i></p>
           
           <div class="paper-buttons">
            
              <a class="button" href="/assets/publications/2019_biometrika/paper.pdf" target="_blank">Paper</a>
            

            

            

            

            
              <a class="button" href="https://github.com/YapengTian/AVVP-ECCV20" target="_blank">Code</a>
            

            
              <a class="button" href="https://github.com/YapengTian/AVVP-ECCV20" target="_blank">Data</a>
            

            



          </div>
        </div>
      
        <div class="paper">
          <p class="title"><b>Zooming Slow-Mo: Fast and Accurate One-Stage Space-Time Video Super-Resolution</b></p>
          <p>Xiaoyu Xiang<sup>‡</sup>, <b>Yapeng Tian<sup>‡</sup></b>, Yulun Zhang, Yun Fu, Jan Allebach, and Chenliang Xu</p>
          <p><i>CVPR'20: IEEE/CVF Conference on Computer Vision and Pattern Recognition.</i></p>
           
           <div class="paper-buttons">
            
              <a class="button" href="https://arxiv.org/pdf/2002.11616.pdf" target="_blank">Paper</a>
            

            

            

            
              <a class="button" href="https://www.youtube.com/watch?v=8mgD8JxBOus" target="_blank">Video</a>
            

            
              <a class="button" href="https://github.com/Mukosame/Zooming-Slow-Mo-CVPR-2020" target="_blank">Code</a>
            

            

            



          </div>
        </div>
      
        <div class="paper">
          <p class="title"><b>TDAN: Temporally Deformable Alignment Network for Video Super-Resolution</b></p>
          <p><b>Yapeng Tian</b>, Yulun Zhang, Yun Fu, and Chenliang Xu</p>
          <p><i>CVPR'20: IEEE/CVF Conference on Computer Vision and Pattern Recognition.</i></p>
          
          <p style="color:red">This is the first work that uses deformable alignment to address video restoration.</p>
         
           <div class="paper-buttons">
            
              <a class="button" href="https://openaccess.thecvf.com/content_CVPR_2020/papers/Tian_TDAN_Temporally-Deformable_Alignment_Network_for_Video_Super-Resolution_CVPR_2020_paper.pdf" target="_blank">Paper</a>
            

            

            

            
              <a class="button" href="https://www.youtube.com/watch?v=eZExENE50I0" target="_blank">Video</a>
            

            
              <a class="button" href="https://github.com/YapengTian/TDAN-VSR-CVPR-2020" target="_blank">Code</a>
            

            

            



          </div>
        </div>
      
        <div class="paper">
          <p class="title"><b>Interpretable and Controllable Audio-Visual Video Captioning</b></p>
          <p><b>Yapeng Tian</b>, Chenxiao Guan, Goodman Justin, Marc Moore, and Chenliang Xu</p>
          <p><i>CVPRW'19: CVPR Workshops.</i></p>
          
          <p style="color:red">Multisensory interpretability in terms of the audio-visual video captioning task.</p>
         
           <div class="paper-buttons">
            
              <a class="button" href="https://openaccess.thecvf.com/content_CVPRW_2019/papers/Sight%20and%20Sound/Yapeng_Tian_Audio-Visual_Interpretable_and_Controllable_Video_Captioning_CVPRW_2019_paper.pdf" target="_blank">Paper</a>
            

            

            

            

            

            

            



          </div>
        </div>
      
        <div class="paper">
          <p class="title"><b>Audio-Visual Event Localization in Unconstrained Videos</b></p>
          <p><b>Yapeng Tian</b>, Jing Shi, Bochen Li, Zhiyao Duan, and Chenliang Xu</p>
          <p><i>ECCV'18: European Conference on Computer Vision.</i></p>
           
           <div class="paper-buttons">
            
              <a class="button" href="https://openaccess.thecvf.com/content_ECCV_2018/papers/Yapeng_Tian_Audio-Visual_Event_Localization_ECCV_2018_paper.pdf" target="_blank">Paper</a>
            

            

            

            
              <a class="button" href="https://www.youtube.com/watch?v=m6r6BbD5MSc" target="_blank">Video</a>
            

            
              <a class="button" href="https://github.com/YapengTian/AVE-ECCV18" target="_blank">Code</a>
            

            
              <a class="button" href="https://drive.google.com/file/d/1FjKwe79e0u96vdjIVwfRQ1V6SoDHe7kK" target="_blank">Data</a>
            

            
              <a class="button" href="https://sites.google.com/view/audiovisualresearch" target="_blank">Project</a>
            



          </div>
        </div>
      
        <div class="paper">
          <p class="title"><b>Residual Dense Network for Image Super-Resolution</b></p>
          <p>Yulun Zhang, <b>Yapeng Tian</b>, Yu Kong , Bineng Zhong, Yun Fu</p>
          <p><i>CVPR'18 Spotlight: IEEE/CVF Conf. on Computer Vision and Pattern Recognition.</i></p>
           
           <div class="paper-buttons">
            
              <a class="button" href="https://arxiv.org/pdf/1802.08797.pdf" target="_blank">Paper</a>
            

            

            

            

            
              <a class="button" href="https://github.com/yulunzhang/RDN" target="_blank">Code</a>
            

            

            



          </div>
        </div>
      
    </div> -->
  
        

    <!-- <div class="tab-pane active" id="papers-audiovisual">
      
      
        <div class="paper">
          <p class="title"><b>Learning to Answer Questions in Dynamic Audio-Visual Scenarios</b></p>
          <p>Guangyao Li<sup>‡</sup>, Yake Wei<sup>‡</sup>, <b>Yapeng Tian<sup>‡</sup></b>, Chenliang Xu, Ji-Rong Wen, and Di Hu</p>
          <p><i>CVPR'22 Oral: IEEE/CVF Conference on Computer Vision and Pattern Recognition. </i></p>
           <div class="paper-buttons">
            
              <a class="button" href="https://arxiv.org/pdf/2203.14072.pdf" target="_blank">Paper</a>
            

            

            

            
              <a class="button" href="https://www.youtube.com/watch?v=JH3t5gwe9Xw" target="_blank">Video</a>
            

            
              <a class="button" href="https://github.com/GeWu-Lab/MUSIC-AVQA" target="_blank">Code</a>
            

            

            
              <a class="button" href="https://gewu-lab.github.io/MUSIC-AVQA/" target="_blank">Project</a>
            

          </div>
        </div>
      
        <div class="paper">
          <p class="title"><b>Space-Time Memory Network for Sounding Object Localization in Videos</b></p>
          <p>Sizhe Li<sup>‡</sup>, <b>Yapeng Tian<sup>‡</sup></b>, and Chenliang Xu</p>
          <p><i>BMVC'21: The British Machine Vision Conference. </i></p>
           <div class="paper-buttons">
            
              <a class="button" href="https://arxiv.org/pdf/2111.05526.pdf" target="_blank">Paper</a>
            

            

            

            

            
              <a class="button" href="https://github.com/lester0866/Space-Time-Memory-Network-for-Sounding-Object-Localization-in-Videos" target="_blank">Code</a>
            

            

            
              <a class="button" href="https://sites.google.com/view/bmvc2021stm" target="_blank">Project</a>
            

          </div>
        </div>
      
        <div class="paper">
          <p class="title"><b>Can audio-visual integration strengthen robustness under multimodal attacks?</b></p>
          <p><b>Yapeng Tian</b> and Chenliang Xu</p>
          <p><i>CVPR'21: IEEE/CVF Conference on Computer Vision and Pattern Recognition. </i></p>
           <div class="paper-buttons">
            
              <a class="button" href="https://arxiv.org/pdf/2104.02000.pdf" target="_blank">Paper</a>
            

            

            

            

            
              <a class="button" href="https://github.com/YapengTian/AV-Robustness-CVPR21" target="_blank">Code</a>
            

            

            

          </div>
        </div>
      
        <div class="paper">
          <p class="title"><b>Cyclic Co-Learning of Sounding Object Visual Grounding and Sound Separation</b></p>
          <p><b>Yapeng Tian</b>, Di Hu, and Chenliang Xu</p>
          <p><i>CVPR'21: IEEE/CVF Conference on Computer Vision and Pattern Recognition.</i></p>
           <div class="paper-buttons">
            
              <a class="button" href="https://arxiv.org/pdf/2104.02026.pdf" target="_blank">Paper</a>
            

            

            

            

            
              <a class="button" href="https://github.com/YapengTian/CCOL-CVPR21" target="_blank">Code</a>
            

            

            

          </div>
        </div>
      
        <div class="paper">
          <p class="title"><b>Unified Multisensory Perception: Weakly-Supervised Audio-Visual Video Parsing</b></p>
          <p><b>Yapeng Tian</b>, Dingzeyu Li, and Chenliang Xu</p>
          <p><i>ECCV'20 Spotlight: European Conference on Computer Vision.</i></p>
           <div class="paper-buttons">
            
              <a class="button" href="/assets/publications/2019_biometrika/paper.pdf" target="_blank">Paper</a>
            

            

            

            

            
              <a class="button" href="https://github.com/YapengTian/AVVP-ECCV20" target="_blank">Code</a>
            

            
              <a class="button" href="https://github.com/YapengTian/AVVP-ECCV20" target="_blank">Data</a>
            

            

          </div>
        </div>
      
        <div class="paper">
          <p class="title"><b>Deep Audio Prior</b></p>
          <p><b>Yapeng Tian</b>, Chenliang Xu, and Dingzeyu Li</p>
          <p><i>CVPRW'20: CVPR Workshops.</i></p>
           <div class="paper-buttons">
            
              <a class="button" href="https://arxiv.org/pdf/1912.10292v1.pdf" target="_blank">Paper</a>
            

            

            

            

            
              <a class="button" href="https://github.com/adobe/Deep-Audio-Prior" target="_blank">Code</a>
            

            

            
              <a class="button" href="https://opensource.adobe.com/Deep-Audio-Prior/" target="_blank">Project</a>
            

          </div>
        </div>
      
        <div class="paper">
          <p class="title"><b>Interpretable and Controllable Audio-Visual Video Captioning</b></p>
          <p><b>Yapeng Tian</b>, Chenxiao Guan, Goodman Justin, Marc Moore, and Chenliang Xu</p>
          <p><i>CVPRW'19: CVPR Workshops.</i></p>
           <div class="paper-buttons">
            
              <a class="button" href="https://openaccess.thecvf.com/content_CVPRW_2019/papers/Sight%20and%20Sound/Yapeng_Tian_Audio-Visual_Interpretable_and_Controllable_Video_Captioning_CVPRW_2019_paper.pdf" target="_blank">Paper</a>
            

            

            

            

            

            

            

          </div>
        </div>
      
        <div class="paper">
          <p class="title"><b>Audio-Visual Event Localization in Unconstrained Videos</b></p>
          <p><b>Yapeng Tian</b>, Jing Shi, Bochen Li, Zhiyao Duan, and Chenliang Xu</p>
          <p><i>ECCV'18: European Conference on Computer Vision.</i></p>
           <div class="paper-buttons">
            
              <a class="button" href="https://openaccess.thecvf.com/content_ECCV_2018/papers/Yapeng_Tian_Audio-Visual_Event_Localization_ECCV_2018_paper.pdf" target="_blank">Paper</a>
            

            

            

            
              <a class="button" href="https://www.youtube.com/watch?v=m6r6BbD5MSc" target="_blank">Video</a>
            

            
              <a class="button" href="https://github.com/YapengTian/AVE-ECCV18" target="_blank">Code</a>
            

            
              <a class="button" href="https://drive.google.com/file/d/1FjKwe79e0u96vdjIVwfRQ1V6SoDHe7kK" target="_blank">Data</a>
            

            
              <a class="button" href="https://sites.google.com/view/audiovisualresearch" target="_blank">Project</a>
            

          </div>
        </div>
      
    </div> -->
<!-- 
    <div class="tab-pane active" id="papers-videorestoration">
      
      
        <div class="paper">
          <p class="title"><b>Video Matting via Consistency-Regularized Graph Neural Networks</b></p>
          <p>Tiantian Wang, Sifei Liu, <b>Yapeng Tian</b>, Kai Li, and Ming-Hsuan Yang</p>
          <p><i>ICCV'21: IEEE/CVF International Conference on Computer Vision. </i></p>
           <div class="paper-buttons">
            
              <a class="button" href="https://faculty.ucmerced.edu/mhyang/papers/iccv2021_video_matting.pdf" target="_blank">Paper</a>
            

            

            

            

            
              <a class="button" href="https://github.com/TiantianWang/VideoMatting-CRGNN" target="_blank">Code</a>
            

            

            

          </div>
        </div>
      
        <div class="paper">
          <p class="title"><b>Zooming Slow-Mo: Fast and Accurate One-Stage Space-Time Video Super-Resolution</b></p>
          <p>Xiaoyu Xiang<sup>‡</sup>, <b>Yapeng Tian<sup>‡</sup></b>, Yulun Zhang, Yun Fu, Jan Allebach, and Chenliang Xu</p>
          <p><i>CVPR'20: IEEE/CVF Conference on Computer Vision and Pattern Recognition.</i></p>
           <div class="paper-buttons">
            
              <a class="button" href="https://arxiv.org/pdf/2002.11616.pdf" target="_blank">Paper</a>
            

            

            

            
              <a class="button" href="https://www.youtube.com/watch?v=8mgD8JxBOus" target="_blank">Video</a>
            

            
              <a class="button" href="https://github.com/Mukosame/Zooming-Slow-Mo-CVPR-2020" target="_blank">Code</a>
            

            

            

          </div>
        </div>
      
        <div class="paper">
          <p class="title"><b>TDAN: Temporally Deformable Alignment Network for Video Super-Resolution</b></p>
          <p><b>Yapeng Tian</b>, Yulun Zhang, Yun Fu, and Chenliang Xu</p>
          <p><i>CVPR'20: IEEE/CVF Conference on Computer Vision and Pattern Recognition.</i></p>
           <div class="paper-buttons">
            
              <a class="button" href="https://openaccess.thecvf.com/content_CVPR_2020/papers/Tian_TDAN_Temporally-Deformable_Alignment_Network_for_Video_Super-Resolution_CVPR_2020_paper.pdf" target="_blank">Paper</a>
            

            

            

            
              <a class="button" href="https://www.youtube.com/watch?v=eZExENE50I0" target="_blank">Video</a>
            

            
              <a class="button" href="https://github.com/YapengTian/TDAN-VSR-CVPR-2020" target="_blank">Code</a>
            

            

            

          </div>
        </div>
      
    </div> -->
<!-- 
    <div class="tab-pane active" id="papers-imagerestoration">
      
      
        <div class="paper">
          <p class="title"><b>Transformer-empowered Multi-scale Contextual Matching and Aggregation for Multi-contrast MRI Super-Resolution</b></p>
          <p>Guangyuan Li, Jun Lv, <b>Yapeng Tian</b>, Qi Dou, ChengyanWang, Chenliang Xu, and Jing Qin</p>
          <p><i>CVPR'22: IEEE/CVF Conference on Computer Vision and Pattern Recognition.</i></p>
           <div class="paper-buttons">
            
              <a class="button" href="https://arxiv.org/pdf/2203.13963.pdf" target="_blank">Paper</a>
            

            

            

            

            
              <a class="button" href="https://github.com/XAIMI-Lab/McMRSR" target="_blank">Code</a>
            

            

            

          </div>
        </div>
      
        <div class="paper">
          <p class="title"><b>Coarse-to-Fine Embedded PatchMatch and Multi-Scale Dynamic Aggregation for Reference-based Super-Resolution</b></p>
          <p>Bin Xia, <b>Yapeng Tian</b>, Yucheng Hang, Wenming Yang, Qingmin Liao, Jie Zhou</p>
          <p><i>AAAI'22: The AAAI Conference on Artificial Intelligence.</i></p>
           <div class="paper-buttons">
            
              <a class="button" href="https://arxiv.org/pdf/2201.04358.pdf" target="_blank">Paper</a>
            

            

            

            

            
              <a class="button" href="https://github.com/Zj-BinXia/AMSA" target="_blank">Code</a>
            

            

            

          </div>
        </div>
      
        <div class="paper">
          <p class="title"><b>Efficient Non-Local Contrastive Attention for Image Super-Resolution</b></p>
          <p>Bin Xia<sup>‡</sup>, Yucheng Hang<sup>‡</sup>, <b>Yapeng Tian</b>, Wenming Yang, Qingmin Liao, Jie Zhou</p>
          <p><i>AAAI'22: The AAAI Conference on Artificial Intelligence. </i></p>
           <div class="paper-buttons">
            
              <a class="button" href="https://arxiv.org/pdf/2201.03794.pdf" target="_blank">Paper</a>
            

            

            

            

            
              <a class="button" href="https://github.com/Zj-BinXia/ENLCA" target="_blank">Code</a>
            

            

            

          </div>
        </div>
      
        <div class="paper">
          <p class="title"><b>Residual Dense Network for Image Super-Resolution</b></p>
          <p>Yulun Zhang, <b>Yapeng Tian</b>, Yu Kong , Bineng Zhong, Yun Fu</p>
          <p><i>TPAMI'20: IEEE Transactions on Pattern Analysis and Machine Intelligence.</i></p>
           <div class="paper-buttons">
            
              <a class="button" href="https://arxiv.org/pdf/1812.10477.pdf" target="_blank">Paper</a>
            

            

            

            

            
              <a class="button" href="https://github.com/yulunzhang/RDN" target="_blank">Code</a>
            

            

            

          </div>
        </div>
      
        <div class="paper">
          <p class="title"><b>CFSNet: Toward a Controllable Feature Space for Image Restoration</b></p>
          <p>Wei Wang<sup>‡</sup>, Ruiming Guo<sup>‡</sup>, <b>Yapeng Tian</b>, and Wenming Yang</p>
          <p><i>ICCV'19: IEEE/CVF International Conference on Computer Vision.</i></p>
           <div class="paper-buttons">
            
              <a class="button" href="https://arxiv.org/pdf/1904.00634.pdf" target="_blank">Paper</a>
            

            

            

            

            
              <a class="button" href="https://github.com/qibao77/CFSNet" target="_blank">Code</a>
            

            

            

          </div>
        </div>
      
        <div class="paper">
          <p class="title"><b>LCSCNet: Linear Compressing Based Skip-Connecting Network for Image Super-Resolution</b></p>
          <p>Wenming Yang, Xuechen Zhang, <b>Yapeng Tian</b>, Wei Wang, Jing-Hao Xue, Qingmin Liao</p>
          <p><i>TIP'19: IEEE Trans. Image Processing.</i></p>
           <div class="paper-buttons">
            
              <a class="button" href="https://arxiv.org/abs/1909.03573" target="_blank">Paper</a>
            

            

            

            

            

            

            

          </div>
        </div>
      
        <div class="paper">
          <p class="title"><b>Deep Learning for Single Image Super-Resolution: A Brief Review</b></p>
          <p>Wenming Yang, Xuechen Zhang, <b>Yapeng Tian</b>, Wei Wang, JingHao Xue, and Qingmin Liao</p>
          <p><i>TMM'19: IEEE Trans. Multimedia.</i></p>
           <div class="paper-buttons">
            
              <a class="button" href="https://arxiv.org/pdf/1808.03344.pdf" target="_blank">Paper</a>
            

            

            

            

            

            

            

          </div>
        </div>
      
        <div class="paper">
          <p class="title"><b>Residual Dense Network for Image Super-Resolution</b></p>
          <p>Yulun Zhang, <b>Yapeng Tian</b>, Yu Kong , Bineng Zhong, Yun Fu</p>
          <p><i>CVPR'18 Spotlight: IEEE/CVF Conf. on Computer Vision and Pattern Recognition.</i></p>
           <div class="paper-buttons">
            
              <a class="button" href="https://arxiv.org/pdf/1802.08797.pdf" target="_blank">Paper</a>
            

            

            

            

            
              <a class="button" href="https://github.com/yulunzhang/RDN" target="_blank">Code</a>
            

            

            

          </div>
        </div>
      
        <div class="paper">
          <p class="title"><b>NTIRE 2017 Challenge on Single Image Super-Resolution: Methods and Results</b></p>
          <p>Radu Timofte, Eirikur Agustsson, Luc Van Gool, ..., Xintao Wang, <b>Yapeng Tian</b>, Ke Yu, Yulun Zhang, Shixiang Wu, Chao Dong, Liang Lin, Yu Qiao, ...</p>
          <p><i>CVPRW'17: CVPR Workshops.</i></p>
           <div class="paper-buttons">
            
              <a class="button" href="https://people.ee.ethz.ch/~timofter/publications/Timofte-CVPRW-2017.pdf" target="_blank">Paper</a>
            

            

            

            

            

            

            

          </div>
        </div>
      
        <div class="paper">
          <p class="title"><b>Consistent Coding Scheme for Single-Image Super-Resolution Via Independent Dictionaries</b></p>
          <p>Wenming Yang, <b>Yapeng Tian</b>, Fei Zhou*, Qingmin Liao, Hai Chen and Chenglin Zheng</p>
          <p><i>TMM'16: EEE Trans. Multimedia.</i></p>
           <div class="paper-buttons">
            
              <a class="button" href="https://drive.google.com/file/d/1MpEM5qmSJi1GtY9TftNNV0cgSHqMT_KQ/view" target="_blank">Paper</a>
            

            

            

            

            

            

            

          </div>
        </div>
      
        <div class="paper">
          <p class="title"><b>Anchored Neighborhood Regression based Single Image Super-Resolution from Self-examples</b></p>
          <p><b>Yapeng Tian</b>, Fei Zhou, Wenming Yang*, Xuesen Shang and Qingmin Liao</p>
          <p><i>ICIP'16: IEEE International Conference on Image Processing.</i></p>
           <div class="paper-buttons">
            
              <a class="button" href="https://drive.google.com/file/d/1Ts_gYIp57llzK53Wyt7hwu4lZ9GQsbis/view" target="_blank">Paper</a>
            

            

            

            

            
              <a class="button" href="https://github.com/YapengTian/ICIP2016" target="_blank">Code</a>
            

            

            

          </div>
        </div>
      
        <div class="paper">
          <p class="title"><b>Single-Image Super-Resolution Using Clustering-Based Global Regression and Propagation Filtering</b></p>
          <p>Wenming Yang, <b>Yapeng Tian</b>, Fei Zhou, Tingrong Yuan, Xuesen Shang and QingminLiao</p>
          <p><i>ACPR'15 Oral: Asian Conference on Pattern Recognition.</i></p>
           <div class="paper-buttons">
            
              <a class="button" href="https://drive.google.com/file/d/12tqTHt0aLn7-B1jEgEJBYY64uhwfEezA/view" target="_blank">Paper</a>
            

            

            

            

            

            

            

          </div>
        </div>
      
    </div> -->

    

    

    


   

  </div>
</div>
</div>

<!-- ========== PROJECTS ========== 
<div class="docs-section" id="projects">
  <h4>Projects</h4>

  <ul class="tab-nav">
    <li><div class="button active" data-ref="#projects-selected">Selected</div></li>
    <li><div class="button" data-ref="#projects-all">All</div></li>
  </ul>

  <div class="tab-content">
    <div class="tab-pane active" id="projects-selected">
      
      
        
        
          <div class="row">
        

          <div class="four columns">
            <div class="project-container">

                <div class="project-image-container">
                  <a href="projects/2016_network-ab-testing.html">
                    <img src="assets/projects/2016_network-ab/thumbnail.jpg" class="u-max-full-width" />
                  </a>
                </div>

                <div class="project-caption">
                  <b>Detecting Network Effects</b> <br/>
                  Randomizing Over Randomized Experiments
                </div>

            </div>
          </div>

        
      
        
        

          <div class="four columns">
            <div class="project-container">

                <div class="project-image-container">
                  <a href="projects/2016_human-atlas.html">
                    <img src="assets/projects/2016_human-atlas/thumbnail.png" class="u-max-full-width" />
                  </a>
                </div>

                <div class="project-caption">
                  <b>Human Atlas</b> <br/>
                  Tool for Mapping Social Networks
                </div>

            </div>
          </div>

        
      
        
        

          <div class="four columns">
            <div class="project-container">

                <div class="project-image-container">
                  <a href="projects/2015_jun.html">
                    <img src="assets/projects/2015_jun/thumbnail.png" class="u-max-full-width" />
                  </a>
                </div>

                <div class="project-caption">
                  <b>Responsive Communities</b> <br/>
                  Pilot project in Jun, Spain
                </div>

            </div>
          </div>

        
          </div>
        
      
    </div>

    <div class="tab-pane" id="projects-all">
      
        
        
          <div class="row">
        

          <div class="four columns">
            <div class="project-container">

                <div class="project-image-container">
                  <a href="projects/2016_network-ab-testing.html">
                    <img src="assets/projects/2016_network-ab/thumbnail.jpg" class="u-max-full-width" />
                  </a>
                </div>

                <div class="project-caption">
                  <b>Detecting Network Effects</b> <br/>
                  Randomizing Over Randomized Experiments
                </div>

            </div>
          </div>

        
      
        
        

          <div class="four columns">
            <div class="project-container">

                <div class="project-image-container">
                  <a href="projects/2016_human-atlas.html">
                    <img src="assets/projects/2016_human-atlas/thumbnail.png" class="u-max-full-width" />
                  </a>
                </div>

                <div class="project-caption">
                  <b>Human Atlas</b> <br/>
                  Tool for Mapping Social Networks
                </div>

            </div>
          </div>

        
      
        
        

          <div class="four columns">
            <div class="project-container">

                <div class="project-image-container">
                  <a href="projects/2015_jun.html">
                    <img src="assets/projects/2015_jun/thumbnail.png" class="u-max-full-width" />
                  </a>
                </div>

                <div class="project-caption">
                  <b>Responsive Communities</b> <br/>
                  Pilot project in Jun, Spain
                </div>

            </div>
          </div>

        
          </div>
        
      
        
        
          <div class="row">
        

          <div class="four columns">
            <div class="project-container">

                <div class="project-image-container">
                  <a href="projects/2014_item-cold-start.html">
                    <img src="assets/projects/2014_item-cold-start/thumbnail.jpg" class="u-max-full-width" />
                  </a>
                </div>

                <div class="project-caption">
                  <b>Cold-Start Recommendations</b> <br/>
                  Learning Local Collective Embeddings
                </div>

            </div>
          </div>

        
      
        
        

          <div class="four columns">
            <div class="project-container">

                <div class="project-image-container">
                  <a href="projects/2013_iterative-hybrid-algorithm.html">
                    <img src="assets/projects/2013_iterative-hybrid-algorithm/thumbnail.jpg" class="u-max-full-width" />
                  </a>
                </div>

                <div class="project-caption">
                  <b>Semi-supervised Learning</b> <br/>
                  Iterative Hybrid Algorithm
                </div>

            </div>
          </div>

        
      
        
        

          <div class="four columns">
            <div class="project-container">

                <div class="project-image-container">
                  <a href="projects/2011_twitter-sentiment-analysis.html">
                    <img src="assets/projects/2011_twitter-sentiment-analysis/thumbnail.png" class="u-max-full-width" />
                  </a>
                </div>

                <div class="project-caption">
                  <b>Twitter Sentiment Analysis</b> <br/>
                  Analyzing Financial Tweets
                </div>

            </div>
          </div>

        
          </div>
        
      
        
        
          <div class="row">
        

          <div class="four columns">
            <div class="project-container">

                <div class="project-image-container">
                  <a href="projects/2010_wordnet-contruction.html">
                    <img src="assets/projects/2010_wordnet-construction/thumbnail.jpg" class="u-max-full-width" />
                  </a>
                </div>

                <div class="project-caption">
                  <b>Wordnet Construction</b> <br/>
                  Automatic Wordnet Construction using Language Models
                </div>

            </div>
          </div>

        
      
        
        

          <div class="four columns">
            <div class="project-container">

                <div class="project-image-container">
                  <a href="projects/2010_fingerprint-verification.html">
                    <img src="assets/projects/2010_fingerprint-verification/thumbnail.png" class="u-max-full-width" />
                  </a>
                </div>

                <div class="project-caption">
                  <b>Fingerprint Verification</b> <br/>
                  Image processing class project
                </div>

            </div>
          </div>

        
      
        
        

          <div class="four columns">
            <div class="project-container">

                <div class="project-image-container">
                  <a href="projects/2009_connect-four.html">
                    <img src="assets/projects/2009_connect-four/thumbnail.png" class="u-max-full-width" />
                  </a>
                </div>

                <div class="project-caption">
                  <b>Connect Four AI Agent</b> <br/>
                  Iterative deepening and alpha-beta pruning
                </div>

            </div>
          </div>

        
          </div>
        
      
    </div>
  </div>

</div>
-->

<!-- ========== PUBLICATIONS ========== -->
<span class="anchor" id="teaching"></span>
<div class="docs-section">
<div class="docs-section">
  <h4>Teaching</h4>

  <p>
    <b>TA'd Courses:</b>
  </p>

  <ul class="STYLE238">
    <li> Spring 2019 - <a href="https://www.cs.rochester.edu/~cxu22/t/249S19/">CSC 249/449: Machine Vision</a> (University of Rochester) </li>
    <li> Fall 2018 - <a href="https://www.cs.rochester.edu/~cxu22/t/577F18/">CSC 577: Advanced Topics in Computer Vision,</a> (University of Rochester) </li>
    <li> Spring 2018 - <a href="https://www.cs.rochester.edu/~cxu22/t/249S18/">CSC 249/449: Machine Vision</a> (University of Rochester) </li>
    <li> Fall 2016 - Advanced Image Processing and Its Applications (Tsinghua University) </li>
    <li> Spring 2016 - Digital Image Processing (Tsinghua University) </li>

  </ul>

    <p style="text-align:left"><b>Guest Lecturer:</b></p>
    <ul class="STYLE238">
      <li> Spring 2021 - <a href="https://www.cs.rochester.edu/~cxu22/t/577S21/">CSC 577: Advanced Topics in Computer Vision,</a> (University of Rochester) </li>
      <li> Fall 2020 - <a href="https://www.cs.rochester.edu/~cxu22/t/249F20/">CSC 249/449: Machine Vision</a> (University of Rochester) </li>
    </ul>


  <p>
    <b>Tutorials:</b>
    </p>
    <ul class="STYLE238">
      <li> CVPR'21 - <a href="https://audio-visual-scene-understanding.github.io/">Audio-Visual Scene Understanding</a> </li>
      <li> WACV'21 - <a href="https://echo0409.github.io/Audio-Visual-Scene-Understanding/">Audio-Visual Scene Understanding</a> </li>
    </ul>


</div>
</div>

<!-- ========== Professional Activities ========== -->
<span class="anchor" id="activity"></span>
<div class="docs-section">
<div class="docs-section">
  <h4>Professional Activities</h4>
  <p style="text-align:left"><b>Talks and Seminars:</b></p>
  <ul class="STYLE238">
    <li> Audio-Visual Scene Understanding Towards Unified, Explainable, and Robust Multisensory Perception 
      <p style = "text-indent:0.5cm;"> KTH Dive-Deep Seminar, Dec. 2021<br>
        &nbsp;&nbsp;&nbsp;&nbsp; RIT PhD Colloquium Series, Oct. 2021</p>
    </li>
    <li>Audio-Visual Video Understanding, IIAI Seminar, Sep. 2021 </li>
    <li>The Future of Audio-Visual Research Panel Discussion, VALSE Webinar, Nov. 2021 </li>
    
  </ul>

  <p style="text-align:left"><b>Conference Program Committee/Reviewer:</b></p>
  <ul class="STYLE238">
    <li>CVPR: IEEE/CVF Conference on Computer Vision and Pattern Recognition </li>
    <li>ICCV: IEEE/CVF International Conference on Computer Vision</li>
    <li>ECCV: European Conference on Computer Vision </li>
    <li>NeurIPS: Conference on Neural Information Processing Systems  </li>
    <li>ICLR: International Conference on Learning Representations </li>
    <li>AAAI: AAAI Conference on Artificial Intelligence</li>
    <li>ICML: International Conference on Machine Learning </li>
    <li>WACV: Winter Conference on Applications of Computer Vision</li>
    <li>ACCV: Asian Conference on Computer Vision</li>
  </ul>

  <p style="text-align:left"><b>Journal Reviewer:</b></p>
  <ul class="STYLE238">
    <li>TPAMI: IEEE Transactions on Pattern Analysis and Machine Intelligence  </li>
    <li> TMLR: The Transactions on Machine Learning Research  </li>
    <li>TIP: IEEE Transactions on Image Processing  </li>
    <li>TNNLS: IEEE Transactions on Neural Networks and Learning Systems  </li>
    <li> TMM: IEEE Transactions on Multimedia </li>
    <li>TCSVT: IEEE Transcations on Circuits and Systems for Video Technology  </li>
    <li>TASLP: IEEE/ACM Transactions on Audio, Speech and Language Processing </li>
    <li>Scientific Reports–Nature  </li>
    <li>CGF: Computer Graphics Forum </li>
    <li>CVIU: Computer Vision and Image Understanding </li>
    <li>SPIC: Signal Processing: Image Communication </li>
    <li> IEEE Access</li>

  </ul>

</div>
</div>

<!-- ========== Awards ========== -->
<span class="anchor" id="award"></span>
<div class="docs-section">
<div class="docs-section">
  <h4>Awards</h4>
    <p>
      Top 10% of High-Scoring Reviewers for NeurIPS, 2020<br>
      Invited attendee of Amazon Graduate Student Symposium, Seattle, USA, 2019  <br>
      Outstanding Graduate of Tsinghua University, 2017  <br>
      Outstanding Master Thesis Award, Tsinghua University, 2017  <br>
      National Scholarship, Tsinghua University, 2016 <br>
      Second-class Scholarship, Tsinghua University, 2015 
    </p>


</div>
</div>


<!-- ========== RESUME ========== -->
<span class="anchor" id="resume"></span>
<div class="docs-section">
<div class="docs-section">
  <h4>Vitæ</h4>

  <p>Full CV in <a href=/assets/cv/cv_web.pdf target="_blank">PDF</a>.</p>

  <!-- The Timeline -->
  <ul class="timeline">
    
    <li>
      
      <div class="direction-r">
      
        <div class="flag-wrapper">
          <span class="flag">University of Rochester</span>
          <span class="time-wrapper"><span class="time">2017 - now</span></span>
        </div>
        <div class="desc"><b>Ph.D. Student</b> <br/> Department of Computer Science</div>
      </div>
    </li>
    
    <li>
      
      <div class="direction-l">
      
        <div class="flag-wrapper">
          <span class="flag">Meta</span>
          <span class="time-wrapper"><span class="time">Sep. 2021 - Jan. 2022</span></span>
        </div>
        <div class="desc"><b>Research Intern</b> <br/> Reality Labs</div>
      </div>
    </li>
    
    <li>
      
      <div class="direction-l">
      
        <div class="flag-wrapper">
          <span class="flag">Adobe</span>
          <span class="time-wrapper"><span class="time">Summer 2021</span></span>
        </div>
        <div class="desc"><b>Research Intern</b> <br/> Creative Intelligence Lab</div>
      </div>
    </li>
    
    <li>
      
      <div class="direction-l">
      
        <div class="flag-wrapper">
          <span class="flag">Adobe</span>
          <span class="time-wrapper"><span class="time">Summer 2019</span></span>
        </div>
        <div class="desc"><b>Research Intern</b> <br/> Creative Intelligence Lab</div>
      </div>
    </li>
    
    <li>
      
      <div class="direction-r">
      
        <div class="flag-wrapper">
          <span class="flag">Tsinghua University,</span>
          <span class="time-wrapper"><span class="time">2014-2017</span></span>
        </div>
        <div class="desc"><b>M.E. Student</b> <br/> Department of Electronic Engineering</div>
      </div>
    </li>
    
    <li>
      
      <div class="direction-l">
      
        <div class="flag-wrapper">
          <span class="flag">Chinese Academy of Sciences,</span>
          <span class="time-wrapper"><span class="time">Nov. 2016- May 2017</span></span>
        </div>
        <div class="desc"><b>Visiting Student</b> <br/> Shenzhen Institutes of Advanced Technology</div>
      </div>
    </li>
    
    <li>
      
      <div class="direction-r">
      
        <div class="flag-wrapper">
          <span class="flag">Xidian University</span>
          <span class="time-wrapper"><span class="time">2009 - 2013</span></span>
        </div>
        <div class="desc"><b>B.E. Student</b> <br/> School of Electronic Engineering</div>
      </div>
    </li>
    
  </ul>
</div>
</div>

<p> This website was built with <a href="https://jekyllrb.com">jekyll</a> based on a template from <a href="http://web.media.mit.edu/~msaveski/">Martin Saveski</a>.
</p>


    <div class="footer">
      <div class="row">
        <div class="four columns">
          Yapeng Tian
        </div>
        <div class="four columns">
          yapengtian [AT] rochester.edu
        </div>
        <div class="four columns">
          <span onclick="window.open('https://twitter.com/YapengTian')" style="cursor: pointer">
            <i class="fa fa-twitter" aria-hidden="true"></i>
          </span>
          <span onclick="window.open('https://www.linkedin.com/in/yapeng-tian-780795141/')" style="cursor: pointer">
            <i class="fa fa-linkedin-square" aria-hidden="true"></i>
          </span>
          <span onclick="window.open('https://github.com/YapengTian')" style="cursor: pointer">
            <i class="fa fa-github" aria-hidden="true"></i>
          </span>
          <span onclick="window.open('https://scholar.google.com/citations?user=lxCqdpoAAAAJ&hl=en')" style="cursor: pointer">
            <i class="ai ai-google-scholar ai-lg" aria-hidden="true"></i>
          </span>
          <span onclick="window.open('https://dblp.dagstuhl.de/pid/176/4020.html')" style="cursor: pointer">
            <i class="ai ai-dblp ai-lg" aria-hidden="true"></i>
          </span>
        </div>
      </div>
    </div>

  </div>

  <!-- Google Analytics -->
  <script>
  (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
  (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
  m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
  })(window,document,'script','https://www.google-analytics.com/analytics.js','ga');

  ga('create', 'G-7BR8HB30JT', 'auto');
  ga('send', 'pageview');

</script>

  <!-- do not remove -->
  <span id="62cd7b7da1aff3196fdc26b60e396df9"></span>

<!-- End Document
  –––––––––––––––––––––––––––––––––––––––––––––––––– -->
</body>
</html>
